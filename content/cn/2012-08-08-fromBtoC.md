---
title: "从高维诅咒到因子分析"
date: 2012-08-08
slug: fromBtoC
tags:
  - popsci
  - data
---

调用无尽的参数来描述一个物体是有必要的吗？可以从另一个角度来看看待这个问题：我有一个苹果，我有必要为了说明它是个苹果而去学习植物学甚至是遗传组学来断定这货是个苹果吗？

当然没有必要，这倒不是说你对这个苹果的认识不够深刻，只是在辨认苹果这个概念所对应的实体时我们会套用一个类似柏拉图理型世界的玩意来识别并忽视其所谓不完美的部分来认定，这种抽象的概念在柏拉图看来是完美且合理的。且不论这里面的理想成分有多少是主观的，这里需要注意的是其实所谓“完美”的概念所描绘的东西现实世界可能并不存在。好了，在这里我们会遇到一个问题，这样的描述其实是增加了一个维度，而这个维度对于事物的描绘可能是唯一的。因此，我只依靠这个维度去判断区别物体不是更好吗？

这里停一下，前文明明说用无尽的参数描述是有必要的，怎么又回到没必要了呢？因为有必要的前文已经说过了，高维诅咒可以帮助我们设置密码，此外前文留的尾巴的真正意义是“无尽”这个词，从0到1间有多少有理数？这个数会比1到2之间的多还是少？比0.5到1之间的呢？好了，不折腾了，这个问题思考下去就是希尔伯特那个第一问题——连续统假设。这是个不可从内部证明的东西，其实我倒希望很多这样的问题包括黎曼猜想，如果能用对角线方法证明这个问题不可证明就好了，至少不像费马定理那样最后的证明搞得非专业的俺一点都看不懂。这个“无尽”问题是个无底洞，很多经典的悖论就是在无尽上挖的坑，例如芝诺的乌龟悖论，其实说谎者悖论的本质也是涉及了无穷推衍甚至变成循环推衍而让人心驰神往，但无尽的推衍不代表无尽的时间，谜题的设置有时候就是让人感觉到不可能而不去思考的，这些问题存在了几千年但不影响人类对世界的认识，为什么？因为这不妨碍采集捕猎男欢女爱？这是实用主义的观点但却很真实：这个世界就是带着问题或者说谜题展现到每个人面前的，而我们在这方面的认知水平与2万年前区别不大，都是得过且过。为什么呢？我们的认知的程度更多与生存下去所需的知识水平相对应，那种思考无穷的东西换不来饭吃，可能有那么一两个这样的基因都被自然选择抹掉了，但在现在的生活条件下会不会再现呢？谁知道呢，未来无限可能。

好了，前面的尾巴收拾掉了，来谈谈我们现有的认知水平。我们的认识如果真如柏拉图所言是看到一个个完美理型的影子的话就会有个问题：何为完美？几何或许给了我们一些答案，到同一点距离相同点的轨迹所构成的圆？平行的两条线？等边三角形？或是物理上的光速与绝对零度？不知道。这是个纯主观的东西，让盲人去想象彩虹是不现实的，让别人去接受你的完美也很困难。但每个人都可以构建自己的完美，这就是亚里士多德的观点：归纳与演绎。我们认识世界本质上是一种抽象提取特征的过程，我们不需要知道太多的细节，把握特征就可以整理思路，归类事物，也就是说我们的唯一性建立在抽象的基础上，而抽象过程不会是随机的，其目的性可能就是实用或者说可交流。事实上，知识的认可要比其本身更有意义，那要保证每个人都认可你的认识，我们要拥有同一套密码本，那就是所谓的知识。这些知识的产生过程既要不依赖于人而存在又要可保证可被交流，这如何实现？这问题可能我们自己永远答不上来，我们的大脑进化到今天本身就回答了这个问题，至于这是怎样的一个过程，我们能做的就只有像寻找背景辐射那样搜寻我们认识事物共通的一些线索。在这里从维度角度上看，我想讨论的是维度的降低过程。

当两个相互陌生的人看到一块石头，他们如何就这个石头进行交流呢？首先得告诉对方看到了什么，这里语言就为我们提供了便利，一些既定的概念就可以用来交流，那么这些概念如何抽象出来的呢？我们的感官可能是罪魁祸首，例如颜色、质地、重量、口味、气味……通过一些感官上的综合我们可以形成一个特征谱，而这个特征谱可能是唯一的，因此为了交流我们会对特征谱进行模糊化，保留我们所认为最根本的特征来传递这个信息，这个过程就是一个降维的过程。而当要描述物体的唯一性时也很简单，将维度升上去，加几个区别的特性就好。有了抽象我们可以归类物体，有了具象我们可以区别物体，这也许就是交流的起点。上篇文章实际只是说了具象的过程，今天的主角是抽象过程。所谓因子分析的东西就是这样一个抽象工具。

但其实真正熟悉因子分析的人可能察觉到我在这里用因子分析不太合适，因为因子分析是从显性变量中提取隐性变量的过程，而且它能不能降维还取决于变量是否独立之类的假设。的确，如果变量间独立那就谈不上降维而仅仅是个信息处理能力的问题了，但所谓变量独立这种事在现实世界恐怕并不多见，而这也是抽象过程的一部分前提。当然，其实面对因子分析更麻烦的地方在与其与主成分分析经常混在一起讨论，这里就不涉及这两种过程了，但值得明确的是主成分分析属于一种描述性统计，属于让数据自己说话而因子分析则事先有自己的一个假设来进行验证，具体区别可参考wiki上的解释：

> The differences between principal components analysis and factor analysis are further illustrated by Suhr (2009):
PCA results in principal components that account for a maximal amount of variance for observed variables; FA account for common variance in the data.
PCA inserts ones on the diagonals of the correlation matrix; FA adjusts the diagonals of the correlation matrix with the unique factors.
PCA minimizes the sum of squared perpendicular distance to the component axis; FA estimates factors which influence responses on observed variables.
The component scores in PCA represent a linear combination of the observed variables weighted by eigenvectors; the observed variables in FA are linear combinations of the underlying and unique factors.
In PCA, the components yielded are uninterpretable, i.e. they do not represent underlying ‘constructs’; in FA, the underlying constructs can be labeled and readily interpreted, given an accurate model specification.

其实关于因子分析再深了我也讲不了了，只是说这是一种统计学工具，而这种工具在我看来是很有说服力的，同时我也认为统计学工具对于了解世界认识世界是极为关键的，至少这种工具可以让我们从纯粹的自然选择中逃离出来一探自我与所谓完美的东西。但所谓统计似乎也逃不出先验东西的存在，而且似乎正是有了先验的东西统计学变的更实用了，下一篇从因子分析到垃圾邮件就会讨论这个问题以及解决因子分析这个尾巴，至于时间吗，可能遥遥无期吧^.^
