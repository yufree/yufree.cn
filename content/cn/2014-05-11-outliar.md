---
title: 去留两难异常值
date: 2014-05-11
slug: outliar
tags:
  - paper
---

最近看到一个关于大气污染物的案例，感觉可以部分回答为什么科技如此发达却搞不清污染物与健康联系的问题，也可作为非相关科研人员了解实际研究的一扇窗户。

该论文题目很唬人，Cardiovascular Effects of Nickel in Ambient Air，发表于环境健康领域顶级期刊Environ Health Perspect，该期刊收录PMC，也就是说免费，谁都可以看全文。

这篇文章的故事简单明快，使用了小鼠作为模型，通了几个月纽约的浓缩空气然后测了下心电图什么的指标，发现浓缩空气中的Ni跟一些指标的变化相关，然后利用一个公共数据库NMMAPS查询了死亡率与空气中各种污染物的关系，发现只有Ni与V与死亡率关系密切，其余的组分没什么影响。基于此，研究人员认为Ni与V跟心血管死亡率存在相关性，但不清楚机理。

应该说整个研究结论是比较有意思的，因为大气污染物，特别是我们所说的PM10，PM2.5都只是一个笼统的重量上的概括，我们相信健康效应是由这些颗粒物上的部分而不是全部污染物来改变的，所以单纯说颗粒物浓度高低其实对健康效应研究没太大意义，当然总浓度高了，相关污染物浓度提高也能观察到现象。但这类现象太表面，所以现在我们得到颗粒物的样品都会进一步进行分析，确定其组成，搞清楚有机成分与无机成分是什么，然后寻找与健康效应的关系。这个研究基本思路也是这样的，他们主要关注了无机组分的数据，然后就发现了Ni的问题，通过同行评议发表了高水平文章，似乎接下来的研究就很明朗了，进行下一步动物实验，找出影响机制。

应该说，如果没有一年后的另一篇文章，这个故事还是很理想的。但我们回想一下，这个过程其实是在碰运气，因为颗粒物上的污染物他们只关注了34种，还都是元素浓度没考虑形态，能撞上一两种很不容易了，特别是数据量很大时这种规律性依然明显。但是，我们依然忽略了很多细节，例如他们的置信区间如何计算，数据哪里得到，是否一致，模型选择是否合适…也许你会说这该是审稿人把关，但即便把过关也不代表没问题。一年后的这篇研究没有实际进行过实验，只是重新把他们用的数据算了一下，结果发现了一个很有意思的现象：整个相关性实际上是被三个纽约的数据所控制的，也就是我们所说的杠杆点，这些点参与建模就有相关性，不参与就没有太大统计学意义。

这样就更有意思了，到底要不要这三个数据？也许你会说当然不要，很明显是应该剔除的异常点。但如果你从事环境调查研究就明白实际数据大都是这样的，环境污染物浓度的分析与监测受实际采样过程影响显著，有些规划的采样点采样根本就不现实，所以数据从来都不是理想的，这时候模型里加入或减去数据都是需要说明白的。但也仅仅就是说明白，然后结论存疑而不是推翻，因为这样研究人员也不敢轻易下结论，推翻前人的发现同样需要谨慎。但到媒体报导就显得大气多了，常常就直接去掉虚拟语气了。

大体就是这样了，可以说现在环境健康的研究做到最高层也就是这样，不断的质疑，不断的发现。所以不要问环境科研人员一些yes or no的问题，每个问题展开了去说都是一长串的问号，那些动不动就给你答案的十占八九是砖家，道行不够就出来卖了。科研人员寻找的是证据并基于证据给出限定性结论，对于喜闻乐见的XX有没有害，XX有没有毒等问题，有时候实在没办法就按最保守的方法搞个分类什么提个标准的，而其实所谓的保守也仅仅是基于已有知识来判断的。以诺贝尔奖为例，这种级别的发现可以说运气与实力都得好才行，更多的科研工作者面对的就是上面提到的状况，不断的质疑与反思才可能换来一点点进步，而这一点点进步到头来可能还是假的。

全文链接

[1](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1665439/)

[2](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2137127/)