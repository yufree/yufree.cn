---
title: 贝叶斯棒球
date: 2016-06-12
slug: bayes baseball
---

<!-- BLOGDOWN-HEAD -->
<!-- /BLOGDOWN-HEAD -->

<!-- BLOGDOWN-BODY-BEFORE -->
<!-- /BLOGDOWN-BODY-BEFORE -->
<p>最近看到一系列以棒球为主题的关于贝叶斯分析的<a href="http://varianceexplained.org/posts/">文章</a>，赶忙总结了一下，省的忘了。我非常喜欢这类通过实际案例来进行分析的讲解方法，很容易举一反三。</p>
<div class="section level2">
<h2>什么是贝塔分布？</h2>
<p>贝塔分布的本质是概率分布的分布。我们来看一个棒球击球率的估计问题，一共打了300个球，81个击中，219个击空。你可以计算出一个击中的概率：</p>
<p><span class="math display">\[\frac{\alpha}{\alpha + \beta} = \frac{81}{81+219} = 0.27\]</span></p>
<p>这个概率应该来自于一个分布，而这个分布可能是参数为 <span class="math inline">\(\alpha\)</span> 与 <span class="math inline">\(\beta\)</span> 的贝塔分布。我们看下概率密度曲线：</p>
<pre class="r"><code>library(ggplot2)
x &lt;- seq(0,1,length=100)
db &lt;- dbeta(x, 81, 219)
ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/beta-1.png" alt="plot of chunk beta" />
<p class="caption">plot of chunk beta</p>
</div>
<p>观察这个概率密度分布图可以看出一个大约在0.2-0.35的概率区间，表示击球率可能的取值空间。</p>
</div>
<div class="section level2">
<h2>为什么击球的概率分布符合贝塔分布？</h2>
<p>设想球员A打了一个球打中了，那么在没有先验知识的情况下我会认为他击中概率为1；这个球员又打中了一个球，那么还是1；但第三个没打中，我们会认为他击中概率是0吗？一般而言，这类连续击球问题可以用二项分布来描述，例如10个球打中8个的概率，我们假设这个击球概率为q，那么这个概率应该是个q的函数：</p>
<p><span class="math display">\[f(q) \propto q^a(1-q)^b\]</span></p>
<p>q对于一个实际问题（例如个人击球率）是常数，所以出现这个场景的概率实际上是a与b的函数。为了保障这个概率函数累积为1，需要除一个跟a与b有关的数。这个数可以用贝塔函数<span class="math inline">\(B(a,b)\)</span>来表示，数学证明<a href="https://en.wikipedia.org/wiki/Conjugate_prior#Example">略</a>。</p>
<p>那么我们继续关注这个球员，如果接着打了一个中了，那么如何更新这个概率？根据贝叶斯公式，最后推导出的结果如下：</p>
<p><span class="math display">\[Beta(\alpha+1,\beta+0)\]</span></p>
<p>根据公式可以看出我们对这个击球率的估计会高一点，这是贝塔分布的神奇之处，形式非常简单，理解也很直观。虽然贝塔分布不是为贝叶斯分析而设计的，但其数学性质非常便于进行贝叶斯分析。</p>
</div>
<div class="section level2">
<h2>先验与后验</h2>
<p>如果我们后续观察的击球少，那么不太容易影响到对概率的先验估计：</p>
<pre class="r"><code>x &lt;- seq(0,1,length=100)
db &lt;- dbeta(x, 81+1, 219)
ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/beta1-1.png" alt="plot of chunk beta1" />
<p class="caption">plot of chunk beta1</p>
</div>
<p>如果后续观察了大量的击球都中了，那么概率会偏向后面数据所提供的击球率：</p>
<pre class="r"><code>x &lt;- seq(0,1,length=100)
db &lt;- dbeta(x, 81+1000, 219)
ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/beta2-1.png" alt="plot of chunk beta2" />
<p class="caption">plot of chunk beta2</p>
</div>
<p>这是贝叶斯分析的核心思想，通过证据更新经验。经验是主观的或先验的，当证据足够多，结果就偏向事实。因此，最后得到的均值（后验0.83）一定是介于经验值（先验0.27）与证据值（全击中就是1）之间。</p>
<p>另一种不那么严谨的理解方法是如果一个概率是稳定的，那么多次实验的结果差别不会太大，则有：</p>
<p><span class="math display">\[\frac{a}{b} = \frac{c}{d} = \frac{a+b}{c+d}\]</span></p>
<p>如果每次实验的概率持平，那么不存在不确定度；但如果前面实验的次数少而后面实验的次数多，那么概率会偏重于后面，这就是贝塔分布想说明的事。</p>
</div>
<div class="section level2">
<h2>经验贝叶斯</h2>
<p>对于两个球员，一个打了10个球中了4个，另一个打了1000个球中了300个，一般击中概率0.2，你会选哪一个去培养？我们对于小样本量的统计推断会有天然的不信任，如何通过统计量来描述？下面用MLB的数据说明，首先提取出球员的击球数据：</p>
<pre class="r"><code>library(dplyr)
library(tidyr)
library(Lahman)
# 拿到击球数据
career &lt;- Batting %&gt;%
  filter(AB &gt; 0) %&gt;%
  anti_join(Pitching, by = &quot;playerID&quot;) %&gt;%
  group_by(playerID) %&gt;%
  summarize(H = sum(H), AB = sum(AB)) %&gt;%
  mutate(average = H / AB)

# 把ID换成球员名字
career &lt;- Master %&gt;%
  tbl_df() %&gt;%
  select(playerID, nameFirst, nameLast) %&gt;%
  unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;%
  inner_join(career, by = &quot;playerID&quot;)
# 展示数据
career</code></pre>
<pre><code>## Source: local data frame [9,342 x 5]
## 
##     playerID              name     H    AB average
##        (chr)             (chr) (int) (int)   (dbl)
## 1  aaronha01        Hank Aaron  3771 12364  0.3050
## 2  aaronto01      Tommie Aaron   216   944  0.2288
## 3   abadan01         Andy Abad     2    21  0.0952
## 4  abadijo01       John Abadie    11    49  0.2245
## 5  abbated01    Ed Abbaticchio   772  3044  0.2536
## 6  abbotfr01       Fred Abbott   107   513  0.2086
## 7  abbotje01       Jeff Abbott   157   596  0.2634
## 8  abbotku01       Kurt Abbott   523  2044  0.2559
## 9  abbotod01        Ody Abbott    13    70  0.1857
## 10 abercda01 Frank Abercrombie     0     4  0.0000
## ..       ...               ...   ...   ...     ...</code></pre>
<pre class="r"><code># 击球前5
career %&gt;%
  arrange(desc(average)) %&gt;%
  head(5) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">playerID</th>
<th align="left">name</th>
<th align="right">H</th>
<th align="right">AB</th>
<th align="right">average</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">banisje01</td>
<td align="left">Jeff Banister</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">bassdo01</td>
<td align="left">Doc Bass</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">birasst01</td>
<td align="left">Steve Biras</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">1</td>
</tr>
<tr class="even">
<td align="left">burnscb01</td>
<td align="left">C. B. Burns</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">gallaja01</td>
<td align="left">Jackie Gallagher</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
</tr>
</tbody>
</table>
<pre class="r"><code># 击球后5
career %&gt;%
  arrange(average) %&gt;%
  head(5) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">playerID</th>
<th align="left">name</th>
<th align="right">H</th>
<th align="right">AB</th>
<th align="right">average</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">abercda01</td>
<td align="left">Frank Abercrombie</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">adamsla01</td>
<td align="left">Lane Adams</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">allenho01</td>
<td align="left">Horace Allen</td>
<td align="right">0</td>
<td align="right">7</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">allenpe01</td>
<td align="left">Pete Allen</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">alstowa01</td>
<td align="left">Walter Alston</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>如果仅考虑击球率会把很多板凳球员与运气球员包括进来，一个先验概率分布很有必要。那么考虑下如何得到，经验贝叶斯方法认为如果估计一个个体的参数，那么这个个体所在的整体的概率分布可作为先验概率分布。这个先验概率分布可以直接从数据的整体中得到，然后我们要用极大似然或矩估计的方法拿到贝塔分布的两个参数：</p>
<pre class="r"><code>career_filtered &lt;- career %&gt;%
    filter(AB &gt;= 500)

m &lt;- MASS::fitdistr(career_filtered$average, dbeta,
                    start = list(shape1 = 1, shape2 = 10))

alpha0 &lt;- m$estimate[1]
beta0 &lt;- m$estimate[2]

# 看下拟合效果

ggplot(career_filtered) +
  geom_histogram(aes(average, y = ..density..), binwidth = .005) +
  stat_function(fun = function(x) dbeta(x, alpha0, beta0), color = &quot;red&quot;,
                size = 1) +
  xlab(&quot;Batting average&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ebayes-1.png" alt="plot of chunk ebayes" />
<p class="caption">plot of chunk ebayes</p>
</div>
<p>当我们估计个人的击球率时，整体可以作为先验函数，个人的数据可以通过贝塔分布更新到个体。那么如果一个人数据少，我们倾向于认为他是平均水平；数据多则认为符合个人表现。这事实上是一个分层结构，贝叶斯推断里隐含了这么一个从整体到个人的过程</p>
<pre class="r"><code>career_eb &lt;- career %&gt;%
    mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0))
# 击球率高
career_eb %&gt;%
  arrange(desc(eb_estimate)) %&gt;%
  head(5) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">playerID</th>
<th align="left">name</th>
<th align="right">H</th>
<th align="right">AB</th>
<th align="right">average</th>
<th align="right">eb_estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">hornsro01</td>
<td align="left">Rogers Hornsby</td>
<td align="right">2930</td>
<td align="right">8173</td>
<td align="right">0.358</td>
<td align="right">0.355</td>
</tr>
<tr class="even">
<td align="left">jacksjo01</td>
<td align="left">Shoeless Joe Jackson</td>
<td align="right">1772</td>
<td align="right">4981</td>
<td align="right">0.356</td>
<td align="right">0.350</td>
</tr>
<tr class="odd">
<td align="left">delahed01</td>
<td align="left">Ed Delahanty</td>
<td align="right">2596</td>
<td align="right">7505</td>
<td align="right">0.346</td>
<td align="right">0.343</td>
</tr>
<tr class="even">
<td align="left">hamilbi01</td>
<td align="left">Billy Hamilton</td>
<td align="right">2158</td>
<td align="right">6268</td>
<td align="right">0.344</td>
<td align="right">0.340</td>
</tr>
<tr class="odd">
<td align="left">heilmha01</td>
<td align="left">Harry Heilmann</td>
<td align="right">2660</td>
<td align="right">7787</td>
<td align="right">0.342</td>
<td align="right">0.338</td>
</tr>
</tbody>
</table>
<pre class="r"><code># 击球率低
career_eb %&gt;%
  arrange(eb_estimate) %&gt;%
  head(5) %&gt;%
  kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">playerID</th>
<th align="left">name</th>
<th align="right">H</th>
<th align="right">AB</th>
<th align="right">average</th>
<th align="right">eb_estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">bergebi01</td>
<td align="left">Bill Bergen</td>
<td align="right">516</td>
<td align="right">3028</td>
<td align="right">0.170</td>
<td align="right">0.179</td>
</tr>
<tr class="even">
<td align="left">oylerra01</td>
<td align="left">Ray Oyler</td>
<td align="right">221</td>
<td align="right">1265</td>
<td align="right">0.175</td>
<td align="right">0.191</td>
</tr>
<tr class="odd">
<td align="left">vukovjo01</td>
<td align="left">John Vukovich</td>
<td align="right">90</td>
<td align="right">559</td>
<td align="right">0.161</td>
<td align="right">0.196</td>
</tr>
<tr class="even">
<td align="left">humphjo01</td>
<td align="left">John Humphries</td>
<td align="right">52</td>
<td align="right">364</td>
<td align="right">0.143</td>
<td align="right">0.196</td>
</tr>
<tr class="odd">
<td align="left">bakerge01</td>
<td align="left">George Baker</td>
<td align="right">74</td>
<td align="right">474</td>
<td align="right">0.156</td>
<td align="right">0.196</td>
</tr>
</tbody>
</table>
<pre class="r"><code># 整体估计
ggplot(career_eb, aes(average, eb_estimate, color = AB)) +
  geom_hline(yintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) +
  geom_point() +
  geom_abline(color = &quot;red&quot;) +
  scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5)) +
  xlab(&quot;Batting average&quot;) +
  ylab(&quot;Empirical Bayes batting average&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ebayes2-1.png" alt="plot of chunk ebayes2" />
<p class="caption">plot of chunk ebayes2</p>
</div>
<p>数据点多会收缩到<span class="math inline">\(x=y\)</span>，也就是个人的击球率；数据点少则回归到整体击球率。这就是经验贝叶斯方法的全貌：先估计整体的参数，然后把整体参数作为先验概率估计个人参数。</p>
</div>
<div class="section level2">
<h2>可信区间与置信区间</h2>
<p>经验贝叶斯可以给出点估计，但现实中我们可能更关心区间估计，也就是击球率的范围。一般这类区间估计可以用二项式比例估计来进行，不过没有先验经验的限制置信区间会大到没意义。经验贝叶斯会给出一个后验分布，这个分布可以用来求可信区间。</p>
<pre class="r"><code># 给出后验分布
career_eb &lt;- career %&gt;%
    mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0))
career_eb &lt;- career_eb %&gt;%
    mutate(alpha1 = H + alpha0,
           beta1 = AB - H + beta0)
# 提取洋基队的数据
yankee_1998 &lt;- c(&quot;brosisc01&quot;, &quot;jeterde01&quot;, &quot;knoblch01&quot;, &quot;martiti02&quot;, &quot;posadjo01&quot;, &quot;strawda01&quot;, &quot;willibe02&quot;)

yankee_1998_career &lt;- career_eb %&gt;%
    filter(playerID %in% yankee_1998)

# 展示球员的后验分布
library(broom)
yankee_beta &lt;- yankee_1998_career %&gt;%
    inflate(x = seq(.18, .33, .0002)) %&gt;%
    ungroup() %&gt;%
    mutate(density = dbeta(x, alpha1, beta1))

ggplot(yankee_beta, aes(x, density, color = name)) +
    geom_line() +
    stat_function(fun = function(x) dbeta(x, alpha0, beta0),
                  lty = 2, color = &quot;black&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ci-1.png" alt="plot of chunk ci" />
<p class="caption">plot of chunk ci</p>
</div>
<pre class="r"><code># 提取可信区间
yankee_1998_career &lt;- yankee_1998_career %&gt;%
    mutate(low  = qbeta(.025, alpha1, beta1),
           high = qbeta(.975, alpha1, beta1))
yankee_1998_career %&gt;%
    select(-alpha1, -beta1, -eb_estimate) %&gt;%
    knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">playerID</th>
<th align="left">name</th>
<th align="right">H</th>
<th align="right">AB</th>
<th align="right">average</th>
<th align="right">low</th>
<th align="right">high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">brosisc01</td>
<td align="left">Scott Brosius</td>
<td align="right">1001</td>
<td align="right">3889</td>
<td align="right">0.257</td>
<td align="right">0.244</td>
<td align="right">0.271</td>
</tr>
<tr class="even">
<td align="left">jeterde01</td>
<td align="left">Derek Jeter</td>
<td align="right">3465</td>
<td align="right">11195</td>
<td align="right">0.310</td>
<td align="right">0.300</td>
<td align="right">0.317</td>
</tr>
<tr class="odd">
<td align="left">knoblch01</td>
<td align="left">Chuck Knoblauch</td>
<td align="right">1839</td>
<td align="right">6366</td>
<td align="right">0.289</td>
<td align="right">0.277</td>
<td align="right">0.298</td>
</tr>
<tr class="even">
<td align="left">martiti02</td>
<td align="left">Tino Martinez</td>
<td align="right">1925</td>
<td align="right">7111</td>
<td align="right">0.271</td>
<td align="right">0.260</td>
<td align="right">0.280</td>
</tr>
<tr class="odd">
<td align="left">posadjo01</td>
<td align="left">Jorge Posada</td>
<td align="right">1664</td>
<td align="right">6092</td>
<td align="right">0.273</td>
<td align="right">0.262</td>
<td align="right">0.283</td>
</tr>
<tr class="even">
<td align="left">strawda01</td>
<td align="left">Darryl Strawberry</td>
<td align="right">1401</td>
<td align="right">5418</td>
<td align="right">0.259</td>
<td align="right">0.247</td>
<td align="right">0.270</td>
</tr>
<tr class="odd">
<td align="left">willibe02</td>
<td align="left">Bernie Williams</td>
<td align="right">2336</td>
<td align="right">7869</td>
<td align="right">0.297</td>
<td align="right">0.286</td>
<td align="right">0.305</td>
</tr>
</tbody>
</table>
<pre class="r"><code># 绘制可信区间
yankee_1998_career %&gt;%
    mutate(name = reorder(name, average)) %&gt;%
    ggplot(aes(average, name)) +
    geom_point() +
    geom_errorbarh(aes(xmin = low, xmax = high)) +
    geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) +
    xlab(&quot;Estimated batting average (w/ 95% interval)&quot;) +
    ylab(&quot;Player&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ci-2.png" alt="plot of chunk ci" />
<p class="caption">plot of chunk ci</p>
</div>
<pre class="r"><code># 对比置信区间与可信区间
career_eb &lt;- career_eb %&gt;%
    mutate(low = qbeta(.025, alpha1, beta1),
           high = qbeta(.975, alpha1, beta1))

set.seed(2016)

some &lt;- career_eb %&gt;%
    sample_n(20) %&gt;%
    mutate(name = paste0(name, &quot; (&quot;, H, &quot;/&quot;, AB, &quot;)&quot;))

frequentist &lt;- some %&gt;%
    group_by(playerID, name, AB) %&gt;%
    do(tidy(binom.test(.$H, .$AB))) %&gt;%
    select(playerID, name, estimate, low = conf.low, high = conf.high) %&gt;%
    mutate(method = &quot;Confidence&quot;)

bayesian &lt;- some %&gt;%
    select(playerID, name, AB, estimate = eb_estimate,
           low = low, high = high) %&gt;%
    mutate(method = &quot;Credible&quot;)

combined &lt;- bind_rows(frequentist, bayesian)

combined %&gt;%
    mutate(name = reorder(name, -AB)) %&gt;%
    ggplot(aes(estimate, name, color = method, group = method)) +
    geom_point() +
    geom_errorbarh(aes(xmin = low, xmax = high)) +
    geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) +
    xlab(&quot;Estimated batting average&quot;) +
    ylab(&quot;Player&quot;) +
    labs(color = &quot;&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ci-3.png" alt="plot of chunk ci" />
<p class="caption">plot of chunk ci</p>
</div>
<p>可信区间与置信区间（二项式比例估计）很大的区别在于前者考虑了先验概率进而实现了区间的收缩，后者则可看作无先验贝塔分布给出的区间估计，频率学派目前没有很好的收缩区间估计的方法。</p>
</div>
<div class="section level2">
<h2>后验错误率</h2>
<p>现实问题经常不局限于估计，而是侧重决策，例如如果一个球员的击球率高于某个值，他就可以进入名人堂（击球率大于0.3），这个决策常常伴随区间估计而不是简单的点估计：</p>
<pre class="r"><code># 以 Hank Aaron 为例
career_eb %&gt;%
    filter(name == &quot;Hank Aaron&quot;) %&gt;%
    do(data_frame(x = seq(.27, .33, .0002),
                  density = dbeta(x, .$alpha1, .$beta1))) %&gt;%
    ggplot(aes(x, density)) +
    geom_line() +
    geom_ribbon(aes(ymin = 0, ymax = density * (x &lt; .3)),
                alpha = .1, fill = &quot;red&quot;) +
    geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/lp-1.png" alt="plot of chunk lp" />
<p class="caption">plot of chunk lp</p>
</div>
<pre class="r"><code># 提取该球员数据
career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;)</code></pre>
<pre><code>## Source: local data frame [1 x 10]
## 
##    playerID       name     H    AB average eb_estimate alpha1 beta1   low
##       (chr)      (chr) (int) (int)   (dbl)       (dbl)  (dbl) (dbl) (dbl)
## 1 aaronha01 Hank Aaron  3771 12364   0.305       0.304   3850  8819 0.296
## Variables not shown: high (dbl)</code></pre>
<pre class="r"><code># 计算其不进入名人堂的概率
pbeta(.3, 3850, 8818)</code></pre>
<pre><code>## [1] 0.169</code></pre>
<p>这里我们引入后验错误率与后验包括率两个概念。后验错误率（Posterior Error Probability）可类比经典假设检验中的显著性水平<span class="math inline">\(\alpha\)</span>；后验包括率（Posterior Inclusion Probability）可类比经典假设检验中的置信水平<span class="math inline">\(1-\alpha\)</span></p>
<pre class="r"><code># 所有球员的后验错误率分布，大部分不超过0.3
career_eb &lt;- career_eb %&gt;%
    mutate(PEP = pbeta(.3, alpha1, beta1))
ggplot(career_eb, aes(PEP)) +
    geom_histogram(binwidth = .02) +
    xlab(&quot;Posterior Error Probability (PEP)&quot;) +
    xlim(0, 1)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ap-1.png" alt="plot of chunk ap" />
<p class="caption">plot of chunk ap</p>
</div>
<pre class="r"><code># 后验错误率与击球率的关系
career_eb %&gt;%
    ggplot(aes(eb_estimate, PEP, color = AB)) +
    geom_point(size = 1) +
    xlab(&quot;(Shrunken) batting average estimate&quot;) +
    ylab(&quot;Posterior Error Probability (PEP)&quot;) +
    geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3) +
    scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5))</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ap-2.png" alt="plot of chunk ap" />
<p class="caption">plot of chunk ap</p>
</div>
<p>后验错误率高于0.3的多数是击球率与击球数都高的人，因为经验贝叶斯方法惩罚了击球数低的人。</p>
</div>
<div id="fdr" class="section level2">
<h2>错误发现率（FDR）</h2>
<p>错误发现率可用来控制一个整体决策，保证整体犯错的概率低于某个数值，错误发现率越高，越可能把假阳性包括进来。假如我们把进入名人堂的决策作为一个整体，则可允许一定的整体错误率，因为每个人的后验错误率可以计算且期望值线性可加和，我们可以得到一个整体的错误率：</p>
<pre class="r"><code># 取前100个球员
top_players &lt;- career_eb %&gt;%
    arrange(PEP) %&gt;%
    head(100)
# 总错率率
sum(top_players$PEP)</code></pre>
<pre><code>## [1] 4.69</code></pre>
<pre class="r"><code># 平均错误率
mean(top_players$PEP)</code></pre>
<pre><code>## [1] 0.0469</code></pre>
<pre class="r"><code># 错误率随所取球员的变化
sorted_PEP &lt;- career_eb %&gt;%
    arrange(PEP)

mean(head(sorted_PEP$PEP, 50))</code></pre>
<pre><code>## [1] 0.00113</code></pre>
<pre class="r"><code>mean(head(sorted_PEP$PEP, 200))</code></pre>
<pre><code>## [1] 0.241</code></pre>
<p>错误率在排序后前面低后面高，但这个错误率不特指某个球员，而是包含到某个球员的整体犯错的概率。</p>
</div>
<div id="q" class="section level2">
<h2>q值</h2>
<p>q值定义为排序后累积到某个样本的整体平均错误率，类似多重比较中对整体错误率控制的p值。</p>
<pre class="r"><code># 生成每个球员的q值
career_eb &lt;- career_eb %&gt;%
    arrange(PEP) %&gt;%
    mutate(qvalue = cummean(PEP))
# 观察不同q值对名人堂球员数的影响
career_eb %&gt;%
    ggplot(aes(qvalue, rank(PEP))) +
    geom_line() +
    xlab(&quot;q-value cutoff&quot;) +
    ylab(&quot;Number of players included&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/qvalue-1.png" alt="plot of chunk qvalue" />
<p class="caption">plot of chunk qvalue</p>
</div>
<pre class="r"><code># 观察小q值部分
career_eb %&gt;%
    filter(qvalue &lt; .25) %&gt;%
    ggplot(aes(qvalue, rank(PEP))) +
    geom_line() +
    xlab(&quot;q-value cutoff&quot;) +
    ylab(&quot;Number of players included&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/qvalue-2.png" alt="plot of chunk qvalue" />
<p class="caption">plot of chunk qvalue</p>
</div>
<p>200个人进入名人堂可能有1/4的球员不合适，如果是50个人进入名人堂那么基本不会犯错。</p>
<p>q值是一个整体而非个体的平均错误率，具有累积性，不代表q值大的那一个就是错的。q值在频率学派的多重比较里也有定义，虽然没有空假设（有先验概率），但实质等同。</p>
</div>
<div class="section level2">
<h2>贝叶斯视角下的假设检验</h2>
<p>前面描述的是击球率如何求，如何进行区间估计与多个体的错误率控制，面向的个体或整体，那么如何解决比较问题。设想多个球员，我们考虑如何去比较他们击球率：</p>
<pre class="r"><code># 选三个球员
career_eb %&gt;%
  filter(name %in% c(&quot;Hank Aaron&quot;, &quot;Mike Piazza&quot;, &quot;Hideki Matsui&quot;)) %&gt;%
  inflate(x = seq(.26, .33, .00025)) %&gt;%
  mutate(density = dbeta(x, alpha1, beta1)) %&gt;%
  ggplot(aes(x, density, color = name)) +
  geom_line() +
  labs(x = &quot;Batting average&quot;, color = &quot;&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ht-1.png" alt="plot of chunk ht" />
<p class="caption">plot of chunk ht</p>
</div>
<p>如果两个球员击球率的概率密度曲线比较接近，那么即便均值有不同我们也无法进行区分；如果重叠比较少，那么我们有理由认为他们之间的差异显著。那么贝叶斯视角下如何定量描述这个差异是否显著？</p>
<div class="section level3">
<h3>模拟</h3>
<p>单纯取样比大小然后计算比例：</p>
<pre class="r"><code># 提取两人数据
aaron &lt;- career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;)
piazza &lt;- career_eb %&gt;% filter(name == &quot;Mike Piazza&quot;)
# 模拟取样10万次
piazza_simulation &lt;- rbeta(1e6, piazza$alpha1, piazza$beta1)
aaron_simulation &lt;- rbeta(1e6, aaron$alpha1, aaron$beta1)
# 计算一个人超过另一个人的概率
sim &lt;- mean(piazza_simulation &gt; aaron_simulation)
sim</code></pre>
<pre><code>## [1] 0.606</code></pre>
</div>
<div class="section level3">
<h3>数值积分</h3>
<p>两个概率的联合概率分布，然后积分一个球员大于另一个的概率：</p>
<pre class="r"><code>d &lt;- .00002
limits &lt;- seq(.29, .33, d)
sum(outer(limits, limits, function(x, y) {
  (x &gt; y) *
    dbeta(x, piazza$alpha1, piazza$beta1) *
    dbeta(y, aaron$alpha1, aaron$beta1) *
    d ^ 2
}))</code></pre>
<pre><code>## [1] 0.604</code></pre>
</div>
<div class="section level3">
<h3>解析解</h3>
<p>两个贝塔分布一个比另一个高是有含有贝塔函数的解析解的：</p>
<p><span class="math display">\[p_A \sim \mbox{Beta}(\alpha_A, \beta_A)\]</span></p>
<p><span class="math display">\[p_B \sim \mbox{Beta}(\alpha_B, \beta_B)\]</span></p>
<p><span class="math display">\[{\rm Pr}(p_B &gt; p_A) = \sum_{i=0}^{\alpha_B-1}\frac{B(\alpha_A+i,\beta_A+\beta_B)}{(\beta_B+i) B(1+i, \beta_B) B(\alpha_A, \beta_A) }\]</span></p>
<pre class="r"><code>h &lt;- function(alpha_a, beta_a,
              alpha_b, beta_b) {
  j &lt;- seq.int(0, round(alpha_b) - 1)
  log_vals &lt;- (lbeta(alpha_a + j, beta_a + beta_b) - log(beta_b + j) -
               lbeta(1 + j, beta_b) - lbeta(alpha_a, beta_a))
  1 - sum(exp(log_vals))
}

h(piazza$alpha1, piazza$beta1,
  aaron$alpha1, aaron$beta1)</code></pre>
<pre><code>## [1] 0.605</code></pre>
</div>
<div class="section level3">
<h3>正态近似求解</h3>
<p>贝塔分布在<span class="math inline">\(\alpha\)</span>与<span class="math inline">\(\beta\)</span>比较大时接近正态分布，可以直接用正态分布的解析解求，速度快很多：</p>
<pre class="r"><code>h_approx &lt;- function(alpha_a, beta_a,
                     alpha_b, beta_b) {
  u1 &lt;- alpha_a / (alpha_a + beta_a)
  u2 &lt;- alpha_b / (alpha_b + beta_b)
  var1 &lt;- alpha_a * beta_a / ((alpha_a + beta_a) ^ 2 * (alpha_a + beta_a + 1))
  var2 &lt;- alpha_b * beta_b / ((alpha_b + beta_b) ^ 2 * (alpha_b + beta_b + 1))
  pnorm(0, u2 - u1, sqrt(var1 + var2))
}

h_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1)</code></pre>
<pre><code>## [1] 0.606</code></pre>
</div>
</div>
<div class="section level2">
<h2>比例检验</h2>
<p>这是个列联表问题，频率学派对比两个比例：</p>
<pre class="r"><code>two_players &lt;- bind_rows(aaron, piazza)

two_players %&gt;%
  transmute(Player = name, Hits = H, Misses = AB - H) %&gt;%
  knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">Player</th>
<th align="right">Hits</th>
<th align="right">Misses</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Hank Aaron</td>
<td align="right">3771</td>
<td align="right">8593</td>
</tr>
<tr class="even">
<td align="left">Mike Piazza</td>
<td align="right">2127</td>
<td align="right">4784</td>
</tr>
</tbody>
</table>
<pre class="r"><code>prop.test(two_players$H, two_players$AB)</code></pre>
<pre><code>## 
##  2-sample test for equality of proportions with continuity
##  correction
## 
## data:  two_players$H out of two_players$AB
## X-squared = 0.1, df = 1, p-value = 0.7
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.0165  0.0109
## sample estimates:
## prop 1 prop 2 
##  0.305  0.308</code></pre>
<p>贝叶斯学派对比两个比例：</p>
<pre class="r"><code>credible_interval_approx &lt;- function(a, b, c, d) {
  u1 &lt;- a / (a + b)
  u2 &lt;- c / (c + d)
  var1 &lt;- a * b / ((a + b) ^ 2 * (a + b + 1))
  var2 &lt;- c * d / ((c + d) ^ 2 * (c + d + 1))

  mu_diff &lt;- u2 - u1
  sd_diff &lt;- sqrt(var1 + var2)

  data_frame(posterior = pnorm(0, mu_diff, sd_diff),
             estimate = mu_diff,
             conf.low = qnorm(.025, mu_diff, sd_diff),
             conf.high = qnorm(.975, mu_diff, sd_diff))
}

credible_interval_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1)</code></pre>
<pre><code>## Source: local data frame [1 x 4]
## 
##   posterior estimate conf.low conf.high
##       (dbl)    (dbl)    (dbl)     (dbl)
## 1     0.606 -0.00182  -0.0151    0.0115</code></pre>
<p>多个球员对比一个：</p>
<pre class="r"><code>set.seed(2016)

intervals &lt;- career_eb %&gt;%
  filter(AB &gt; 10) %&gt;%
  sample_n(20) %&gt;%
  group_by(name, H, AB) %&gt;%
  do(credible_interval_approx(piazza$alpha1, piazza$beta1, .$alpha1, .$beta1)) %&gt;%
  ungroup() %&gt;%
  mutate(name = reorder(paste0(name, &quot; (&quot;, H, &quot; / &quot;, AB, &quot;)&quot;), -estimate))
f &lt;- function(H, AB) broom::tidy(prop.test(c(H, piazza$H), c(AB, piazza$AB)))
prop_tests &lt;- purrr::map2_df(intervals$H, intervals$AB, f) %&gt;%
  mutate(estimate = estimate1 - estimate2,
         name = intervals$name)

all_intervals &lt;- bind_rows(
  mutate(intervals, type = &quot;Credible&quot;),
  mutate(prop_tests, type = &quot;Confidence&quot;)
)

ggplot(all_intervals, aes(x = estimate, y = name, color = type)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) +
  xlab(&quot;Piazza average - player average&quot;) +
  ylab(&quot;Player&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/mp-1.png" alt="plot of chunk mp" />
<p class="caption">plot of chunk mp</p>
</div>
<p>由此，置信区间与可信区间的主要差异来自于经验贝叶斯的区间收敛，也就是对整体先验概率的考虑。</p>
</div>
<div class="section level2">
<h2>错误率控制</h2>
<p>如果我打算交易一个球员，那么如何筛选候选人？肯定是先选那些击球率更好的球员：</p>
<pre class="r"><code># 对比打算交易的球员与其他球员
career_eb_vs_piazza &lt;- bind_cols(
  career_eb,
  credible_interval_approx(piazza$alpha1, piazza$beta1,
                           career_eb$alpha1, career_eb$beta1)) %&gt;%
  select(name, posterior, conf.low, conf.high)

career_eb_vs_piazza</code></pre>
<pre><code>## Source: local data frame [9,342 x 4]
## 
##                    name posterior conf.low conf.high
##                   (chr)     (dbl)    (dbl)     (dbl)
## 1        Rogers Hornsby  2.84e-11   0.0345    0.0639
## 2          Ed Delahanty  7.10e-07   0.0218    0.0518
## 3  Shoeless Joe Jackson  8.77e-08   0.0278    0.0611
## 4         Willie Keeler  4.62e-06   0.0183    0.0472
## 5            Nap Lajoie  1.62e-05   0.0158    0.0441
## 6            Tony Gwynn  1.83e-05   0.0157    0.0442
## 7        Harry Heilmann  7.19e-06   0.0180    0.0476
## 8            Lou Gehrig  1.43e-05   0.0167    0.0461
## 9        Billy Hamilton  7.03e-06   0.0190    0.0502
## 10        Eddie Collins  2.00e-04   0.0113    0.0393
## ..                  ...       ...      ...       ...</code></pre>
<pre class="r"><code># 计算q值
career_eb_vs_piazza &lt;- career_eb_vs_piazza %&gt;%
  arrange(posterior) %&gt;%
  mutate(qvalue = cummean(posterior))

# 筛选那些q值小于0.05的
better &lt;- career_eb_vs_piazza %&gt;%
  filter(qvalue &lt; .05)

better</code></pre>
<pre><code>## Source: local data frame [50 x 5]
## 
##                    name posterior conf.low conf.high   qvalue
##                   (chr)     (dbl)    (dbl)     (dbl)    (dbl)
## 1        Rogers Hornsby  2.84e-11   0.0345    0.0639 2.84e-11
## 2  Shoeless Joe Jackson  8.77e-08   0.0278    0.0611 4.39e-08
## 3          Ed Delahanty  7.10e-07   0.0218    0.0518 2.66e-07
## 4         Willie Keeler  4.62e-06   0.0183    0.0472 1.36e-06
## 5        Billy Hamilton  7.03e-06   0.0190    0.0502 2.49e-06
## 6        Harry Heilmann  7.19e-06   0.0180    0.0476 3.27e-06
## 7            Lou Gehrig  1.43e-05   0.0167    0.0461 4.85e-06
## 8            Nap Lajoie  1.62e-05   0.0158    0.0441 6.28e-06
## 9            Tony Gwynn  1.83e-05   0.0157    0.0442 7.62e-06
## 10           Bill Terry  3.03e-05   0.0162    0.0472 9.89e-06
## ..                  ...       ...      ...       ...      ...</code></pre>
<p>这样我们筛到一个可交易的群体，总和错误率不超过5%。</p>
</div>
<div class="section level2">
<h2>影响因子</h2>
<p>击球率高还有可能是因为得到的机会多或者光环效应，一开始凭运气打得好，后面给机会多，通过经验累积提高了击球率：</p>
<pre class="r"><code>career %&gt;%
  filter(AB &gt;= 20) %&gt;%
  ggplot(aes(AB, average)) +
  geom_point() +
  geom_smooth(method = &quot;lm&quot;, se = FALSE) +
  scale_x_log10()</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/if-1.png" alt="plot of chunk if" />
<p class="caption">plot of chunk if</p>
</div>
<p>击球数低方差会大，这比较正常，很多人挂在起跑线上了。直接使用经验贝叶斯方法会导致整体向均值收敛，这高估了新手的数据：</p>
<pre class="r"><code>prior_mu &lt;- alpha0 / (alpha0 + beta0)
career_eb %&gt;%
  filter(AB &gt;= 20) %&gt;%
  gather(type, value, average, eb_estimate) %&gt;%
  mutate(type = plyr::revalue(type, c(average = &quot;Raw&quot;,
                                      eb_estimate = &quot;With EB Shrinkage&quot;))) %&gt;%
  ggplot(aes(AB, value)) +
  geom_point() +
  scale_x_log10() +
  geom_hline(color = &quot;red&quot;, lty = 2, size = 1.5, yintercept = prior_mu) +
  facet_wrap(~type) +
  ylab(&quot;average&quot;) +
    geom_smooth(method = &quot;lm&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/ife-1.png" alt="plot of chunk ife" />
<p class="caption">plot of chunk ife</p>
</div>
<p>为了如实反应这种情况，我们应该认为击球率符合贝塔分布，但同时贝塔分布的两个参数受击球数的影响，击球数越多，越可能击中。这个模型可以用贝塔－二项式回归来描述：</p>
<p><span class="math display">\[\mu_i = \mu_0 + \mu_{\mbox{AB}} \cdot \log(\mbox{AB})\]</span></p>
<p><span class="math display">\[\alpha_{0,i} = \mu_i / \sigma_0\]</span></p>
<p><span class="math display">\[\beta_{0,i} = (1 - \mu_i) / \sigma_0\]</span></p>
<p><span class="math display">\[p_i \sim \mbox{Beta}(\alpha_{0,i}, \beta_{0,i})\]</span></p>
<p><span class="math display">\[H_i \sim \mbox{Binom}(\mbox{AB}_i, p_i)\]</span></p>
<div class="section level3">
<h3>拟合模型</h3>
<p>寻找拟合后的模型参数，构建新的先验概率：</p>
<pre class="r"><code>library(gamlss)
# 拟合模型
fit &lt;- gamlss(cbind(H, AB - H) ~ log(AB),
              data = career_eb,
              family = BB(mu.link = &quot;identity&quot;))</code></pre>
<pre><code>## GAMLSS-RS iteration 1: Global Deviance = 91083 
## GAMLSS-RS iteration 2: Global Deviance = 72051 
## GAMLSS-RS iteration 3: Global Deviance = 67972 
## GAMLSS-RS iteration 4: Global Deviance = 67966 
## GAMLSS-RS iteration 5: Global Deviance = 67966</code></pre>
<pre class="r"><code>library(broom)
# 展示拟合参数
td &lt;- tidy(fit)
td</code></pre>
<pre><code>##   parameter        term estimate std.error statistic p.value
## 1        mu (Intercept)   0.1441  0.001616      89.1       0
## 2        mu     log(AB)   0.0151  0.000221      68.5       0
## 3     sigma (Intercept)  -6.3372  0.024910    -254.4       0</code></pre>
<pre class="r"><code># 构建新的先验概率
mu_0 &lt;- td$estimate[1]
mu_AB &lt;- td$estimate[2]
sigma &lt;- exp(td$estimate[3])

# 看看AB对先验概率的影响
crossing(x = seq(0.08, .35, .001), AB = c(1, 10, 100, 1000, 10000)) %&gt;%
  mutate(density = dbeta(x, (mu_0 + mu_AB * log(AB)) / sigma,
                         (1 - (mu_0 + mu_AB * log(AB))) / sigma)) %&gt;%
  mutate(AB = factor(AB)) %&gt;%
  ggplot(aes(x, density, color = AB, group = AB)) +
  geom_line() +
  xlab(&quot;Batting average&quot;) +
  ylab(&quot;Prior density&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/fitbb-1.png" alt="plot of chunk fitbb" />
<p class="caption">plot of chunk fitbb</p>
</div>
</div>
<div class="section level3">
<h3>求后验概率</h3>
<pre class="r"><code># 计算所有拟合值
mu &lt;- fitted(fit, parameter = &quot;mu&quot;)
sigma &lt;- fitted(fit, parameter = &quot;sigma&quot;)
# 计算所有后验概率
career_eb_wAB &lt;- career_eb %&gt;%
  dplyr::select(name, H, AB, original_eb = eb_estimate) %&gt;%
  mutate(mu = mu,
         alpha0 = mu / sigma,
         beta0 = (1 - mu) / sigma,
         alpha1 = alpha0 + H,
         beta1 = beta0 + AB - H,
         new_eb = alpha1 / (alpha1 + beta1))
# 展示拟合后的击球率
ggplot(career_eb_wAB, aes(original_eb, new_eb, color = AB)) +
  geom_point() +
  geom_abline(color = &quot;red&quot;) +
  xlab(&quot;Original EB Estimate&quot;) +
  ylab(&quot;EB Estimate w/ AB term&quot;) +
  scale_color_continuous(trans = &quot;log&quot;, breaks = 10 ^ (0:4))</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/fitpo-1.png" alt="plot of chunk fitpo" />
<p class="caption">plot of chunk fitpo</p>
</div>
<pre class="r"><code># 对比
library(tidyr)

lev &lt;- c(raw = &quot;Raw H / AB&quot;, original_eb = &quot;EB Estimate&quot;, new_eb = &quot;EB w/ Regression&quot;)

career_eb_wAB %&gt;%
  filter(AB &gt;= 10) %&gt;%
  mutate(raw = H / AB) %&gt;%
  gather(type, value, raw, original_eb, new_eb) %&gt;%
  mutate(mu = ifelse(type == &quot;original_eb&quot;, prior_mu,
                     ifelse(type == &quot;new_eb&quot;, mu, NA))) %&gt;%
  mutate(type = factor(plyr::revalue(type, lev), lev)) %&gt;%
  ggplot(aes(AB, value)) +
  geom_point() +
  geom_line(aes(y = mu), color = &quot;red&quot;) +
  scale_x_log10() +
  facet_wrap(~type) +
  xlab(&quot;At-Bats (AB)&quot;) +
  ylab(&quot;Estimate&quot;)</code></pre>
<div class="figure">
<img src="http://yufree.github.io/blogcn/figure/fitpo-2.png" alt="plot of chunk fitpo" />
<p class="caption">plot of chunk fitpo</p>
</div>
<p>矫正后我们的数据更复合现实了，其实这是贝叶斯分层模型的一个简单版本，通过考虑更多因素，我们可以构建更复杂的模型来挖掘出我们所需要的信息。</p>
</div>
</div>
