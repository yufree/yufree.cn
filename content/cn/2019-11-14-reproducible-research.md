---
title: 可重复性研究的框架
author: ''
date: '2019-11-14'
slug: reproducible-research
categories: []
tags:
  - sci
---

实验结果的可重复性研究不是个新鲜概念，上个世纪就开始有讨论了，最早是心理学，现在已经蔓延到多个学科。但可重复性研究的流程其实比想象的要复杂，完整的可重复性研究包含多个步骤，例如人群可重复性、科学问题是否一致、假设是否一致、实验设计是否一致、实验人员是否一致、数据分析流程是否一致、代码是否可公开、推断的合理性与结论是否一致。新闻里常说的可重复性不好主要是最后一项结论的差异，但整体流程的任何一个环节都可能出问题。而且，原始报道者也常常用实验设计不一致、科学问题不一致等理由来解释两组实验结果的差异，那么有没有一个更好的评价框架？

![img](https://yufree.github.io/sciguide/sciguide_files/figure-html/unnamed-chunk-1-1.png)

有，当前在可重复性研究中目前比较可行的是自数据收集以下的可重复性，也就是可重复计算的部分。如果这部分有问题，那么前面也就不用看了，而且前面就用的原始作者的设计，也不会出现来自原始作者的质疑。这部分验证的成本相比全流程实验验证要低很多，对原始实验的报告者的要求也比较低，就是数据与代码公开，在我看来这会是一个切实可行的趋势。那么是不是作者公布了原始代码与数据就够了呢？

也有问题。如果一组实验重复了二十次才看到一次阳性结果，那么只报道这一次阳性结果而隐藏十九次的探索过程是有问题的，从p值角度看甚至就是随机事件。实验学科的很多研究生经常或主动或被迫尝试一些新想法，此时几次不出结果就该考虑这想法是不是靠谱了，起码机械重复出的阳性结果在多次探索下已经不再可靠。但当前学术界的一些评价体制导致研究人员可能选择性报道自己探索出的成果，也就是发表歧视，其实对于读者而言，有价值的信息往往不是你怎么成功，而是你踩过哪些坑，没有坑的信息一方面你的结果不好重复验证损失影响力，另一方面我们丢失了太多探索细节与新发现的机会。因此，在实验可重复性计算的部分，我们需要研究者同样报道自己探索性实验记录，或者起码是可以电子化随时实名查阅的。然而，大量选择性报道可能出现一个副作用，论文的讨论很多是依赖引文，如果引文结果不靠谱，那么后续研究只有同样采用了选择性报道才能继续跟进发表，最后形成一种确认偏误，这情况比想象的要常见。甚至在系统综述过程中，对确认偏误的忽略可能通过结论影响决策者，那就成了一种自我实现。那么有了探索性实验记录是不是就够了呢？

还是不够。当前科研属于“定语”科研，由于各学科基础理论已经相对完善，很多新发现都是建立在一些特殊控制条件下的。然而，当你进行条件控制时，其实又掉到了高维诅咒的坑里。打比方我做了一组实验，最后发现某种药在A条件B参数面对C人群中D年龄分组里是有效的。那么问题来了，假设ABCD全是互斥的二元变量，那么我这个结果实际上是做了16次对比得到了一次显著性结果。然而，如果我们采用p值，那么16次随机假设检验里出现一次p值小于0.05的概率是0.56，也就是说这个结果在完全随机状态下也有一半可能发生。其实可靠性跟p值没关系，最终是跟样本量挂钩，如果你的满足条件的目标样本很大，那这个结果很可能就是对的。相反，如果这个结果是来自于小样本，虽然根据多元模型是显著的，但具体到这个条件下其实就几个样本，此时结果就不能算靠谱。探索性数据分析通常会面对这个无穷假设困境，当你不断引入协变量后，维度的增加导致样本实际是稀疏欠拟合的，最后看到现象可能就是假象。因此对于此类“定语”科研，我们会要求定语条件下的样本量必须够多，否则就需要其他证据来说明现象。那么符合了样本量要求是否够了呢？

依然不够。不同的统计模型会产生不同的假设检验结果，研究人员通常只会报道那些有阳性结果的统计模型。这个非常难识别，因为统计模型通常比较复杂且研究人员有可能是先上船后买票，也就是先发现这个模型结果有利然后根据模型组织文章。这里面会牵扯到探索性数据分析与论证的差异，如果研究人员把新模型当成了文章亮点，那读者是完全看不出来这里面的不恰当行为的。此时还是需要把探索性数据分析的流程也进行公开，如果大家都能下载到数据，标准化后然后同时跑多个模型，只有共存结果才有可能可靠。不过，这里面的问题在于多个模型的假设是不一样的，只有符合数据本身统计特征的模型才能被加入到评价体系里。在这里有个要求就是分析流程脚本化，这也是我长期以来一直反对使用图形界面数据分析软件的原因，如果你的图形探索流程可以脚本化也没什么，但仅仅说我用了某某软件是完全不够的。那么公开数据探索脚本对研究可重复性是不是够了呢？

当然还不够。科学本身是构建在错误校正过程上的，但科学家评价却是人性化的，良好的评价很多时候成了科学家追求的标的。不论是对影响因子的追求还是学术明星的打造，非科学的评价与评优其实影响到了科研结果的报道。科学家正在作为一个团体来维护自己的利益与社会地位，其副作用就是对失败的低容忍度，年龄限制与成果限制使得探索必须要符合效率原则，很多年轻人在年富力强的时候做了大量排列组合而非探索性的工作来确保个人的生存无虞，这样造成的损失目前我们无法衡量。随之伴生的学术不规范、不端与造假则是层出不穷，很多人开始利用一些规则上的漏洞来实现非科研目的，例如审稿流程与评优。科学家的形象要由团体的文化来体现，阳光底下没有新鲜事，除了开放获取的研究成果，研究整体流程也应该实现透明化，这样可以很大程度防止暗箱操作。

所以应对可重复性的问题，我们需要透明化科研流程，从基金申请到修改到进度报告到结题报告到文章的投稿接受与后续跟进研究及评优都要有公开的记录可以查询，文书都要经过版本控制方便返溯，所有研究人员都要实名负责对应的项目。学术团体接受公众舆论监督与同行监督，日常学术交流也要有公开的记录与反馈机制，所有的记录不直接对外公开但接受实名查询并留存查询记录。这样透明化的流程可以保证学术团体除了发表论文之外还有其他的结果展示途径，进而避免实验结果的选择性汇报与资源的过度集中。打破自我包装与人脉对科研的束缚，让结果更直白地展示给所有人。此外，关于可重复性，nature就近年来的科研可重复性危机采访了五组科学家，分别从认知、NHST、FDR、数据共享与范式转化的角度进行了[论述](https://www.nature.com/articles/d41586-017-07522-z)，值得一读。在医疗领域也有了一些有意思的讨论，例如认为基于人群的归纳式诊断会被个性化精准医疗所替代，此时可重复性里内含的平均律就会被彻底颠覆，分子水平的因果逻辑可能成为未来的主要知识探索方向。预印本、开放获取与审稿、科研社交媒体及数据共享等新[趋势](https://theoreticalecology.wordpress.com/2019/01/22/tree-species-richness-and-its-effects-on-productivity-neither-global-nor-consistent/)也孕育着新的问题解决方法。其实结果不可重复或者错误对于科学探索而言是可接受的，不然就不会有新知识的出现，但因非学术目的掩盖错误与选择报道实验结果就属于学术不端了。

可重复性研究的明天是建立在今天的基础之上的，在流程透明的明天，谁在裸泳一目了然。