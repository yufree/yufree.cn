---
title: 纽约暴露组学研讨会纪要
author: ''
date: '2020-03-08'
slug: nyc-exposome-symposium
categories: []
tags:
  - conf
  - life
---

作为一个中老年人，开会越来越记不住东西了，这周周四周五在纽约参加了我们研究所主办的纽约暴露组学研讨会，现在做个纪要。

首先，我得说下背景，不是暴露组学的背景，而是这两天纽约新冠开始爆发，纽约目前医疗资源只够重症患者，而轻症是强制隔离的，街上会有戴口罩的但不多，超市价格至少上东区跟东哈莱姆区超市日常用品价格变化不大，整体看就是政府跟民众都不当回事，反倒是华埠、布鲁克林八大道还有法拉盛等华裔社区会出现冷清状况。我的感觉就是得把自己当感染者看待，然后依赖年龄优势不去想后果，政府完全指望不上，试纸短缺、医用资源短缺已经无法获得准确的数字。目前能上试纸的需要符合三种情况：有症状且有旅行史、有症状且有确诊接触史还有重症患者，也就是说，社区感染除非你发展到重症，否则最多就是隔离，试纸都不会给你测。且不论纽约的人口密度远高于大农村，即便是大农村，周末的教会聚集也会缩短传播途径，我很好奇的是不论香港的佛舍、伊朗的圣地还是韩国的邪教，宗教这种常规高风险聚集在几乎所有政府都避而不谈不提预警，搞个远程讲经不也挺好，佛陀、默罕默德或耶稣也不想信众在宗教生活中冒险吧？总之，在这个背景下开学术会议一定是有额外风险的，我个人会觉得无所谓但不见得每个人都乐意冒险，但现代社会的计划性是内生的，对外部风险通常不考虑，不能退票的低价机票与预付款都透支了对未来风险的应变能力，很多人买了票但又不甘心退票的损失，后果就是风险更高，美国的至尊公主号竟然在二月初疫情已经出现的前提下照常出航，后果就是现在加州满地图的社区传播。有人认为病死率可能不高，就是个大流感，不应过分反应，但你仔细去看看中国除了湖北的病死率数据，其实是在逐渐上升的，这个肺炎的病程与传播能力都不能当流感来对待，流感重症率大概只有百分之一而这个有近20%，病死率也至少高流感一个数量级。当然，你要非说数据是假的不全我也没办法，很多人只相信自己认为正确的数据，包括我在内，我可以在某种价值观下啥反对数据都怀疑为假，但观点永远不能替代事实，用观点替代事实来传播不是蠢就是坏。

还是聊会议，暴露组学从一开始就算很坎坷，2005年提出的概念在五年内没有任何文章跟进，到了2010年才陆续有人关注非遗传因素对疾病的贡献，即使到了今天，大红大紫的基因组学也在向公众灌输基因对疾病或行为的决定性作用。基因组学其实也就比暴露组概念早个十年二十年，也同样经历了初期的无人问津与后面的爆发。这里面最重要的驱动因素其实还是分析技术，有了定性定量指标，概念才能落地被科学实验所检验。暴露组学的技术推动我认为有三个方面，一个是高分辨质谱、一个是遥感卫星数据、另一个则是可穿戴设备。质谱技术让化学污染的暴露可以定性定量找到源头物质，遥感卫星数据让大尺度空气污染暴露脱离了监测站点的限制而可穿戴设备让实时监测成了可能。当然这一切都要依赖数据科学提供了数据处理与分析的通用框架。在点突破的前提下，传统学科例如预防医学、流行病学、环境监测、生物信息学、心理学等都很快融合到暴露组学的框架里去围绕一个行为或疾病进行多角度考察。

那么今年又有哪些新动向呢？NIEHS的前主任 Linda Birnbaum 博士与 Rice University 的Marie Lynn Miranda 教授认为，数据共享与透明化很重要，需要有良好的平台来支持 reproducible research，这也是我头一次在学术会议的报告里听到有人把这个问题放到台面上来说。不得不说这是一个很好的信号，各人玩各人的灌水游戏是需要一些规范了。

我们系主任 Robert Wright 教授则提出了另一个问题，那就是暴露组学与精准医疗的关系，暴露组学重在解释而精准医疗重在药物研发与治疗，作为小领域，暴露组还没发展到影响精准医疗的程度，而精准医疗则压根就没搭理过暴露组学，目前绝大多数精准医疗是基于基因而非环境暴露来做的。其实如果环境暴露是疾病的主要因素的话，精准医疗的手段就不仅仅是靶向药物，而可以是包含生活方式改变在内的各种治疗手段，例如有个案例是一个家庭两个孩子里上学的大孩子经常容易发怒而4岁的小孩子就没有问题，后来发现是印刷品中的铅主导了这个过程，4岁的小孩子不出现问题是因为不认字，这种问题你去做基因检测啥也不会测出来，当然也存在基因易感性问题。所以暴露组学的长期发展一定会从为什么走到怎么办的阶段，这时候精准医疗就是很好的出口。

我们实验室主任 Manish Arora 教授则提出了环境生物动力学的概念，其实很多之前的报告都涵盖了这个趋势，那就是暴露组学要做时序追踪，用个忽悠点的概念就是需要4D数据。所谓环境生物动力学其实就是对疾病的动力学过程进行追踪，例如某种污染物暴露在疾病不同阶段的水平与关系而不仅仅就是病人与对照组来回分类。有意思的是，他管这种纵向数据叫做 deep data 来区分 big data，天下忽悠是一家，不过新名词对于学科发展还是有积极意义的。但说白了就是把分析流行病学进行整合，只是目前学科间术语墙还是比较难打通，人家用SAS，你用R，光是数据接口与格式就够折腾半天的。

今年有大概四个报告是关于遥感数据的，我也是刚意识到遥感那块目前的进步已经很可观了。其对大气污染的监控已经不再是全部，跟社交网络数据、地学数据等的融合已经相对成熟，其实很多概念我看着并不陌生，前些年R语言会议就有人提到类似项目，不过业界或互联网公司去做这个科学功底并不够，很多背景知识程序员们不知道。时至今日，我还是更倾向于带着问题学编程而不是先学编程后找问题，因为现实问题的复杂性不是做个抽象可视化就完事的，而是建立在对问题的多角度思考之上，先接触实际问题比在理论上磨洋工要更有利于问题的解决。印象中有个报告提到了21世纪的3C问题，Climate、Chemical与City，我觉得总结非常到位，这三个问题都是20世纪出现但影响不大不过21世纪需要解决的问题，气候变化、化学品暴露与城市化，每个问题背后都是当前正在发生的事实，确实需要解决方案。

关于非目的分析的报告其实新意不多，但公认物质峰鉴定是瓶颈，也终于明白了质谱峰数目跟物质数目不是一回事的事实。其中，耶鲁的一个报告所使用的非目的分析与目的性筛查配合可穿戴设备的报告倒是个挺不错的故事。很多人都说非目的分析包含目的分析，但验证工作其实做的不多，例如从非目的分析数据里能不能把目的分析的污染物在没有标准的情况下提取出来，其实做的人不多。我自己的经验是这个活一般都是仪器软件能做的，但全扫描的灵敏度损失是很大的，开源的工作流确实有必要做一个。这目的性筛查的活我有空可以在 R 里面实现一下，毕竟我可能是为数不多的对PBDEs的183种异构体都做过分析的人，而PBDEs一共就209种。

总之，这个会议还是属于小规模研讨会，暴露组学也依旧处于研究初期，但能看到新的思考与达成共识的问题就说明下一步可能会更好。

