---
title: 差异分析与主成分分析悖论
author: Miao Yu
date: '2023-10-07'
slug: da-pca-paradox
categories: []
tags:
  - data
---



<p>这是我最近研究工作中遇到的一个有趣现象：有一组含对照与控制样本的多维数据在主成分分析里没有看到差异，但进行差异分析时发现几乎所有维度上都有差异。这就会形成解释数据上的悖论：如果我用主成分分析来进行探索式数据分析，会认为对照组与控制组很难区分；但如果我用单一维度的差异分析去对比，即使经过错误发现率控制，在绝大多数维度上都能看到差异。这里的问题在于，因为你每个维度上都显示了差异，按说整体降维后可视化差异应该很明显才对。那么，这两组数据究竟算有差异还是没差异？</p>
<p>这里我用模拟仿真来重现下这个问题。首先，我们模拟两组数据，对照组与控制组均有100维，都存在1.2倍均值差异，每组十万个点：</p>
<pre class="r"><code>library(genefilter)
# 100个维度
np &lt;- rnorm(100,100,100)
z &lt;- c()
for(i in 1:100){
  case &lt;- rnorm(100000,mean = np[i],sd=abs(np[i])*0.1+1)
  control &lt;- rnorm(100000,mean=np[i]*1.2,sd=abs(np[i])*0.1+1)
  zt &lt;- c(case,control)
  z &lt;- cbind(z,zt)
}</code></pre>
<p>我们来看下主成分分析结果：</p>
<pre class="r"><code>pca &lt;- prcomp(z)
# 主成分贡献
summary(pca)$importance[,c(1:10)]</code></pre>
<pre><code>##                             PC1      PC2     PC3      PC4      PC5      PC6
## Standard deviation     143.6913 32.46544 28.8205 27.75735 27.16693 26.65109
## Proportion of Variance   0.4821  0.02461  0.0194  0.01799  0.01723  0.01659
## Cumulative Proportion    0.4821  0.50672  0.5261  0.54411  0.56134  0.57793
##                             PC7      PC8      PC9     PC10
## Standard deviation     26.29228 25.84211 25.22661 24.53475
## Proportion of Variance  0.01614  0.01559  0.01486  0.01406
## Cumulative Proportion   0.59407  0.60966  0.62452  0.63858</code></pre>
<pre class="r"><code>plot(pca$x[,1],pca$x[,2],pch=19,col=c(rep(1,100000),rep(2,100000)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>colnames(z) &lt;- 1:ncol(z)
re &lt;- colttests(z,factor(c(rep(1,100000),rep(2,100000))))
re$adj &lt;- p.adjust(re$p.value,&#39;BH&#39;)
sum(re$adj&lt;0.05)</code></pre>
<pre><code>## [1] 100</code></pre>
<p>很明显差异。下面我们要做些变化：</p>
<pre class="r"><code>z &lt;- c()
for(i in 1:100){
  case &lt;- rnorm(100000,mean = np[i],sd=abs(np[i])*0.5+1)
  control &lt;- rnorm(100000,mean=np[i]*1.2,sd=abs(np[i])*0.5+1)
  zt &lt;- c(case,control)
  z &lt;- cbind(z,zt)
}
pca &lt;- prcomp(z)
# 主成分贡献
summary(pca)$importance[,c(1:10)]</code></pre>
<pre><code>##                              PC1       PC2       PC3       PC4       PC5
## Standard deviation     183.27851 155.32810 139.39841 134.50982 131.62684
## Proportion of Variance   0.06263   0.04499   0.03623   0.03374   0.03231
## Cumulative Proportion    0.06263   0.10762   0.14386   0.17759   0.20990
##                             PC6       PC7       PC8       PC9     PC10
## Standard deviation     129.3622 127.52456 124.78930 121.69614 118.3017
## Proportion of Variance   0.0312   0.03032   0.02904   0.02762   0.0261
## Cumulative Proportion    0.2411   0.27143   0.30046   0.32808   0.3542</code></pre>
<pre class="r"><code>plot(pca$x[,1],pca$x[,2],pch=19,col=c(rep(1,100000),rep(2,100000)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code>colnames(z) &lt;- 1:ncol(z)
re &lt;- colttests(z,factor(c(rep(1,100000),rep(2,100000))))
re$adj &lt;- p.adjust(re$p.value,&#39;BH&#39;)
sum(re$adj&lt;0.05)</code></pre>
<pre><code>## [1] 100</code></pre>
<p>目前差异已经开始互相融合了，好，进一步加大力度。</p>
<pre class="r"><code>z &lt;- c()
for(i in 1:100){
  case &lt;- rnorm(100000,mean = np[i],sd=abs(np[i])*0.5+1)
  control &lt;- rnorm(100000,mean=np[i]*1.2,sd=abs(np[i])*0.5+1)
  zt &lt;- c(case,control)
  z &lt;- cbind(z,zt)
}
pca &lt;- prcomp(z)
# 主成分贡献
summary(pca)$importance[,c(1:10)]</code></pre>
<pre><code>##                             PC1       PC2       PC3      PC4       PC5
## Standard deviation     182.9669 155.40621 139.38457 134.3476 131.78184
## Proportion of Variance   0.0625   0.04509   0.03627   0.0337   0.03242
## Cumulative Proportion    0.0625   0.10760   0.14387   0.1776   0.21000
##                              PC6       PC7       PC8       PC9      PC10
## Standard deviation     128.89627 127.35777 124.58692 120.82573 118.27849
## Proportion of Variance   0.03102   0.03028   0.02898   0.02726   0.02612
## Cumulative Proportion    0.24102   0.27130   0.30028   0.32754   0.35366</code></pre>
<pre class="r"><code>plot(pca$x[,1],pca$x[,2],pch=19,col=c(rep(1,100000),rep(2,100000)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code>colnames(z) &lt;- 1:ncol(z)
re &lt;- colttests(z,factor(c(rep(1,100000),rep(2,100000))))
re$adj &lt;- p.adjust(re$p.value,&#39;BH&#39;)
sum(re$adj&lt;0.05)</code></pre>
<pre><code>## [1] 100</code></pre>
<p>目前这两组差异数据在前两个主成分上已经看不出来了。</p>
<p>其实这也算不上悖论，主要线索就是主成分的方差贡献，而我做的改动也在相对标准偏差上，第一个是10%，第二个是50%，第三个是120%。也就是说，当单一维度上方差已经大到均值水平时，前几个主成分展示的就不会是本来存在的均值差异。也就是说组内方差已经大于组间方差了，而主成分分析的前几个主成分展示的主要方差的方向，此时就很难看到差异了。</p>
<p>另外一个问题就在为什么每个维度上做t检验都能看到差异？是不是这个检验太灵敏了？这里我们可以换下非参检验试一下：</p>
<pre class="r"><code>re &lt;- apply(z, 2, function(x) wilcox.test(x~factor(c(rep(1,100000),rep(2,100000)))))
pv &lt;- sapply(re, function(x) x$p.value)
table(pv)</code></pre>
<pre><code>## pv
##   0 
## 100</code></pre>
<p>结果很直观，依然全是差异。那么问题在哪里？其实就是差异本身的性质，这个差异太小，同时样品量又太大，结果这个客观存在的差异就会在大样本的情况下被检验出来。那么皮球就踢回来了，这个微弱但存在的差异有没有物理意义或科学意义？</p>
<p>如果这个差异出现在无关紧要的地方，那么即使有差异可能也没多少意义。打比方我们对比了两个国家的人口拇指指甲宽度，发现其中一个国家的人口拇指指甲平均长度比另一个国家宽0.5毫米。从统计意义上存在显著差异，但实际意义上几乎为零。不过如果这个客观存在的差异有实际意义，那么想用探索式数据分析找到或者发现就不容易了。</p>
<p>什么时候会出现这个问题呢？就是样本量特别大的时候，或者说现在。我们现在把样品量降下来看看：</p>
<pre class="r"><code># 不同样品
n &lt;- c(50,100,1000,5000,10000,50000)
par(mfrow=c(2,3))
for(t in n){
        z &lt;- c()
        for(i in 1:100){
                case &lt;- rnorm(t,mean = np[i],sd=abs(np[i])*1.2+1)
                control &lt;- rnorm(t,mean=np[i]*1.2,sd=abs(np[i])*1.2+1)
                zt &lt;- c(case,control)
                z &lt;- cbind(z,zt)
        }
        pca &lt;- prcomp(z)
        # 主成分贡献
        print(summary(pca)$importance[,c(1:10)])
        plot(pca$x[,1],pca$x[,2],pch=19,col=c(rep(1,t),rep(2,t)),main=paste(t,&#39;samples&#39;))
        colnames(z) &lt;- 1:ncol(z)
        re &lt;- colttests(z,factor(c(rep(1,t),rep(2,t))))
        re$adj &lt;- p.adjust(re$p.value,&#39;BH&#39;)
        print(sum(re$adj&lt;0.05))
}</code></pre>
<pre><code>##                              PC1       PC2      PC3      PC4      PC5       PC6
## Standard deviation     443.89020 418.81034 407.4017 389.1612 384.0458 371.80732
## Proportion of Variance   0.06506   0.05791   0.0548   0.0500   0.0487   0.04564
## Cumulative Proportion    0.06506   0.12297   0.1778   0.2278   0.2765   0.32211
##                              PC7       PC8       PC9      PC10
## Standard deviation     347.05778 337.82420 328.59077 322.24252
## Proportion of Variance   0.03977   0.03768   0.03565   0.03428
## Cumulative Proportion    0.36188   0.39956   0.43521   0.46949</code></pre>
<pre><code>## [1] 1
##                              PC1       PC2      PC3       PC4       PC5
## Standard deviation     408.68566 384.14060 361.0594 356.38645 338.64842
## Proportion of Variance   0.05688   0.05026   0.0444   0.04326   0.03906
## Cumulative Proportion    0.05688   0.10714   0.1515   0.19479   0.23385
##                             PC6      PC7       PC8       PC9      PC10
## Standard deviation     338.4160 321.4941 321.00317 304.24234 297.94794
## Proportion of Variance   0.0390   0.0352   0.03509   0.03152   0.03023
## Cumulative Proportion    0.2728   0.3080   0.34315   0.37467   0.40491</code></pre>
<pre><code>## [1] 2
##                             PC1       PC2       PC3       PC4       PC5
## Standard deviation     391.4391 346.68107 335.78486 320.13859 313.30298
## Proportion of Variance   0.0521   0.04086   0.03834   0.03485   0.03337
## Cumulative Proportion    0.0521   0.09296   0.13130   0.16614   0.19952
##                              PC6       PC7       PC8       PC9      PC10
## Standard deviation     306.14963 297.96900 294.60451 292.39897 285.56836
## Proportion of Variance   0.03187   0.03019   0.02951   0.02907   0.02773
## Cumulative Proportion    0.23139   0.26157   0.29108   0.32015   0.34788</code></pre>
<pre><code>## [1] 90
##                              PC1       PC2       PC3       PC4       PC5
## Standard deviation     385.22172 341.09612 330.20575 322.20941 312.75197
## Proportion of Variance   0.05025   0.03940   0.03692   0.03516   0.03312
## Cumulative Proportion    0.05025   0.08965   0.12657   0.16173   0.19485
##                              PC6       PC7       PC8       PC9      PC10
## Standard deviation     308.12069 305.08053 294.47988 287.67776 284.18616
## Proportion of Variance   0.03215   0.03152   0.02937   0.02802   0.02735
## Cumulative Proportion    0.22700   0.25852   0.28788   0.31591   0.34325</code></pre>
<pre><code>## [1] 100
##                             PC1      PC2       PC3       PC4       PC5      PC6
## Standard deviation     385.7225 336.8093 328.40787 318.55870 312.53291 306.5494
## Proportion of Variance   0.0505   0.0385   0.03661   0.03444   0.03315   0.0319
## Cumulative Proportion    0.0505   0.0890   0.12561   0.16006   0.19321   0.2251
##                              PC7       PC8       PC9      PC10
## Standard deviation     302.60637 293.59629 285.12239 281.76564
## Proportion of Variance   0.03108   0.02926   0.02759   0.02695
## Cumulative Proportion    0.25619   0.28544   0.31304   0.33998</code></pre>
<pre><code>## [1] 100
##                              PC1       PC2       PC3       PC4       PC5
## Standard deviation     386.53688 339.35660 326.61421 317.43667 310.75599
## Proportion of Variance   0.05068   0.03906   0.03618   0.03418   0.03275
## Cumulative Proportion    0.05068   0.08974   0.12592   0.16010   0.19285
##                              PC6       PC7       PC8       PC9      PC10
## Standard deviation     307.60965 303.10260 294.97926 286.52059 281.26806
## Proportion of Variance   0.03209   0.03116   0.02951   0.02784   0.02683
## Cumulative Proportion    0.22494   0.25610   0.28562   0.31346   0.34029</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre><code>## [1] 100</code></pre>
<p>这里我们可以看到，在样品单一维度有差异但方差比较大的情况下，当样品数超过维度后，差异分析跟主成分分析就已经出现灵敏度差异了。也就是说，当样品数增加后，类似主成分分析这种探索式数据分析已经看不出预设差异了。同时我们又注意到，在样品量少于维度时，差异分析功效又是不足的，也就是根本测不到预设差异。</p>
<p>这里有人可能觉得是不是主成分分析只考虑了维度间线性组合，如果我换一种非线性方法会不会还能看到差异？没问题，我们继续模拟：</p>
<pre class="r"><code>library(umap)
n &lt;- c(50,100,1000,5000)
par(mfrow=c(2,2))
for(t in n){
        z &lt;- c()
        for(i in 1:100){
                case &lt;- rnorm(t,mean = np[i],sd=abs(np[i])*1.2+1)
                control &lt;- rnorm(t,mean=np[i]*1.2,sd=abs(np[i])*1.2+1)
                zt &lt;- c(case,control)
                z &lt;- cbind(z,zt)
        }
        umap &lt;- umap(z)
        plot(umap$layout,col=c(rep(1,t),rep(2,t)),pch=19,main=paste(t,&#39;samples&#39;))
}</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>上面是用流形分析里的umap来进行的可视化，可以看出情况一致，毕竟我们模拟时差异并非是非线性的，所以流形分析也没法捕捉这种差异。</p>
<p>此处我想说的是，如果我们过分依赖差异分析，在大数据量背景下，大概率会检测到一些客观存在但微弱的差异，这些差异只在均值水平才能发现，具体到个体差异里很难看出来，属于统计意义可能大于实际意义的范畴。</p>
<p>这种情况不大可能发生在样品数小于维度数的场景下，那个场景里最大的问题是差异分析功效不足，增大样品量总是有益的。但却可以发生在维度远低于样品数，此时大数定律反而成了负面作用，因为我们总能发现差异或者说规律，但却缺少用专业知识来筛选差异实际意义的手段。</p>
<p>很显然，此时主成分分析或聚类分析这些方法都没啥用，这些自上而下的方法根本就看不出数据中的异质性。不过，这倒可能帮我们过滤掉哪些微弱差异，只能暂时认为这些差异就是无关紧要的。但此时会遇到的问题就是我开头说的悖论，明明差异分析发现了大量差异，但整体就好像糊成一片，如果数据分析经验不足可能就不知道咋解释了。</p>
<p>这种微弱的差异本质就是 type M 型错误，也就是如果效应比较弱，我们测到了也没实际意义。不仅仅是数据分析，在我们日常生活中这种错误也很常见，例如财经新闻在每天收市后的报道经常就是“受某某影响，今天大盘下降零点几个百分点”。零点几个百分点其实是属于随机过程，并不受某某影响，但即使是财经专家也要对着一堆噪音去找解释。更搞笑的是，这些专家的追随者在听了专家点拨后，马上也看到了潜在的规律性，然后带着优越感去跟其他人说你们能力不行，想不到这么远之类的。但问题是本来也没规律性啊，或者说这个所谓的规律本身的不确定性是大于确定性的。也就是当样本间方差足够大时，样本间均值差异的实际意义就很微弱了。好比两国人均GDP有显著差异，但两个国家内部贫富差异悬殊，此时与其比对人均GDP，不如把两国穷人划分成一类，富人划分成一类来进行对比，此时发现的问题可能更有实际意义。</p>
<p>我一般不讨论社会科学规律，很大原因在于这些学科没有完成科学化改造，其规律性更像是一种自我实现的过程。也就是我首先构建一套逻辑自洽的理论，然后用理论指导实践，怎么做怎么对，用实际行动证明理论可行性。但如果同一个学科存在两种逻辑都自洽且都经过事实检验的理论，那你很难说哪种就是客观规律，或者说不存在最优路线，这就跟科学规律不一样了。自然科学规律是相对唯一的，做不到既同意理论A又同意理论B，最后一定会被更一般性的理论C统一起来。社会科学里的很多所谓规律其实是很主观的学术观点或认知体系，好一点的可以通过观察实验来证明，极端的就单纯讲逻辑自洽，在自己理论圈子里满地打滚抱团取暖，而他们眼中的金科玉律也许就像是上面我模拟的那样，客观存在但实际没意义，或者压根分类就不合理。</p>
<p>要警惕哪些大数据带来的差异。</p>
