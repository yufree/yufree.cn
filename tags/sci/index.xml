<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sci on Miao Yu | 于淼 </title>
    <link>https://yufree.cn/tags/sci/</link>
    <description>Recent content in sci on Miao Yu | 于淼 </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Mar 2023 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://yufree.cn/tags/sci/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>开放科学课程笔记</title>
      <link>https://yufree.cn/cn/2023/03/26/open-sci/</link>
      <pubDate>Sun, 26 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2023/03/26/open-sci/</guid>
      <description>&lt;p&gt;开放科学这个主题我在《现代科研指北》里做过总结，最近研究所例行培训里又推送了个一天的开放科学课程，但我那天已经报名了另外一个课，所以就去查了下课程页面。不出所料，这个课程类似《指北》，也是个完全的开源&lt;a href=&#34;https://carpentries-incubator.github.io/fair-bio-practice/index.html&#34;&gt;项目&lt;/a&gt;，课件网上都准备好了，我们所的内部培训其实就是请个人过来在固定时间固定地点集中学一下，很多时候课程场景下的学习还是有优势的。&lt;/p&gt;
&lt;p&gt;说起来这个培训模式在北美研究机构挺常见的。科研中很多技术、技能或趋势都是快速出现迭代的，指望读学位时那点童子功或员工自学经常是不赶趟或有代差，因此研究机构会从外部请一些公司过来做短期培训，如果是仪器公司这种他们主动掏钱，如果是技能这类研究机构出钱。通常这种培训在大学里是系里面博士或博后办公室组织，在研究机构就是科研服务平台负责组织，有很多学术会议最开始几天也有类似培训，一般不超过三天，我们这边要是全都参与那正事都干不了了，我个人是凭兴趣大概一两个月参与一次。按我观察，每次参会人数20-50人，参与人大都是工作不饱和的新员工与中层管理人员，大多数都是专职科学家与课题组长，因为主题比较新更适合科学家跟课题组长拿来作为要饭噱头。但最该来开拓眼界的研究生与博后反而不多，大概是他们工作过于饱和。其实我现在这个职位要求就有给研究机构提供主题培训这一条，不过好像是系里专门的几个组去做。&lt;/p&gt;
&lt;p&gt;国内这块对于在职科研人员的培训基本就看缘分了，基本靠自学跟开会，好一点的系也会时不时组织报告，但同样存在学生的培训机会少于课题组长的问题。这事完全看研究机构决策者的眼光了，盯着眼前那一点还是面向未来？浪费时间还是投资新机遇？这里没有绝对好坏之分，把握度很重要，很多系里的报告属于学术报告而不是培训报告，这种只有小同行才会有收获，培训报告这种大同行收益的东西还是要有。&lt;/p&gt;
&lt;p&gt;因为我参与不了这个培训，所以就快速过了下这个课程的内容，这里分享一下笔记。&lt;/p&gt;
&lt;p&gt;这个课程对开放科学的定义是透明且自由获取知识数据的行为实践，这是很宽泛的定义了。三个要点是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互联网连接交流&lt;/li&gt;
&lt;li&gt;研究全流程透明&lt;/li&gt;
&lt;li&gt;公众可获取&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其组成部分为&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;开放获取&lt;/li&gt;
&lt;li&gt;开放数据&lt;/li&gt;
&lt;li&gt;开放软件&lt;/li&gt;
&lt;li&gt;开放笔记&lt;/li&gt;
&lt;li&gt;开放审稿&lt;/li&gt;
&lt;li&gt;公民科学&lt;/li&gt;
&lt;li&gt;科学设计网络&lt;/li&gt;
&lt;li&gt;开放教育资源&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;需要进行开放科学的原因是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;钱：付款者可看到成果&lt;/li&gt;
&lt;li&gt;可重复性：提高研究结果有效性&lt;/li&gt;
&lt;li&gt;个人分享意愿&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开放科学的主要障碍是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;敏感数据&lt;/li&gt;
&lt;li&gt;知识产权&lt;/li&gt;
&lt;li&gt;额外精力时间&lt;/li&gt;
&lt;li&gt;假消息/不专业&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开放科学要遵守FAIR原则&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/FAIR.png&#34; alt=&#34;&#34;&gt;
&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:FAIR_data_principles.jpg&#34;&gt;SangyaPundir&lt;/a&gt;, &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0&#34;&gt;CC BY-SA 4.0&lt;/a&gt;, via Wikimedia Commons&lt;/p&gt;
&lt;p&gt;其中要点包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;永久标签（PID）可引用&lt;/li&gt;
&lt;li&gt;可下载 可计数&lt;/li&gt;
&lt;li&gt;纯文本 方便读取处理&lt;/li&gt;
&lt;li&gt;元数据 数据说明 明白易懂&lt;/li&gt;
&lt;li&gt;许可证 可重现&lt;/li&gt;
&lt;li&gt;FAIR不代表开放 但开放一般遵守FAIR原则&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是与开放科学相关的议题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;知识产权：新的对公众不开放的，出版与会议发表会阻止拿到专利，数据是关于事实的，无法产生版权，软件无法保护版权但代码有版权&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;元数据：描述数据的数据，包括管理信息，引用信息，结构信息，用户视角，方面其他人用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;个人网络标志：ORCID&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;开放电子实验笔记：所有实验流程都要保留电子版&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文件命名：有版本号，可以有时间，有文件扩展名，短名字，不要有空格或特殊字符，同类的放到同一个文件夹下&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据管理计划（DMP）：对实验数据生成处理存储全生命周期进行分阶段管理，保证数据可以被重复使用与二次挖掘&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目文件夹管理&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  文件夹结构：

  - 一个项目一个文件夹
  - doc 子文件夹用来放文档
          - 版本控制 CHANGELOG.txt 说明改变原因
  - data 子文件夹用来放原始数据
  - result 子文件夹用来放处理过数据
  - src 子文件夹放代码
  - bin 子文件夹放编译好的程序
  - 文件命名体现内容或功能
  - 不要用连续数字命名，因为一定会变
  - 三次备份，一个离线备份
  - 准备好模版
  - 版本号 SemVer CalVer
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;images/semver.png&#34; alt=&#34;https://www.geeksforgeeks.org/introduction-semantic-versioning&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个课程项目本身在 GitHub 上&lt;a href=&#34;https://github.com/carpentries-incubator/fair-bio-practice&#34;&gt;托管&lt;/a&gt;，大概是12个学时的内容，思考题、版权、引用这些信息网站上很全，里面大部分内容《指北》里都有，不过也有些我之前没考虑到的东西，后面我也会整合补充到《指北》里。这里建议对开放科学感兴趣的朋友可以抽个半天左右的时间看看，毕竟我这边更新会很慢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>小议论文致谢</title>
      <link>https://yufree.cn/cn/2023/01/08/acknowledgement/</link>
      <pubDate>Sun, 08 Jan 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2023/01/08/acknowledgement/</guid>
      <description>&lt;p&gt;研究人员读论文或审稿通常是关注内容本身，但论文致谢里面其实也隐含了一些信息，这些信息对于内容评价是没用的，但却大概能反映出作者要钱的能力与发钱机构对个人或研究的支持力度。&lt;/p&gt;
&lt;p&gt;国内的研究经费一般来自基金委，年轻学者大多挂国自然或博管会的博后基金，资深学者大多通过面上基金来维持课题组运转，大的平台或实验室会申请重大研究计划或重点项目，要是涉及到多研究机构的大项目，那么会去申报国家科技重大专项。不过，基金委及其他发钱的地方也有针对个人的项目，这就是所谓的“帽子”。除了基金委，教育部科技部中科院也都有类似的或者奖励个人（长江学者，其实跟李嘉诚基金有关）或者需申报项目（重点研发计划）的经费。国家经费支持之外，地方政府通常也有类似结构的经费，常见于地方省属高校。还有些属于私人基金资助的，国内常见是校友捐助给大学，然后大学自行安排，很少见私人基金直接资助具体项目的，不过这在企业那边就很常见了，就是入股或投资。&lt;/p&gt;
&lt;p&gt;美国的致谢部分就比较多样了，一个显著区别是美国有几个大机构是主要出钱人，例如美国国立卫生院（NIH）、美国自然科学基金（NSF）、航空航天口的NASA还有各联邦部委。美国国家科学院跟中国科学院是不一样的，前者更多是个学术荣誉机构与提供建议的非营利组织，后者其实更像NIH，但NIH的研究所可以管一个方向的经费审批，跟基金委学部类似，但NIH研究所本身也做研究，中科院研究所则没有这个审批权限，中科院研究所很多是按基础学科分的例如物理所、化学所而NIH研究所则是按应用方向，例如衰老所、癌症所，相对而言NIH从组织构架上更欢迎不同研究方向与背景的人来申请，而国内基金委则直接开了一个交叉学科学部。&lt;/p&gt;
&lt;p&gt;具体到研究基金NIH的研究基金有很多种，T与F开头的是训练型研究经费，最出名的是F32，新科博士申请到F32可以相对独立进行博后研究，类似国内博后基金，T开头则是奖给研究所做训练的，研究所拿到后可以招募并训练博后；K开头的是给个人职业发展的，其中最出名的是K99，拿到K99的博后基本可以在顶级大学里入职做助理教授，类似国内一些国家、地方、还有学校的人才计划；R开头的是给具体研究项目提供经费的，最常见的是R01或R21，助理教授期间拿到R01基本可以保证转终身教职，类似国内青基、面上，U开头的会涉及多研究机构的合作，类似国内重点项目；P开头的项目一般给大项目的，里面会分拆给多个课题组长，但主题相对一致，类似国内重大研究计划项目；前面说的这些都可以向NIH下属的研究所申报，但主题如果超越了单个研究所的研究领域，NIH会有比P开头项目更大的共同基金项目来支持，这个是按照主题申报的，当前在研的不超过三十个，国内与之对应的大概是国家科技重大专项，例如环境领域的水专项，或重点研发计划，不过NIH共同基金只涵盖了生物医药领域的研究项目。NSF的研究基金结构也类似，但研究方向更广更偏基础，但NSF没有NIH的下属研究所来自行决定经费发放。NSF跟NIH都有专门面向产业转化的基金，也就是说，他们都有天使轮融资的功能，其实很多美国高校也会投资入股自己学生或老师做的项目，可以说肥水不流外人田。&lt;/p&gt;
&lt;p&gt;如果你去问一个美国研究人员喜欢申请哪种经费，如果研究方向沾边大概率会说NIH，通过率与经费双高。NIH关注点在生物医药方面，跟纳税人比较容易解释，而且最主要就是经费分发方式。申请过经费的都知道你申请的钱只有一部分是拿来按预算做研究的，另外一部分（overhead）是要被所在研究机构按比例拿走做管理费或间接费用付房租水电还有行政人员工资的。NIH评经费给你那个数就是实实在在的全部做研究，管理费另给，NSF给你那个数你大概能拿到六成，是算一起的。这个东西国内也有，如果是A研究所的课题组长申请到杰青，那么400万经费里50万是间接费用，当然也可以按比例算。美国这个基本一个研究所一个套路，很少有低于40%的，各别研究所要求100%，也就是NIH你给这个课题组100万美金就要也给我研究所100万。那么是不是说间接费用拿的多就不容易过？也不是，这属于研究所的品牌效应，Scripps曾经就是接近100%，但NIH也得上赶着发，而且高额间接费用对于强势研究所而言特别有用，可以提供更高薪资，也可以通过内部所谓过桥经费给经费中断的年青课题组长一个较长的积蓄期来研究重大问题。但美国政府不同党派对此意见不同，川普政府当年砍NIH经费，主要就是砍间接经费，但其实到现在变化也不大，实际间接经费比例是需要学校跟资方谈，其实很多都公布在学校网站上了。当然，有些奖给个人的项目例如K基金就有8%的封顶间接经费。&lt;/p&gt;
&lt;p&gt;另外值得注意的就是私人基金会。很多研究是被私人财团或家族基金资助的，很多罕见病能被研究其实就是因为某个家族本身有这个病，他们直接找医院或实验室谈资助，私人基金在使用上灵活度相对政府限制要少很多。近些年硅谷新贵也热衷于搞这样的资助，例如脸书的Chan Zuckerbery Initiative，传统富豪资助是盖楼冠名或搞奖学金，近期很多都直接下场做研究去资助他们眼中的未来，有些甚至是带有风投性质的。这个跟国内横向经费还不一样，私人基金一般是非营利组织，横向经费其实也将属于历史名词，但凡能拿到横向经费的课题组很多都会自己开公司募资赚钱，而且当前很多领域其实企业自己的科研水平是超过学术界小作坊的，特别是产业相关这块，很多开源项目就是私人基金支持运营的。&lt;/p&gt;
&lt;p&gt;其实还有些更新奇的资助方式。例如如果一个议题特别新，公众特别关心，很可能就会出现基于众筹的科研项目。事实上，2013年众筹热潮中就有很多研究人员去募资，SciFund就说70%的众筹研究成功募资，现在也有很多研究通过网站向公众募资。我研究了一下发现这些众筹研究项目大部分都是来自一些非名校但受过专业学术训练的专家学者主持，内容非常专一，金额也不大。但好处在于他们的研究计划比较容易读懂，会定期上传研究进度，也会直接接受专家、公众及赞助者的质询，这种直面公众的能力很多大课题组可能都没有，可以作为传统科研募资的一个补充与尝试性计划的起点。广义来说，朋友圈集赞都算是众筹精神支持了，文章打赏也算物质支持，看起来国内众筹研究其实具备土壤，就看各位科研工作者如何播种收获了。当然，这里罗翔警告一下，提前查下众筹与非法集资的区别，后面那个是犯罪。&lt;/p&gt;
&lt;p&gt;总之，国家机构的资助为主、私人为辅、公众为补充，一个职业科研人员应该了解其存在，灵活申请。要是对自己的能力足够自信，可以尝试把说人话的项目挂到网上直钩钓鱼，说不定有意外收获。当然，不要忘了在致谢里感谢下这些大多数情况血本无归的衣食父母，科研从来都是一项高风险且烧钱的活动。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研助理</title>
      <link>https://yufree.cn/cn/2022/09/26/research-assistant/</link>
      <pubDate>Mon, 26 Sep 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/09/26/research-assistant/</guid>
      <description>&lt;p&gt;最近看到国内的&lt;a href=&#34;https://www.bjnews.com.cn/detail/1662379079169302.html&#34;&gt;新闻&lt;/a&gt;说今年科研助理岗吸引14万人就业，其中应届毕业生超12万。其实这是个对国内科研挺重要的消息，说明国家开始有意发展职业化科研了。&lt;/p&gt;
&lt;p&gt;这里的科研助理职责为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;博士后、科研辅助研究、实验技术、技术经理人、学术助理和财务助理等科研助理工作&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实要分成两部分来看，一部分是博士后等职业科研岗，另一部分是职业助理岗。前者在中科院体系已经搞了几年了，名曰高级科研助理，实际上采用的是3+3的考核制，类似预聘-长聘的变种，考核通过基本就副研究员了。后者则属于纯助理岗，之前很多报账、仪器维护啥的都依赖研究生，但研究生属于铁打营盘流水的兵，好不容易培养个熟手，毕业就跑路了，这对课题组日常运行效率打击很大，现在拿事业编吸引专毕业生也算是提高效率的一种措施。&lt;/p&gt;
&lt;p&gt;其实科研机构与大学本来就有行政岗，但科研助理跟行政岗还是有很大区别的。例如行政岗的人去维护实验室安全属于外行指导内行了，科研助理更多是本科硕士的专业背景，很多就是课题组前成员，做科研助理所需的科研技能与行政能力同时具备。估计很多科研助理长期也有可能选择读硕博走学术路线，可以算个适应过度的岗位。&lt;/p&gt;
&lt;p&gt;但博士级别的科研助理岗基本就是因为当前教职供需不平衡导致的。现在每年博士招生超过10万，毕业超过6万。新增教职数虽然也在增加，但大概在每年最多3万这个水平，课题组长这个水平一年大概只有2-3千，而且新增教职是开放给资深研究人员的，这些人大都有几年博后经历。因此为了缓解教职数与应届博士毕业生间的差距，势必要在博士与正式教职之间插入一个职业来缓解高学历人才就业压力。&lt;/p&gt;
&lt;p&gt;上面的情况隐含假设是社会上普遍认为读博要做科研，博士毕业生在求职上自然会往教职上卷。教职供应不足自然会搞些新职位来留人，但另一个问题则是当前科研机构又缺人，特别是缺人完成项目，但体制上考虑长远人口年龄结构无法给更多教职，也就逼着科研单位创造新岗位。因为科研助理待遇虽然不比业界，但也足够体面，有些甚至优于编制内教职，所以眼下这个现象其实是科研新人与科研机构的一种对赌。科研机构提供平台与可依靠的课题组，科研新人提供创造力，对赌3-5年，赢了教职上岸独立课题组，输了转行。从科研机构而言，相当于拿一个临时性高待遇投个天使轮，赢了收获科研新星，输了及时止损换下一波，概率上不亏。&lt;/p&gt;
&lt;p&gt;从个人视角，如果你是硕士本科，毕业了没有理想工作，对科研还有些想法，可以通过这个职位去了解下课题组如何运转，但可以预见不会有太多创造性的劳动。如果你是博士，抓住机会搏一把，但能否留下都是看成果而不是努力，任何课题都有风险，但如果你对科研无感且已经拿到业界工作，那么没必要在科研助理岗位浪费时间。&lt;/p&gt;
&lt;p&gt;其实美国的科研助理岗挺成熟了。我之前纽约的那个实验室，除了暑期来几个关系户高中生刷简历，大部分科研助理都是本科或硕士，有些隶属课题组，有些隶属实验室，他们很多就是为了攒一下读硕士或博士的学费才做这个岗位的。同时，科研机构内部人员读学位有的报销部分学费，有的减免内部申请费用且因为做科研助理时熟悉了实验室课题组长，所以真开始做科研也是轻车熟路。从待遇上看，科研助理岗一般是不低于同学历平均工资的，几乎一定比博后或博士工资高，所以美国很多家里没矿的又不想贷款太多的通过科研助理来做职业过渡也挺好，起码你接触的人学历都不低也比较人性化。在他们看来，做科研助理并不是耽误时间，而是类似间隔年这种给自己职业规划做个缓冲。&lt;/p&gt;
&lt;p&gt;而美国的职业科学家应该是国内学术界下一步会借鉴的岗位。我现在就是在学术界做职业科学家的，不隶属课题组但也不养课题组，基本是同时跟着不同项目做研究。例如我现在就推进三个项目，其实我属于超载了，因为一般科学家最多会同时推进两个项目，只是我这边我这个研究方向缺人被拿来凑数了。研究所有自己的经费支持，当然也会申请外部经费，但我一般不掺合，毕竟我主要推进项目，忽悠钱也不是我的分工。&lt;/p&gt;
&lt;p&gt;职业科学家的考评基本就是看项目完成情况，也要写文章，但课题组长没法跑过来压榨，毕竟我跟他们不在一个系统里，属于合作关系，很多课题或方向博士博后的水平都不一定能搞定，课题组长能忽悠但不会执行，此时就需要职业科学家来帮助推进项目。从待遇上看，有博后经历的职业科学家在学术界至少也有六位数年薪，好于公立学校AP，跟私校AP待遇类似，因此一般单一课题组也雇不起职业科学家，但到了工业界待遇就更高一些，会再上浮30-50%。资深职业科学家在研究所也是神棍一级的存在，跳到高校里做教职并不困难。&lt;/p&gt;
&lt;p&gt;职业科学家跟课题组长最大区别在于职业科学家对研究所的价值更高。课题组长要是做大了很容易被别的大学挖走，因为很多项目认人不认技能。但职业科学家属于认技能不认人，毕竟申请经费不用你来管，职业科学家可以更多关注研究而不是到处拉关系树立个人品牌。因此，研究所职业科学家的流动性相对低一点，内部合作与协作更多，累积技能与经验基本都能找到用武之地。其实课题组这种研究单位效率并不高，单一课题组存在技能缺口，找其他课题组合作又存在较高的交流成本，如果研究单位里全是地位平等的职业科学家围绕项目组织人力资源攻坚，那么这样的研究效率会更高一些。NASA还有美国一些国家实验室都大量采用职业科学家来做项目，要是依赖课题组很多就赖在自己舒适区里搞排列组合了。&lt;/p&gt;
&lt;p&gt;我自己的感觉是职业科学家身份跟研究生与课题组长交流都很平等，这点从交流上比较舒服。我有些朋友做了课题组长后总是要端个师长的架子，有时候死不认错，有时候又喜欢威压他人或pua学生，摆出一副自己很聪明的样子，这些在我看来都很不舒服。大家都是要饭的，何必互相为难。&lt;/p&gt;
&lt;p&gt;总之，国内开始推进科研助理是个好事，可以对高学历人才更好按自己的需求与职业规划进行分流。如果后面引入职业科学家岗位我也不会奇怪，那说明大学还有研究机构真得要凝聚自己核心科研竞争力了。其实，课题组这种小作坊体制的效率在现代社会还是有很大提升空间的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>《现代科研指北》已上市</title>
      <link>https://yufree.cn/cn/2022/08/29/sciguide-on-market/</link>
      <pubDate>Mon, 29 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/08/29/sciguide-on-market/</guid>
      <description>&lt;p&gt;《现代科研指北》已经上市，指北奖学金计划细则也公布在了开源版的issue&lt;a href=&#34;https://github.com/yufree/sciguide/issues/13&#34;&gt;里&lt;/a&gt;了。老实说，如果没有指北奖学金，我可能并没有多少动力去推广这本网上有免费版的书，现在就当众筹做实验了，心理平衡多了。&lt;/p&gt;
&lt;p&gt;目前京东淘宝当当搜书名都有货了，但官方店还没货，预计下周才有货开始推广活动。原价是66元，如果肯等一等，那么近期开学季在京东、当当都有满减活动，我还有个专属链接可以用，可扫描下面二维码五折购买：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/WechatIMG1130.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;有工资的朋友对科研感兴趣欢迎支持，也欢迎家里有搞科研的学生的买来当开学礼物。还在花家长钱的学生党们不建议购买，本书开源版本这个页面右上方就有入口，欢迎先上车后补票。希望你买书是为了自己，要是为了支持我就算了，我不重要，这书赚的钱最后都会送到奖学金奖池里，我要饭都是坑大户的。&lt;/p&gt;
&lt;p&gt;这本书能出版首先要感谢电子工业出版社的付睿老师与徐艳老师。特别是付睿老师，因为一开始我只是想放到网上分享，能有出版社编辑来谈出版事宜属于直勾钓鱼了。不过，我确实很好奇出书的流程，后面长达一年半的来回修改与三审三校最先满足的是我的好奇心。在这个过程中，我从两位专业编辑身上学到了解到很多，特别是了解到了我真实的语文水平。我也特别感谢两位老师能协助我通过一轮轮审核，出版一本有观点的书并不容易。&lt;/p&gt;
&lt;p&gt;其次，目前封底推荐语分别从学术界、出版界、学生、非学生四个类别进行了推荐。我很感激为我写封底推荐语的江老师、涂老师还有两位通过问卷吐槽的网友。其实问卷目前收集到两位数了，后面的几份推荐语挺好的，不过很遗憾因为时间原因没法放到封底了。也有通过问卷留下批评意见的朋友并留了联系方式，很遗憾，这种吐槽就算我发给编辑也不会被选的。另外，这个&lt;a href=&#34;https://wj.qq.com/s2/10408005/9374/&#34;&gt;吐槽收集计划&lt;/a&gt;会一直开通，年底或某个时间节点我会集中公布统计数据并回复其中的吐槽。当然，豆瓣&lt;a href=&#34;https://book.douban.com/subject/36078034/&#34;&gt;条目&lt;/a&gt;下评论也可以。&lt;/p&gt;
&lt;p&gt;再次，这是出版社设计的封面，我认为非常切合主题。毕竟指北最远也就指到北极，而现代的北极正在经历冰川消融，暗示了当前科研中存在的问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/WechatIMG943.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;最后，我自己很不要脸的在全网搜了一下这本书，然后很意外发现很多网友的吐槽。下面是介绍或收录了《指北》的文章、推荐文章或列表，所谓物以类聚，又所谓拔出萝卜带出泥，跟《指北》放在一起的应该质量也有保证。只是我没想到读《指北》的人背景这么复杂，如果你们看到了希望能把这种收集推荐习惯坚持下去，于己于人都是一笔财富。这里我做个汇总：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/513765150&#34;&gt;关于科研的种种-从理论到实践&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.jianshu.com/p/8ea4bd7577c2&#34;&gt;读《现代科研指北》|| 或谈谈硕博生活要则&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/mojujiang/article/details/110819846&#34;&gt;现代科研指北笔记（一）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://zxl19.github.io/academic-guide/&#34;&gt;关于如何科研的相关资料&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://shixiangwang.github.io/blog/multiple-stats-testing-and-thinking/&#34;&gt;读《指北》：多重假设检验记录与思考&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/Tirklee/GitHub-Chinese-Top-Charts/blob/4ddb578f1696f4160a2ec52cfe0a8081dcdc1f93/content/charts/overall/knowledge/R.md&#34;&gt;中文总榜 &amp;gt; 资料类 &amp;gt; R&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://cloud.tencent.com/developer/article/1920316&#34;&gt;好物分享17-科研巡礼01-科研第零课：关于科研入坑的学习资源&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://idushu.com/%E4%B8%80%E4%BA%9B%E4%BC%98%E7%A7%80%E7%9A%84%E7%BD%91%E7%BB%9C%E5%86%85%E5%AE%B9%E8%B5%84%E6%BA%90/&#34;&gt;一些优秀的网络内容资源&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://xuanwo.io/2021/01-share-with-luck-4th/&#34;&gt;随缘分享第 4 期&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://chowdera.com/2021/12/202112171111551186.html&#34;&gt;互联网游荡杂志（第三期）&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dingeral/net_note/blob/86e75b2f4a444413313ec01888ef0059d3215b72/docs/%E8%BD%A6%E5%BA%93/%E7%94%B5%E5%AD%90%E4%B9%A6.md&#34;&gt;电子书&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mugpeng/second_brain/blob/48e29037131a8f5fb81116f6d73c5b39434922c3/docs/02-%E5%8C%97%E5%A4%96%E5%9B%BE%E4%B9%A6%E9%A6%86%E5%A5%BD%E7%9C%8B%E5%90%97%EF%BC%9F.md&#34;&gt;02-北外图书馆好看吗？&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/MLNBA-Lab/DataCollection2Public/blob/1ece83ca3d1e2009cc5c8c25b7cdf8100fae47bf/%E7%A7%91%E7%A0%94%E6%96%B9%E6%B3%95%E5%8F%8A%E5%B7%A5%E5%85%B7/%E7%A7%91%E7%A0%94%E5%B7%A5%E5%85%B7%E5%8F%8A%E6%8A%80%E8%83%BD%E8%A1%A8%E6%8E%A8%E8%8D%90.md&#34;&gt;科研工具及技能表推荐&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/jmxsy2016/Data-Science-and-Economics/blob/aeebd1f13c4881fdd1d30222f9d1848c0c684a93/README.md&#34;&gt;学习笔记——机器学习与经济学&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/apachecn/it-ebooks-archive/blob/66a1d479215c0e325d5b86175996a7677d4ff19c/docs/it-ebooks-2021.md&#34;&gt;计算机电子书 2021 Git 仓库备份&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>学术自由</title>
      <link>https://yufree.cn/cn/2022/08/14/academia-freedom/</link>
      <pubDate>Sun, 14 Aug 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/08/14/academia-freedom/</guid>
      <description>&lt;p&gt;人到中年大都对之前有点遗憾，对未来又有很多期许，亟需一些指标来定位自己在地球online上剧情模式的进度条。青少年时期大多数人进度条都差不多，基本就是学-考的交替进行，这里面关键时间节点无过于小升初、中考、高考、考研/考公/考证、成家、下一代出生。此时人与人的差距都有明确的量化指标，例如分数、学校档次、证书等级啥的，当这些需要获取的资格拿到后，蓦然回首，大家基本都站到了不同的赛道上了。&lt;/p&gt;
&lt;p&gt;此时自然就会焦虑，因为到这一步已经没啥参照物了，别人家的孩子成了家家有本难念的经。但习惯了被社会评价的社会人总还是能找到些共同话题继续卷的，例如下一代教育、自己及上一代的医疗养老还有房子。等这些差不多都有了解决方案后，大多数人的人生目标都指向了经济独立，潜身于各种fire或投资论坛上精打细算，目的都指向一种理想的生活，其名为自由。&lt;/p&gt;
&lt;p&gt;然而，绝大多数人终其一生都只能在通往自由的路上，他们的一个个小目标达成后立即会被替换为另一个标的，直到自己意识到能力实在够不着了也依然不会放弃。不过财富自由大概只能算地球online的一个流行副本，还有很多不同的副本可以去体验，不过很多人坚持认为这是主线剧情而不断努力，从一次次里程碑里体会这一生的意义。&lt;/p&gt;
&lt;p&gt;学术副本也差不多，这里要排除那些把学术当成财富自由小目标的人。现代分工体系里的确需要做学术的人，但不代表做学术的人都喜欢做学术。很多人走学术路线是因为别的做不了，空有高学历，想通过学术身份来证明自己在努力生活；还有些人则是认为做学术有利可图，能在学术身份下获取适合自己的最大经济利益或就业优势；当然也有人做学术是迎合社会家庭对其的期望，一辈子早就被安排明明白白的。因此跑去下学术副本的人如果本身不是为了给自己一个交代，大多数时候都需要一些学术偶像的传奇经历来打打鸡血。&lt;/p&gt;
&lt;p&gt;不过能上新闻的学术经历基本都是异常值，其经验即没有统计学意义，也没有太多可借鉴意义。这就像很多明星出的减肥书，除了明星自己有效外读者要是效仿大概率是仿了个寂寞。我小时候读了很多科学家的故事，但很快我就意识到这些故事跟科学家的成就的关系大概跟天气与股票的关系差不多，故事里的逻辑总是会被现实中的复杂性打碎。人们在个人成就的归因上总倾向于去找那些独家秘方，但事实上就是在过拟合噪音。&lt;/p&gt;
&lt;p&gt;临渊羡鱼不如退而结网，这里我总结下实现学术自由的步骤，学术自由应该是一种自我认可的状态，可以在资源允许状态下自由探索知识的边界，这里不涉及其在政治上的含义。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;教科书自由&lt;/p&gt;
&lt;p&gt;这是学术自由的第一阶段，也就是你所在的领域任何一本教材你拿来看都没有知识盲区。这是高年级本科生与研究生做研究的基本要求，而另一层要求则是学习能力，也就是给你一本不是你所在领域的教科书，你也能很快读明白，大体了解这个领域是咋回事，知识框架如何。达到教科书自由的人，就业上基本没有太大限制，可以默认拿到博士学位具备教科书自由。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文献自由&lt;/p&gt;
&lt;p&gt;这是学术自由的第二阶段，教科书自由是对过去知识的掌控，文献则是对当前学科知识的掌控。达到文献自由一方面对新出的文章套路大概熟悉，清楚作者的创新点在哪里；另一方面，也可以很快从当前非本专业文献中找到可以用在自己研究中的工具与思路。要达到文献自由，需要有足够的论文阅读量打底，而且要持续读新文献。一般而言，独立课题组组长要具备文献自由。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;基金自由&lt;/p&gt;
&lt;p&gt;到了文献自由，基本就进入职业化学术研究领域了。而职业化意味着你要能让国家或企业出钱来做当前还不存在成果的课题，基金申请就是这样一个面向未来的流程。所谓基金自由，就是申请的基金几乎都能拿到，课题组可以持续运转，不会出现经费断档。能实现基金自由，很多时候是需要运气才能办到的，得踩到热点学科热点方向上才行。有了基金自由，你可以探索本领域能覆盖到的任一方向，一般只有少数独立课题组能实现，大多数课题组都是在维持文献自由的水平上找自己不可替代性来维持经费，谈不上探索。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;期刊自由&lt;/p&gt;
&lt;p&gt;很多课题组能实现基金自由，但成果发表上通常并不自由，可以在本专业内期刊灌水，但综合性期刊完全上不去。事实上，很多发表在综合性期刊上的工作也是因为现象本身重要而不是学术价值高而得到发表的，学术价值评价在前沿领域是很主观的，CNS一年的论文里最后被专业教科书收录的也只是很小一部分。所谓期刊自由，核心在于成果不受期刊限制，不论放到什么期刊上都是重量级的成果，能开拓一个新领域。能达到期刊自由的成果对每个学科每年都是在个位数到两位数之间徘徊的，而能达到期刊自由的人，随便拿出一个都得是某方向开山祖师爷这个水平的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课题自由&lt;/p&gt;
&lt;p&gt;课题自由目前有记载的并不多，大都在地理大发现到维多利亚时代这个时期。那个年代很多学者可以单纯依赖兴趣就开创一个学科，然后又可以在兴趣消退后去开拓另一个学科。这种学术自由人只能是时代产物，当前语境下就算很多诺贝尔奖实验室都不一定能做到课题自由，可以任意切研究方向。但反过来说，当前声称自己课题自由的更多则是民科或现代宗教创始人居多，他们总有一套大一统理论来解释世间万物，也算某种课题自由，但并不是学术副本而是形而上学副本。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;绝大多数当前的职业科学家都在第二档与第三档之间，但依然可以算某种程度的自由，前三档从知识的过去、现在与未来三个档上给出了自由，后面两档都属于异常值，不是你努力能实现的，运气与机遇更重要。&lt;/p&gt;
&lt;p&gt;就算是前三档，其实也是有很高门槛的，下面我给出一些指标，这里面的指标有的是可以刷的，有的是被动的：&lt;/p&gt;
&lt;p&gt;1000次引用+100次实验+10篇一作通信（包含不少于三个不同于导师的独立研究方向）&lt;/p&gt;
&lt;p&gt;2000份文献研读+200次大小报告（包含课题组报告）+20次专业审稿&lt;/p&gt;
&lt;p&gt;3000天研究+300同行人脉+30封据稿信&lt;/p&gt;
&lt;p&gt;上述指标如果没达到就独立做研究，很可能学术训练不到位，需要持续借助外力；如果达到了，基本可以吃科研这碗饭了。需要注意的是做学术很重要的训练是习惯失败与不认可，没有这种心态很可能搞出学术不端来，走学术路线一定要比正常人更能接受挫折，否则大概率活不下去。从进实验室开始算如果10年能达到这个指标就是优秀，15年达到算良好，20年还没达到估计早就转行了。而且这个标准你要真达到了基本也移民自由了，起码已经到美国eb1杰出人才的标准了。当然，你也可以直接奔着异常值去，但异常值需要统计上异常的经历，很多不是个人能把控的。&lt;/p&gt;
&lt;p&gt;不过自由与否本就是一个自我主观认定过程，学术副本绝大多数人根本就刷不到最终boss达到学术自由。但如果自己可以认可自己，那这些标准都是虚的，只是当前的问题在于太多的人着急用群体标准去评价别人，但却从来不问自己究竟需要什么。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>通引膨胀</title>
      <link>https://yufree.cn/cn/2022/06/29/impact-factor-inflation/</link>
      <pubDate>Wed, 29 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/06/29/impact-factor-inflation/</guid>
      <description>&lt;p&gt;每到六月底学术界就跟过年差不多，主要原因是前一年的期刊影响因子会公布。不出意外又是个皆大欢喜，大部分期刊影响因子都有提高。这里我们就来梳理下影响因子的相关数据与议题。&lt;/p&gt;
&lt;p&gt;根据 Eugene Garfield 在JAMA上的&lt;a href=&#34;https://jamanetwork.com/journals/jama/article-abstract/202114&#34;&gt;自述&lt;/a&gt;，影响因子是他1955年在 &lt;em&gt;science&lt;/em&gt; 上提出的一个想法，这个利用引用来评价的思路发展到1961年出版了第一版 &lt;em&gt;Science Citation Index&lt;/em&gt;。之后他与Irving H. Sher在美国科学情报研究所（ISI）联合创造出了期刊影响因子。ISI后来被汤森路透收购而期刊影响因子报告则作为报告出售，但到了2016年ISI这块业务又打包卖给了Onex公司与霸菱亚洲投资基金（基金经理就是网传在上海买不到菜的徐新，不过今年又被欧洲一个私募给收购了），成立了独立的Clarivate，也就是科睿唯安公司。现在我们看到的期刊影响因子理论上都应该是科睿唯安公司发布的。&lt;/p&gt;
&lt;p&gt;但其实影响因子的计算方式其实并不困难，就是某一期刊的2021年影响因子就等于其于2019年2020年两年发表文章在2021年的引用数除以这两年的发文量（研究性文章，要有同行评议），打比方A期刊2019年与2020年两年总发文量100，这100篇在2021年被引用了500次，那么其影响因子就是5。因为算法早就公开了，所以就算JCR还没发布，很多期刊自己也能在2021年年底后算出自己2021年的影响因子。这里主要依赖的是 WoS 跟 Scopus 这两个付费的引文数据库，不过因为开放科学的推动，现在主流期刊基本都会开放引文的交叉查询，所以估算出的影响因子通常差不多。这里要补充的信息是影响因子计算涉及的学术期刊并不包括所有学术期刊，今年期刊影响因子涉及了大概有两万多份期刊，其中收录于SCIE的大概九千多份，Scopus 收录了4.3万份期刊不过活跃的只有2.7万份，而&lt;a href=&#34;https://www.scimagojr.com/journalrank.php&#34;&gt;Scimago&lt;/a&gt;也收录了大概2.7万份期刊，历史悠久的化学文摘数据库则收录了大概八千多份期刊，总体而言当前学术期刊总量应该在三万份这个量级上，影响因子计算可能会有疏漏，不过考虑到绝大多数学术论文引用量奇低，所以这个疏漏影响不大。&lt;/p&gt;
&lt;p&gt;影响因子是用来评价期刊的，但更多人熟悉的是拿期刊来评价人，例如某某在影响因子高达某某的期刊上发表了论文。其实这属于本末倒置，就好比通过学历来评价学生一样。刚毕业学生如果来自名校自然好找工作，但毕业十几二十年还在到处宣传自己母校的大概率都是水平达不到母校平均水平而只能依赖母校牌子来忽悠人，社会招聘跟应届生招聘最大区别就是更多通过实际工作业绩来招人而不是通过学校牌子来保障一个最低水平。&lt;/p&gt;
&lt;p&gt;同理，刚进入学术界的人大家都不了解，通过影响因子来评价算是一种期刊信用透支。但运行时间比较长的课题组在某个领域已经形成声誉了，此时研究工作发在任何地方都影响不大，因为不论发到哪里都会有人关注。2009年一项&lt;a href=&#34;https://www.phil-fak.uni-duesseldorf.de/fileadmin/Redaktion/Institute/Informationswissenschaft/stock/fulltext_The_Inflation_of_Impact_Factors.pdf&#34;&gt;研究&lt;/a&gt;考察了期刊 &lt;em&gt;ChemPhysChem&lt;/em&gt; 上面的论文引用状况（见下图），结果发现期刊里论文的引用状况并非高斯分布而更像幂律分布，少数高引用论文主导了期刊的影响因子。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/ifdistribution.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;而2016年出版的&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-02511-3_1&#34;&gt;书&lt;/a&gt;则发现大概只有30%的论文引用情况能达到或超过其所在发表期刊的影响因子（见下图）。因此，通过影响因子评价期刊文章水平对于大多数文章而言都是高估了。相应的，本来引用很高的文章也会更多宣传自己单独的引用率，因为影响因子反而是低估了文章影响力。如果一个人长期津津乐道于自己的高分文章，大概率是引用不大行拖期刊后腿的。很不幸，这部分人占了大多数，没有实现影响因子自由。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/ifpapervsjournal.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;很多研究人员简单通过影响因子去评价自己不熟悉的工作或人。不过这也无可厚非，毕竟学术界大了，总要有些量化指标方便外行来比较。网上关于影响因子讨论最多的可能就是各路研究生跟期刊编辑编委，但长期吃科研饭的人关注度就一般了，因为行业内虽然还是看重影响因子，但由于这些年新期刊出来搅局外带预印本服务器的流行，他们更关注自己工作的引用数与影响力，这些对于申请基金有更直接的帮助。当找教职的人还在宣传自己论文所在期刊影响力时，另一些人可能更多去宣传自己的封面文章或高引论文了，不过真正做评价的人还会关注候选人不同于其独立前课题组传统研究方向的工作，这些更说明研究潜力，否则其实就招了个大课题组的远程分支实验室，当然有时候这对学院/研究所团队建设也挺重要的。&lt;/p&gt;
&lt;p&gt;影响因子自从出现后就没少出现争议。除了前面拿影响因子评价人的误用外，另一点就在于影响因子分子分母的计算上，因为分母只算研究性论文而分子可以算所有引用，所以很多期刊就会搞一些编辑导读、观点评述、读者来信啥的栏目，这些栏目大都没有同行评议不会被算到分母里，但他们也会去引用学术论文或高亮某些研究，这样就可以给引用量注水了。另一个就是综述性期刊，因为综述相比具体研究更容易获得大量引用，所以很多期刊会选择在创刊时先找资深研究人员写综述，这样很快就会形成一个比较高的起点。&lt;/p&gt;
&lt;p&gt;还一个就是文章半衰期，影响因子的计算算得是发表后两年内的引用量，确实很多学科发展日新月异，超过两年的文章可能连读的价值都没了，但更多学科特别是基础学科发展没那么快，引用的大头在两年之后，根据自然指数网站的&lt;a href=&#34;https://www.natureindex.com/news-blog/whats-wrong-with-the-jif-in-five-graphs&#34;&gt;研究&lt;/a&gt;，生物医药类文章引用量两年达到高峰，但社会科学的文章在发表10年内的年均引用量几乎不变。如果拿影响因子去评价不同学科是肯定有问题的，拿着高影响因子学科的文章跑到低影响因子学科里去做所谓“跨学科”研究或经费申请的降维打击也不太公平，当然这种输出性内卷有时也会给传统学科带来危机感，从而推动学科发展。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/ifhalftime.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;影响因子计算上，自引率也是一个争议点。2007年一项&lt;a href=&#34;https://edoc.hu-berlin.de/bitstream/handle/18452/9945/213HWb3G2qJzw.pdf&#34;&gt;研究&lt;/a&gt;表明，期刊引用存在马太效应，好的期刊更愿意引用自己的论文而其他期刊也会引用好的期刊，这导致期刊会自发形成高影响因子的权威性。2016年所有期刊&lt;a href=&#34;https://link.springer.com/chapter/10.1007/978-3-030-02511-3_1&#34;&gt;自引率&lt;/a&gt;大概在12%左右（见下图），存在明显学科差异。2020年一项&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/full/10.1002/leap.1348&#34;&gt;研究&lt;/a&gt;考察了 1975-2017 年期刊的自引情况，发现其实所有期刊自引率其实是下降的，1975年大概20%，到了2017年不到15%，高影响力期刊确实比低影响力期刊更多引用自己期刊内容，但更多是最近两年的工作，属于相对良性的。不过，自引率高也可能是期刊编辑操纵的结果，JCR就曾经移除过一些通过提高自引率提高影响因子的期刊，但这种操纵影响因子的小把戏还是很常见。例如，很多期刊拒稿的理由就是引用文献里没有本期刊的论文，说明内容不属于期刊的研究领域。但反过来说，如果投某期刊就要引用该期刊内容，客观上也就推高了这个期刊引用率，这种现象属于灰色地带，很难判断动机。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/ifselfcitation.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;那么开放获取呢？最近几年各大出版集团可算找到了敛财利器，新期刊层出不穷，逐渐形成期刊矩阵来抢夺优质稿源，其中一个旗号就是开放获取的引用率高。不过，早在2008年的一次随机对照&lt;a href=&#34;https://www.bmj.com/content/337/bmj.a568&#34;&gt;实验&lt;/a&gt;中就发现，生理学科的期刊开放获取并不能有效提高发表后一年的引用率。这篇文章本身属于开放评论的，通过文末评论我们可以得知，作者后续又追踪了几年，结果依然是不支持提高引用率的结论，甚至2011年的一项&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/21450907/&#34;&gt;研究&lt;/a&gt;发现药学、跨学科研究、人类学等其他学科也有类似现象。也就是说，如果认为开放获取运动提高了引用率是不恰当的，开放获取更多是提供了出版业的利润率。其实我认为开放获取最大的意义在于知情权，公众出钱的研究理应让公众看到结果，付费开放获取与研究机构订阅期刊只是朝三暮四的收费方式差异，只是商业模式的不同存在套利空间罢了。我更看好的是类似 &lt;a href=&#34;https://www.jmlr.org/&#34;&gt;&lt;em&gt;Journal of Machine Learning Research&lt;/em&gt; &lt;/a&gt;这样追求全流程免费且开源的在线出版模式或预印本服务器这种自存档手段，但全志愿者运行效率肯定高不到哪去就是了。总之，开放获取是不能去背影响因子提高的锅的，这属于两个议题。&lt;/p&gt;
&lt;p&gt;那么影响因子的增长情况如何呢？1975年的JCR里，影响因子最高的是&lt;em&gt;Journal of Experimental Medicine&lt;/em&gt;，影响因子为11.874，但2021年影响因子最高的期刊&lt;em&gt;CA-A CANCER JOURNAL FOR CLINICIANS&lt;/em&gt; 影响因子到了286.13。影响因子超过10的期刊在1997年只有49份，而到了2007年就有105份，到今天有660份。我查了一下过去五年的11198份期刊的影响因子，平均值从2017年的2.359增长到了2021年的3.814，就连中位数都从2017年的1.633涨到了2021年的2.551。所以期刊引用大涨是毋庸置疑的，但原因却是不唯一的。&lt;/p&gt;
&lt;p&gt;首先我们知道全球科研活动在过去几十年是增长的，中国科研从业人员直线甚至曲线上升的，人多了研究成果多了，发表自然就多了。学术期刊每篇论文引用的文献数都是两位数起步的，这样发表越多，引用就越多。因为引用明显集中到少数论文里而大多数论文发表就没人看，因此一定会推高头部期刊影响因子的。另一个原因则在于引文工具现代化与DOI流行，现在添加参考文献非常简单，点几下鼠标就能加进去，换格式也很方便，&lt;a href=&#34;https://academic.oup.com/bioscience/article/60/6/455/242286&#34;&gt;研究&lt;/a&gt;显示引用文献数量是直线上升的（见下图）。不过这个很难验证是不是软件的锅，毕竟你问我为啥引用四五十篇，我更可能说是读得多而不是加得方便。科研活动增多与引用增多还算得上正面原因，不过影响因子也是可以操纵的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;images/ifref.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;影响因子工程学大概是所有期刊编辑都听过的术语，最近几年很多期刊转成了专业编辑而非学术兼职运营，这样很多手段就出现了，例如前面说的大量发表影响因子里不算引用项目的文章。不过还有些手段不怎么上台面，那就是强迫引用，一项&lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0187394&#34;&gt;研究&lt;/a&gt;指出，20%的受访学者认为他们受过各种类型的强迫引用，包括但不限于审稿人要求引用相关研究、编辑要求加入对本期刊引用，而这种情况在高影响力期刊里更常见，属于心照不宣的交换。其实有些引用是相关的，但另外一些引用纯粹就是无效引用，例如2017年 &lt;em&gt;Land Degradation &amp;amp; Development&lt;/em&gt; 主编就在其负责的其他期刊的82份稿件里额外要求了622个引用，把影响因子从3.089炒到了8.145。吃相如此难看的案例毕竟少数，但对于发文量不大且编辑话语权比较强的期刊，这种小动作很容易把影响因子炒起来。&lt;/p&gt;
&lt;p&gt;总之，影响因子的通引膨胀现象是值得关注的，倒不是说影响因子本身有多少意义，而更多是对科研评价体系的思考。但我更希望研究者能回归研究本身，提炼有意义的科学问题而不是去刻意追求评价指标，成败帝王事，真假后人传。&lt;/p&gt;
&lt;p&gt;其实我本来是打算写一篇过去五年影响因子分析的，但写个前言到这里发现搞成了影响因子的文献综述。不过我还是把自己的分析结果简单说一下吧，毕竟数据源属于灰色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;研究范围是有2017年到2021年五年影响因子的11198份期刊&lt;/li&gt;
&lt;li&gt;过去五年引用量与影响因子的描述性统计量都在提升&lt;/li&gt;
&lt;li&gt;线性回归发现 4319 份期刊影响因子是线性显著升高的，只有50份期刊线性显著下降的&lt;/li&gt;
&lt;li&gt;提高的期刊平均影响因子小于所有期刊的平均影响因子，说明是普遍性提高&lt;/li&gt;
&lt;li&gt;2021年影响因子排名前1000的期刊有522份期刊在过去5年线性升高&lt;/li&gt;
&lt;li&gt;有些期刊虽然也在升高，但不是线性的（此处有大坑，线性回归检验不出来）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外有些问题可以探索，但我觉得读者可以自己动手尝试下（&lt;del&gt;总不能说实话是我懒吧&lt;/del&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;开放获取期刊的引用是不是更高（验证前面文献结果）&lt;/li&gt;
&lt;li&gt;学科间是否存在引用外溢现象，也就是卷到其他学科&lt;/li&gt;
&lt;li&gt;那些学科在走下坡路&lt;/li&gt;
&lt;li&gt;设计一个更合理的统计量来描述期刊/个人学术水平&lt;/li&gt;
&lt;li&gt;非学术论文类引用概括，例如新闻、软件、博客、推特、会议等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，能看到这的麻烦来填个表吧，到现在还是个位数留言。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wj.qq.com/s2/10408005/9374/&#34;&gt;https://wj.qq.com/s2/10408005/9374/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>指北奖学金</title>
      <link>https://yufree.cn/cn/2022/06/19/keng-scholarship/</link>
      <pubDate>Sun, 19 Jun 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/06/19/keng-scholarship/</guid>
      <description>&lt;p&gt;《现代科研指北》如果不出意外应该会在今年夏天上市，但出版前我需要做下面三件事：&lt;/p&gt;
&lt;p&gt;第一就是收集对这本书的吐槽。这主要是为了配合新书宣发，到时文案里会加进去，希望读过在线版的朋友可以到下面或文末链接留言，正面负面都无所谓，反正最后只会选正面的跟幽默的负面评价，当然负面有助于后续改进。注意只有第一个空是必填的，后面的问题只是为了展示下我拙劣的问卷设计能力：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wj.qq.com/s2/10408005/9374/&#34;&gt;https://wj.qq.com/s2/10408005/9374/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第二就是解释下出版内容与在线内容的区别。印刷版是以2.71版为基础进行修改的，因为涉及出版社的劳动成果，所以很多出版内容并未更新到在线版，但也更新了一些事实上的问题。在线开源版目前版本号是2.718，上面贡献者的改动并未出现在印刷版，有些改动印刷版也做了。由于我顽劣的语文水平，从可读性上而言出版版会更好些，也加了些配图；另外在线版的链接在出版版都去掉了，改为脚注，也因此修改了些表述方式；出版版去掉了词典部分并修改很多调侃内容，主要为了使受众面广一些，很多网络表达方式受众不大，但也保留了一些就当彩蛋了。我之前说过这本书开源版会持续更新，所以内容上跟出版版的差异会随时间不断增大，开源版始终欢迎志愿者参与修改，开源开放对于科研非常重要，大概十年左右如果更新足够多且出版社同意，会再次以某个版本号为基础修改为印刷版，届时会在前言里写入志愿者的贡献。而且开源版本网上会一直公开，不想买书看开源版本完全没有问题。&lt;/p&gt;
&lt;p&gt;第三就是解释下出书动机跟收益去向。出书会有版税收益，但于我而言这部分经济收益对于改变我的财务现状影响很小。这里我的计算方式是统计一年的纯消费开支，包括房租水电衣食住行，这个数代表了我的实际消费需求。另外计算我交的税跟社会安全金但不包括403b还有IRA这种，如果我的实际需求等于我交给国家的钱，那么说明我的收入可以额外养活一个同等消费水平的我自己。一般而言，一个人的收入如果能养活两个自己还有盈余，那么额外的收入带来的幸福感提升就很有限了。2012年美国曾经有调查说收入达到7.5万美金后更多的钱就无法带来更多幸福感提升，换算成今天通胀后的数字大概是10万美金，10万美金收入在美国交的税大概也能养活一个消费需求正常的人。当然，我知道后来有研究推翻了这个7.5万美元的结论发现还是越多越好，而且也有人算出来美国人一年要消费6万美元。不过我不关心别人的消费需求，得益于康州高税收跟我自己租房无车无对象无吞金兽，我自己的三和大神式消费需求（远远低于6万）在我当前收入下是能通过交税再养活一个我的，心理上我并不欠美国啥，而且这个计算方式下也肯定会有盈余来进行额外的保险，毕竟在美国要饭交的收入税还没重到超过一半。其实这个算法应该具有一定普适性，因为论赚钱没个头，但论花钱（排除掉投资跟赌博）正常人还是有个限额的，要么是收入，要么是认知水平，个人开支跟税收等同说明起码不会对社会造成负担，这样看偷税漏税还领低保就显得很不厚道了。&lt;/p&gt;
&lt;p&gt;既然不会实际影响我的财务状况，那么出书的钱就可以拿来做些有趣的事。最开始我想的是给每个买书的人写明信片，从美国寄过去邮费大概还高于我在每本书上收的版税，不过这样做一来不太环保，二来除了暴露我字写得不好这个问题外似乎也没啥正面作用，三来就是这个实验我其实做过一次了，结果就是只有不到1/3的人收到明信片，还大都是美国的，寄海外的大部分都被邮政递送黑洞给吞了，国内好像一个都没收到。&lt;/p&gt;
&lt;p&gt;然后我就想到奖学金了。其实设立一个奖学金并不需要很多钱，人民币十几万就可以每年拿利息的一两千块来奖励一个个体并持续下去。当然，肯定有人觉得我现在没资格搞奖学金，但也没谁说设立奖学金就一定要达到某种成就，我是发钱又不是要钱。所以我就打算拿这本书的版税搞个指北奖学金，以后的开源版的贡献者也要明白，你的名字可能出现在书里，但经济收益被我挪走做奖学金实验去了：&lt;/p&gt;
&lt;p&gt;启动条件：书籍销量达到5万或版税达到15万人民币，所有版税自动形成奖池，形成奖池前版税处于累积状态，只能用于免责挪用（见下一条）。之所以是5万，因为5万是畅销书的门槛，如果不畅销，奖池会可持续竭泽而渔；15万则是从利息角度保证每年能发出钱来，其实我现在都不知道书的定价，如果我订，我选42块人民币，但似乎出版社是彩印的，所以价格我也控制不了&lt;/p&gt;
&lt;p&gt;奖金池管理与免责挪用：奖金池来源有且只有版税。免责挪用1）买这本书印刷版送人，因为出版社送的数目低于我想送的朋友；2）如果我的家人亲友（包括我）生命安全或医疗需要这部分资金（投资买房教育都不算），我会毫不犹豫挪用但也会如实公开；3）如果我跟获奖者见面会用版税报销一顿饭钱，所以最好就别见面了，伤钱。如果奖池金额不断膨胀，那么会提升后续奖金额度或得奖人数。奖金池会用于投资一年的定期存款，发奖用利息，利息不够就要消耗本金。当奖金池金额连续三年低于10万人民币，会把剩余金额全部拿出办一次开放科学的会议，花完了事，那时这个奖学金就停办了，后续版税（如果还有的话）我会找过往获奖者吃饭花光（突然想给自己颁一次奖了）。&lt;/p&gt;
&lt;p&gt;奖金额：3000，每年一个，直接支付宝或银行账户打款，不限制用途，如果当年没找到或拒收就返回奖池，不进行累积发奖或补发，得奖人可以是个体可以是组织或团队，可重复得奖但理由必须不同&lt;/p&gt;
&lt;p&gt;合规性：私人账户发奖，不接受任何捐赠，想办自己办去。倒不是我不想把奖池做大，著名发财宝典《刑法》里有非法吸收公众存款罪、集资诈骗罪两个相关罪名，我就做个实验，还不想成为罗老师的刑法课案例&lt;/p&gt;
&lt;p&gt;透明度：版税的开支我每年发奖前会完全公开在书开源版的issue里，也会写明得奖理由，环保考虑没有任何证书，直接打钱，如果有机会见面我找张餐巾纸给你手写一个，如果获奖者需要推荐信我也可以写，但前提是收推荐信的人最好对我的文字风格有心理准备&lt;/p&gt;
&lt;p&gt;奖励条件：开发了开源科研软件，显著降低了同行的研究成本或科研中踩了大坑，可以宣告某个探索方向完全失败。这里的动机在于当前科研界对于数据分析软件的重视度不够，也过于看重成功的研究。而真实科研中数据分析卡脖子非常常见，只是很多人意识不到，单纯以为做不到。同时，对于成功的追逐容易让科研人心浮气躁走捷径，而更有意义的试错却无人关心避之不及。因此我要奖励那些在当前科研环境下还能静下心来做研究的人，鼓励他们继续做科研，雪中送炭但不会锦上添花。相信这也符合我这本书读者的口味。&lt;/p&gt;
&lt;p&gt;申请条件：无，不用你写材料主动申请，我自己从网上找或从朋友那边道听途说，然后我写邮件联系。也没有什么专家团队去评审，有我也信不过，反正我自己就做科研，成果意义我自己能看明白。当然，你的成果一定要是开源且开放的，不然我也看不到。看起来实际上都是天上掉馅饼的样子，但你需要给我写段必须幽默的获奖感言一同公开（是否幽默我说了算）。请注意查收垃圾邮件箱，大概率跟那些假瑞银员工、伊战老兵遗孀还有中东流亡王子的诈骗邮件混在一起&lt;/p&gt;
&lt;p&gt;这个指北奖学金规定肯定还存在漏洞，欢迎大家随意补充。反正一时半会估计也启动不了，书卖不动我就直接收获一个“滞销书作家”称号；真启动了，我就给自己挂一个“奖学金赞助人”的头衔，所有给开源版书籍做过贡献的都可以挂上。看起来这个实验除了钱怎么也不会亏。&lt;/p&gt;
&lt;p&gt;再次放下吐槽收集链接：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://wj.qq.com/s2/10408005/9374/&#34;&gt;https://wj.qq.com/s2/10408005/9374/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>引用</title>
      <link>https://yufree.cn/cn/2022/05/03/citation/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/05/03/citation/</guid>
      <description>&lt;p&gt;今天打开谷歌学术，发现多了个里程碑，引用超过了1000。说来惭愧，我用了十年时间才累积到这个数，但里面没有一篇引用超过100，而且大多数引用多的也不是我的工作而是合作文章。而且谷歌学术是出了名的引用数据有问题，他们有时并不能很好区分学术期刊的质量，所以如果用一些文摘数据库来查引用也是到不了1000的。像我这种没有一篇成名作却混到谷歌学术上千引用H指数过20的，可以算是一种学术老油条的要饭标配了。&lt;/p&gt;
&lt;p&gt;一般而言，引用通常是会比发表更能说明学术影响力的，因为绝大多数论文发表后的所有读者就是自己与审稿人，同行看不看完全看眼缘。一般而言，最后能留在学术界的在博士毕业就要有过百引用，做几年临时工达到过千引用可以找正式工了，总引用上万的不论哪个学科都是话事人级别的。这说的是平均水平，而显然还是有马太效应的，少数人博士上千引用也不是没有。想累积引用数，需要同时保证持续写论文而且论文有人认可，这其实还挺难的。不过引用也有很多种，不同类引用价值也不一样：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;前言类引用。这类引用更多是作为气氛组的，比较保险的方法是引用最近3-5年内的综述文章。也有人喜欢引用自己之前的文章作为背景，这可能是看不上别人写的东西，也可能是怕引到了带有负面评价文章。很多人为了提高引用率会把自己或朋友的论文放到引用气氛组里，这类引用就属于刷数据了。一篇文章引用的文章里八成都是这类引用，就是为了凑背景，很多都是写文章时现用搜索引擎找的，有的可能就读了个摘要就放进来了，反正现在插入文献都用软件，非常简单。这类引用的泛滥是近期所有期刊影响因子都通胀的一个重要原因，另一个原因是搜索引擎的广泛使用开拓了视野，毕竟互联网技术降低了门槛，提高了学术圈的信息流动率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;地基类引用。这类引用是引用了业内经典方法或自己前期工作构建的方法，这类引用是用来表示自己的工作基础的，也是省字数用的。大部分研究都是基于之前的工作继续推进，所以如果文章能作为别人的地基类引用算是得到了学术圈的部分认可或验证。被引用的文章通常会是业内的高引用文章，经常被课题组组会集中讨论或解读。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;评论类引用。在综述文章里如果对某篇文章进行整段评论算是文章获得部分江湖地位了，当然评论得是正面的。在研究论文里也存在评论类引用，会出现在前言与讨论里，有的时候是当靶子的。要是自己之前的文章还好，算是自己挖坑自己填，要是拿别人文章当靶子，那小圈子里就大概率会有内战了。我见过几次小学科内战，多数都是一方和平认怂，但也有几次算是搞出了门派差异，互相老死不相往来。评论类引用的文章一定是被写文章的人反复读很多遍才敢下结论的，很可能都有过邮件沟通。不过，我注意到很多人在引用文章时其实解读原始文章是有问题的，很多为了显示自己方法的优势刻意强调前人工作的劣势，而如果去读前人工作会发现他们早就讨论过这个优劣问题了。这类引用如果被内行看出来是败人品的，这种小动作非蠢即坏。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;审稿类引用。如果你读文章发现突然有一部分集中引用了某个非作者的文章但跟文章又不搭边，那大概率是为了讨好审稿人才引用的。其实严格算这属于学术不端，审稿人是不应该带私货的，但这东西很难取证，只能等公开审稿风气再流行下大家都实名审稿并公开审稿意见才行。不过有些审稿人提出的文献也确实是他们审稿时用审稿系统的相似文章搜索或基于自己经验搜出来的，也是有价值的。很多时候也存在作者为了规避负面评价故意不引用某些文章，这种一般都会被审稿人发现，除非审稿人不称职。不过大同行审稿其实经常出现这种审稿人不靠谱的情况。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在一篇论文几十个参考文献很常见，八成是描述事实或背景的，一成是描述研究地基的，剩下的大都是审稿类引用，评论类引用其实非常少。很多论文就是个排列组合缝合怪，作者也根本就没有学术观点，所以通篇可能都找不到评论类描述。很多人觉得这样写谁都不得罪，但这种文章大概率也不会有人读，被引用也都是放在气氛组里。所谓论文，还是要有自己假说跟科学问题的，可以没有结论，因为通常一个问题能揭示清楚就很不容易了，结论比较模糊也正常。但是，论文没有讨论只有前言、方法与结果是不行的，这就成了技术报告了。还是要聚焦到科学问题上，例如环境领域可能就是某种污染物的健康危害具体是什么，单纯报道其环境浓度意义非常有限，不过首先发现的话还是可以发表的，但后续研究如果找不到具体科学问题或危害就尴尬了。&lt;/p&gt;
&lt;p&gt;所谓科学前沿，是观点多事实少的，有了事实支撑的观点才会形成论文，但一定是要有个假说在前面放着的。不能说只列举事实而羞于表达学术观点，自然科学也有学术观点存在的，没有观点讨论就不会有学科发展与进步。当前的学术界存在很多问题，内部的僵化就是一个表现，很多职业科研人员非常懂忽悠钱的坐牢小技巧但却很少去思考更大的问题，不去讨论看得见的难题反而致力于解决显示不存在的科学问题来维护自己的学术生态位，学科间会有重重壁垒来营造内部舒适圈。如果我们从时间尺度上看，未来这类固步自封的研究很可能会自然衰退掉，这个世界没有无限的资源去满足无穷尽的好奇心。&lt;/p&gt;
&lt;p&gt;我这一千条引用里其实被评论的非常少，大部分人引用文章都是拉来做气氛组，这就像是学术界里的引用泡沫，现在看没有任何会被戳破的迹象。不过，小同行间其实都很清楚引用这东西是拿来给外行做评价的，最新的成果很难短时间大量被引用，没有任何前瞻性可言，真正好的研究带给人的震撼是阅读产生的，如果无法体会智慧火花的美也就没必要委屈自己在科研圈要饭了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>工具变量</title>
      <link>https://yufree.cn/cn/2022/03/05/instrumental-variable/</link>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/03/05/instrumental-variable/</guid>
      <description>&lt;p&gt;最近审了一篇代谢组学文章，作者使用了 Mendelian randomisation 分析并将其作为文章亮点。尴尬的是我没听说过孟德尔随机分析，不过一看描述就知道这是工具变量加壳，再次不得不感慨于学术界造词的能力。&lt;/p&gt;
&lt;p&gt;其实工具变量这个思想更多是搞社会科学特别是经济学的人在用。打个比方我观察到了巧克力消费量与诺贝尔奖获得数的相关关系，很明显应该是存在一个混杂因素同时导致了巧克力消费量与诺贝尔奖获得数，例如社会经济发展水平等。那么一个思路就是找一个单纯指示巧克力消费量例如人群中某个喜爱巧克力的保守基因却不被社会经济发展水平影响的变量，这样因果关系就成了：&lt;/p&gt;
&lt;p&gt;爱吃巧克力基因 -&amp;gt; 巧克力消费量 -&amp;gt; 诺贝尔奖获得数&lt;/p&gt;
&lt;p&gt;此时，即使存在未知混杂因素，我们只要去计算基因与巧克力消费量的相关性、基因与诺贝尔奖获得数相关性两个数值，然后用后者除前者就可以得到巧克力消费量影响诺奖获得数的真实影响了。具体来说，如果基因影响消费量的回归系数是0.8而基因影响诺奖获得数的回归系数是0.1，那么巧克力消费量影响诺奖获得数的系数就是0.1/0.8 = 0.125。但如果你直接测巧克力消费量跟诺奖获得数，你得到的系数可能是0.6且显著，而通过工具变量就可以把这种混杂因素存在影响的相关性直接找出来。当基因影响诺奖获得数的回归系数根本就不显著时，其实就已经暗示了后面那个相关性是存在混杂变量的了。&lt;/p&gt;
&lt;p&gt;如果你去读使用工具变量的经济学论文，会发现整个论文的绝大部分篇章都在讨论工具变量选择的合理性。一旦这个合理性论述充分，后面的计算其实非常简单，并且可以给出效应大小的估计。不过这倒反映了经济学研究的一个难点，那就是工具变量在混杂因素不明确的时候非常不好找。&lt;/p&gt;
&lt;p&gt;流行病学也面临同样的问题，当我们打算将某种生活方式跟疾病联系起来的时候，经常是找不到合适的混杂因素来进行控制，很多同时影响生活方式跟疾病的因素可能根本就不出现在调查量表上。但好在现在基因测序很方便了，我们可以直接找到一些保守基因来对应一些行为，基因虽然也会受环境影响的调控但更多时候还是受遗传影响的，具备人群尺度上的稳定性。如果我们找到相关指示基因，就可以用其作为工具变量来排除掉未知混杂因素的影响。在我看来，这是基因组学跟社会科学能产生1+1&amp;raquo;2效应的一个非常好的应用前景。只不过你很难跟社会科学家解释清楚啥叫snp，对于搞基因组的，跟他们解释工具变量也不太容易（但应该是比反方向容易些）。&lt;/p&gt;
&lt;p&gt;因此，搞流行病的人就提出了所谓的孟德尔随机分析，其实就是找一个跟流行病中的暴露直接因果相关的基因作为工具变量来计算暴露的真实效应。不过这经念到代谢组学就变味了，因为代谢物的水平变化是同时受暴露跟基因影响的，你直接说拿代谢物当工具变量因果逻辑就不通。想拿代谢物做流行病学的工具变量，首先要做的是证明这个代谢物直接影响某种暴露，这个需要的是实验室随机对照实验证据。但我在查阅资料时发现，伟大的科学共同体在创造孟德尔随机分析时竟然顺道给它提供了因果发现的功能，实现了1+1&amp;lt;1的效果。&lt;/p&gt;
&lt;p&gt;这事大概是这样的：某天一个做工具变量研究的人给做流行病的人做了一场报告，然后做流行病的人就凑上去问是不是只要有分子层面的证据就可以拿来做工具变量，然后大概这个做工具变量研究的人只具备统计背景而没有科学背景就满口答应下来了，之后他们之间就开始了合作。流行病学专家找人测了一大堆分子指标也就是各类组学塞给了工具变量专家，工具变量专家拿来一看也懵逼了，咋这么多存在因果关系，那我就当成一个多重比较的假设检验来做吧。之后，工具变量专家就把那些存在显著性相关的分子指标作为工具变量返给了流行病学专家。流行病学专家一看，淦，不愧是统计学大师，果然给我们找到了因果推断视角下的工具变量，快些投文章发表。期刊审稿人拿来也懵了，啥是工具变量？合作者有个统计学家，听专家的不会错，过！然后其他流行病学专家一看，不行，这么先进的技术我们也得有，找人合作！然后一个兼具因果发现与因果推断功能的孟德尔随机分析就成了学术热点，大家依样画葫芦都这么做。&lt;/p&gt;
&lt;p&gt;可问题是，验证分子指标与暴露因果关系的实验从头到尾都没做，这因果关系竟然在一片互相信任的氛围里给搞成言之凿凿的证据了。你别觉得我在这开玩笑，我审的稿子就是讲如何用代谢组学数据进行孟德尔随机分析来找因果关系的，你哪怕对同一批样本的基因组跟代谢组先来个关联分析证明下因果关系的存在或证明下代谢物的保守性我都能说你用心了，现在啥都不干直接说这是文章亮点，这过分了啊。被他们跳过的因果关系证明却成了他们的结论，怕不是 Sir Humphrey 的远房亲戚。而且，要知道工具变量是解决混杂因素的问题的，通篇竟然没提到自己研究中是否有混杂因素，这好比你拿了个锤子去拧螺丝，解决了个寂寞。&lt;/p&gt;
&lt;p&gt;科研里面不担心你去搞排列组合，但起码这是科学研究不是数学研究，很多排列组合科学上的合理性是必须要先说清楚的。你啥都不管就调包分析肯定是能给出数据，但毫无意义。我们已经培养了太多搞排列组合投机取巧的研究人员，他们打着跨学科的旗号已经输出了无数的学术垃圾，如果还搞这种类型的跨学科合作，那么只可能形成一些自娱自乐的小圈子互捧臭脚，真正的科学问题还是得不到解决。这里我还得例行黑一下一些搞统计的人，你们在做方法迁移时一定要搞清楚背后的科学原理，不要认为自己手握开所有学科的后门的钥匙，科学研究是直面科学问题的，这个问题因为有很高的复杂度需要大量的背景知识来降噪，而搞实验跟临床的研究人员经常把新统计方法当成神奇魔盒，这两者之间交流存在很多想当然的设定，一定要把问题掰开揉碎了讲清楚再说。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>质谱组学数据的批次效应</title>
      <link>https://yufree.cn/cn/2022/01/27/ms-data-batch-effect/</link>
      <pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2022/01/27/ms-data-batch-effect/</guid>
      <description>&lt;p&gt;组学数据的一个显著特征就是需要同时测定一个样本里成千上万的信号，这个信号可以是基因、蛋白或代谢物。但这是说给外行听的，真实数据对于基因组来说一个基因对应测定的可能是十几个碱基序列片段或测序信号，对蛋白组来说一个蛋白的数据需要从众多肽段重组出来（也可以直接topdown测定，勿杠），对代谢组而说一个代谢物能产生十几个包括同位素、加合物、寡聚体在内的质谱峰。但凡分析化学背景出身的研究人员都会特别关心测量上的质量问题，因为如果本来就测得不对，后面的统计方法或可视化方法再怎么天花乱坠都属于空中楼阁。&lt;/p&gt;
&lt;p&gt;不过，真实情况要复杂很多。就算一个样品只需要20分钟分析，50个样品需要加上空白与混合样进行质量控制，一般每10个样品就需要进一针空白与混合样，这样实际要进样60个，考虑上每次进样前后都需要一些混合样来稳定柱效，这一批样品大概要跑24小时。每天50个样品连续跑一周也就能跑三百多个真实样品，但凡用过色谱的都知道一根柱子跑上几千个样品后基本也就该换了，连轴转的实验室基本半年一换。而且，做过分析的都知道，连轴转要比断断续续做对仪器稳定性来说更好，但即使再好，同一个样品隔一周测一次也能看到明显的变化，有时候是信号逐渐减弱，有时候则是响应突然断崖式跌一个数量级。从我个人经验而言，即使连续进样的数据也会出现类似状况，更不用说应对那些队列数据。&lt;/p&gt;
&lt;p&gt;队列数据收集起来不是一次成型的，所以样品天然就存在不同批次。今天采血的大哥拔针偏慢，下次采血的大姐喜欢快速收针，很容易造成样品天然背景就不一样。这时候即便你把样品混到一起随机进样，看到的也是基线高高低低的总离子流。不过这都不算事，因为队列数据经常不是同一时间收集的，所以要么攒到最后一起测，要么凑一波几十个样先测，前者需要保证样品储存不能产生影响，后者需要保证不同时间分析的仪器出信号要稳定。巧了，这两个保证现实中一个都做不到，即使零下八十摄氏度保存代谢物也会出现差异（我在实验室验证过），而仪器前面说了，隔一周都不够稳就不用说隔几个月甚至几年了。在论文里大家都会说是稳定的或者换个方式说“尽最大可能保证稳定”，至于不稳定的部分，学术界目前都是回避讨论。所以，用流行病学样本里的分子证据来证实某种疾病的机理是很困难的，一般都需要实验室条件下用老鼠或细胞实验来反复验证。我称之为测不准原理，不懂测量分析的研究人员容易沉浸于理论的逻辑自洽中，真实数据里的因果要比假设的复杂得多。&lt;/p&gt;
&lt;p&gt;好了，既然提到批次效应，我们就要想办法去掉这个影响。做目的性分析出身的人往往很不屑，因为他们有内标法。内标法一般是用稳定同位素标记过的物质在样品进样前加入，所有测到的目标物的响应都要去除内标的响应，这样如果分析上的波动是来自于仪器的不稳定，那么内标控制后的响应就可以排除掉这部分影响。不过内标法有一个前提，那就是标记物质与待测物在仪器上响应因子要一样，原汤化原食。但到了非目的分析，开全扫描模式，你根本不知道待测物是什么，此时加入内标并用内标矫正所有峰响应就属于胡闹了。不同物质的离子化过程是有差异的，在同一样品基质下，有些是信号增强，有些则是信号减弱，你要是用信号减弱的校准信号增强的，那么增强的信号就更强了。我到现在也不是很明白为啥有些非目的分析的研究中还在用内标，不是说内标没用，而是内标能校准的东西太少了。&lt;/p&gt;
&lt;p&gt;真正有用的混合样，也就是每一批次的样品都取出10微升来混成一个样，这样的样品应该会包含所有样品里的物质。那么，我们只要隔10个样品进一针混合样，然后就可以得到混合样里每一个物质的变化趋势了，然后只需要将这个变化趋势去除掉，剩下的就是样品物质的真实生物学变化了。这里需要注意的是这个变化趋势要是明显的才有矫正的意义，举例来说A物质在整个进样序列里的混合样中一直下降，那么对多个混合样里A物质的响应与其进样顺序做回归分析就会看到一条斜率为负的回归线，此时代入样品的进样顺序就会给出在这个回归线上的响应。所谓去除批次效应，就是用样品的真实响应去扣除掉进样顺序回归产生的响应。因为每个物质的质谱响应行为不同，所以回归线也不一样，有线性的，也有非线性的，但这个回归线的物理意义就是来自于进样顺序或批次的影响。因此，如果你进样序列里有混合样，那么后面发现批次效应就可以用这种方式进行原汤化原食的矫正。&lt;/p&gt;
&lt;p&gt;不过，有些实验数据过于莽撞，根本就没加入空白或混合样，这样有没有办法进行矫正呢？也有，但不全有。如果我们知道样本分组的话，那么数据还有救。所谓的样品，不过是一堆存在异质性的数据，如果我们的目标是寻找样品分组差异，那么所有不同于分组差异的显著性趋势都可以归类为某种批次效应。这样对多个物质而言，我们就先构建一个模型：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$响应 = 分组差异 + 其他差异$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这样我们就得到一个其他差异的初始值矩阵，然后我们对这个其他差异的矩阵进行主成分分析或svd分解，这样就可以提取出其他差异中的主要趋势，然后我们构建下面的模型：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$响应 = 其他差异主成分+分组差异+剩下的其他差异$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;拟合这个模型，然后继续在剩下的其他差异中找主要趋势，这里需要设计一个显著性的统计量，当统计量不再显著后就停止寻找，此时的模型就成了：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$响应 = 分组差异+其他差异所有主成分$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;此时，我们只提取分组差异就可以了，这个迭代过程就是替代变量的构建过程，这个方法可以在没有混合样但知道样品分组的条件下进行批次效应控制，效果非常好。那有朋友就会问了，如果我不知道分组差异呢？那我反问一个问题，你怎么知道存在批次效应呢？此时样品的波动究竟是来自于批次效应还是样品本来的差异根本就没法知道。如果你确定来自于批次效应，那么其实直接构建下面的模型：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$响应 = 生物学差异+批次$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;就可以了，但你至少也要知道批次或进样顺序，如果都不知道，我甚至都不知道你有什么理由认为存在批次效应。对于非目的分析，批次效应的难点在于不同物质的效应不一样，没办法用单一方法进行矫正，但这不代表盲目矫正就是对的。通常而言，如果你已经看到了批次效应，那么这个趋势就应该是可建模识别的，否则你根本说不清楚究竟是批次效应还是样本异质性导致出的现象。现在出现了很多自动化的批次效应检测矫正工具，且不论其中大部分都是重复造轮子，很多工具设计者本身就没有理解批次效应的复杂性简单进行函数套用来自动化决策过程，这种工程思维对软件开发是没问题的，但对科研是很不负责的。话虽这么说，这样的事其实我也没少干，这也是最近我在反思的问题，工具永远不能替代思考，否则人会陷到机械流程中无法自拔。&lt;/p&gt;
&lt;p&gt;此外，现在很多研究人员会只做目的性分析的代谢组学，也就是只去测定已知代谢物的数据并进行讨论。其实这是个聪明的选择，因为非目的分析通常会被物质鉴定卡住，做到最后其实也只能给出已知的在谱库里的数据，这只是另一种形式的目的性分析。不过，组学数据如果最后只能用已知信息来给出结论，那么额外测定的信息其实毫无价值。这可以部分解释为什么基因组或测序总能发现新东西而做蛋白的都喜欢光源冷冻电镜，代谢组学则始终在方法学层面打转，不是小分子里没有生物信息，也不是提取不出来，而是提取出来数据库里没有就给扔了。而且数据库匹配现在也是玄学，很多化合物标准品的谱图长一个样，放到生物样品里加上基质效应加上不同仪器状态就变另一个样了，考虑到代谢组学样品前处理跟没有差不多，就算你测到了已知物可能都无法匹配出来。&lt;/p&gt;
&lt;p&gt;这些现实存在的问题都需要解决，只进行“聪明的选择”永远也回答不了最难的科学问题，只是现在的我有点怀疑：是不是有些东西就是永远也测不准呢？如果是的话，那科研就一定要想办法与这种永恒的不确定性共存并寻求发展，这也是过去两三百年科学家们一直在做的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>基本上无害</title>
      <link>https://yufree.cn/cn/2021/09/20/mostly-harmless/</link>
      <pubDate>Mon, 20 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/09/20/mostly-harmless/</guid>
      <description>&lt;p&gt;“基本上无害”既是《银河系漫游指南》五部曲的最后一本的书名，也是《银河系漫游指南》里对地球的描述，最近我是越来越体会到这个描述的准确了。&lt;/p&gt;
&lt;p&gt;先看看科研，我以前经常揶揄现在的科研是定语式研究，毕竟通用规律大概率别人已经发现了，所以职业科研人员很多都去搞细分领域了。举个例子，活性污泥法这种城市污水处理手段已经应用了一百多年了，到现在也是新污水厂设计时首先被考虑的技术路线。那么搞污水处理那帮人这些年都在干什么呢？大多数是在做某一类污染物的定向去除，特别是引入纳米材料，这种研究就属于基本上无害的那种。实际应用中除了特种行业废水，量比较大的其实是生活污水，生活污水处理厂极少会为了特意去除掉某一种污染物而加一道工序，更不可能去加一个成本很高而且本身也具有反应活性有可能产生新污染的材料。活性污泥能用超过百年，一个重要原因就是活性污泥里的微生物基本啥都吃，对大多数有机物都能降解，那么有人问了，遇上微生物不降解的呢？微生物都不降解，它基本就可以认为是环境惰性物质啊朋友，好比咖啡杯里的茶渍，你如果拿肥皂都洗不掉还要担心正常喝水会摄入吗？当然，这类物质里比较特殊的是持久性有机污染物，因为不被代谢消化，所以可以在生物体内富集产生慢性毒性风险。但相关流行病学证据通常也是定语式的，例如在某年龄段某性别某种族某BMI范围里能看到风险，说句不好听的，只要你人群分的足够细，喝水可能都有风险，这种研究经常是辛普森悖论重灾区，全看你的因果图来讲故事。当然，持久性有机污染物对生态系统的影响倒是很直接的，例如蛋壳变薄、性别单一化这类，但这就不如跟人相关的研究更吸引经费。&lt;/p&gt;
&lt;p&gt;那么结果就很有意思了，做水处理的人通过对处理材料与目标污染物进行排列组合发了一堆文章，但这堆纸从产生的那一刻基本就可以说是废纸，现实中不会产生任何真实影响。但这类研究却是最四平八稳的职业规划，有新意没用处的东西不会触及任何行业利益，但会成为某个细分领域的专家，增加学术影响力，解决行业内就业问题。要是真去做那些现实存在的科研难题，例如氮磷去除，卡脖子的反而不是技术，而是行业利益，氮磷超标问题的源头在农业，真要去限制那就是跟化肥厂或农民过不去了。因此，“基本上无害”的定语式研究将可能会长期存在于学术圈，毕竟谁也不得罪，还解决了部分高学历人才的就业问题。毕竟现在学历通胀还挺厉害的，真让一帮人去攻克真的难题，他们可能马上就会暴露出真实能力，当然他们也不傻，可以创造一些“专业术语”来体现专业性。基本上无害的研究最安全，也最容易在现代分工社会存活下来，真去做那些面向问题的课题，按照各行各业“成功引导成功”的逻辑，估计只有三个下场：初期运气不好，没做出成果，后面拿不到经费，黯然离开学术圈；初期运气不错，做出成果，但得到学术界认可需要十几甚至几十年，只能去做基本上无害的研究续命；初期运气不错，学术界认可也很快，但动了当前利益集团的蛋糕，被行业在学术界代理人打压，然后去做基本上无害的研究续命。&lt;/p&gt;
&lt;p&gt;究其本质，学术进步跟现代社会的可持续性是有矛盾的。作为职业，你得有持续的输入输出去养活团队，但作为研究成果经常面对的是长期输入零输出或运气好了有输出。只有后者需要你的科研能力，前者需要的其实是现代企业制度，从国家写本子拿钱，招学生买设备做项目，结果出来了在学术期刊上发表，然后用这个成果证明能力后继续写本子拿钱，完成“成功引导成功”的闭环逻辑。与之对应的企业逻辑就是从投资人那里拿到天使轮，然后招团队推出新产品，投放市场后盈利，上市后投资人退出从股市债市募资继续推出新产品，完成逻辑闭环。不同的是，学术界不需要得到市场的检验，毕竟也不是每个人都能读懂学术论文，这就导致学术界可以通过圈子化来保证即使科研能力不足或断档也可以有持续的成果输出，也就是进行基本上无害的研究或者说俗称的灌水。所以事实上也不能说基本上无害的研究一定是浪费资源，更多是学术界从业人员维持生存的一种策略，说不定哪天来个天赋异禀的学生就能做出很好且有用的结果。如果想追求每一个项目都成功且都很重要，那需要运气，但现代社会搭出的这套法律市场体系规则其实是在尽力弱化运气的影响来提高整体稳定性。说句极端的，只要自然资源允许，现代社会甚至可以在毫无学术进步的条件下持续运转。学术系统嵌入到现代社会分工构架里当然有不合理也不理想的部分，但要是不嵌进去，中世纪那一千年里西欧教会就给我们展示过会有何种的生活。也许对生活在那个时代的普通人而言都一样，他们买赎罪券，我们刷短视频，但对于做学术的人而言，那就是是不是要被烧烤的问题了。&lt;/p&gt;
&lt;p&gt;好，吐槽完学术界，我们来看看消费品市场。我曾经非常关注电子商品的更新换代，但大概十年前开始我就不关心电脑了，五年前我也不关心相机了，两年前我连手机都不关注了。原因很简单，现在商家宣传的点基本上都是有它没它都过年的功能，高刷新率，高分辨率，广音域……说句不好听的，成年人到了年龄很多频率段生理上已经不可能听到了，这时候你去买个玄学耳机没意义了。性能过剩时代厂家有两个策略，一个是创造新场景与新需求，例如开发更耗资源的游戏；另一个就是重金砸营销，创造品牌的高级感来维持溢价。这两个策略前一个必然走向小众，不信你去比比switch跟ps5销量，后一个策略基本一手缔造了当前的情绪化的后现代主义时代，一定要不断刺激消费者的敏感点来产生情绪进行非理性的冲动消费。真要理性了马上就会发现很多消费品本身不值钱，钱都拿去买安全感跟认同感了。消费本身就是新的宗教信仰，它许诺你只要给钱就带来幸福或者比别人更好的生活，通过铺天盖地地广告来布教，一旦你接受了品牌价值这种上香方式，不用等来世就会体会到当下的幸福感。不高兴了，买个包；失意了，买个表；痛苦了，买个醉；无聊了，剧本杀……从来没有那个宗教可以做到这个程度的有求必应。只是别忘了，这里的有求必应跟宗教一样都是心理安慰，地震来了保命的还得是求生技能而绝对不会是包、表与酒。&lt;/p&gt;
&lt;p&gt;消费品里的噱头很多，但它们也是有底线的，那就是基本上无害。最明显的例子就是保健品，保健品虽然不会有什么效果，但也不会吃死人。很多保健品宣传的疗效价值都远远高于其自身价值，但售价却是按宣传的疗效价值来定的。所有按受众预期定价的商品都有巨大的套利空间，因为本质上卖的不是商品，而是商品背后的幸福感，这玩意所有人都乐意出高价来买。你说你卖块石头收一万会被打，但要说象征永恒的爱情就供不应求，普通人谁会缺石头，缺的是石头背后的隐喻。很多人明知上当也要买，不见得是自己不知道这玩意没用，但他们更怕的是别人知道自己过的不幸福。越是喜欢炫耀的人，越是要依赖被炫耀的东西来获得外界的认可，当然这类商品不能是有害的。这里我的描述是中性的，因为似乎所有人都会需要外界认可，不然吃饭都成问题，但要是过于依赖就属于想不开了，依赖水、粮食、药品我都能理解，依赖个基本上无害的石头，没它就活不下去就有点可笑了。&lt;/p&gt;
&lt;p&gt;其实另一个大类的基本上无害的东西是中成药，这玩意就完全是被医药行业绑架了。中国的医生收入跟美国比差距是超过一个数量级的，当然付出的学习成本也有差距，不过整体而言比国外同行比较会亏。然而，国内其实也通过某种方式补贴了医生，那就是开药。但正经八百的医生都是宣誓过或有底线的，是药三分毒，此时中成药就应运而生了。一方面，很多中成药的有效成分其实是里面的西药，另一方面，很多中成药本身就是基本上无害的，其效果不易验证。这样医生开中成药的处方就既可以良心上过得去，还不用涉及收红包这类违规行为，而且也能事实上提高收入，通常是以科室提成的方式进到收入里去的。要是真砍了中成药，估计公立医院一半多的大夫要辞职转行，更不用说相关药企跟药农。这个问题还容易上升到中西医对立的层面上，其实背后是利益对立，如果医生收入不与药品挂钩，那么相关讨论应该会更理性些，走循证医学口就可以了。而且说句公道话，中成药基本上无害不代表完全没用，就算安慰剂还可以通过调节心理改善免疫力起作用，人的天生功利性会自动给物品赋予价值，心理上拥有物品后很多时候就是能体会到满足感，每次我买书都是这感觉，后面看不看就两说了。&lt;/p&gt;
&lt;p&gt;基本上无害的出了具体的东西还有抽象的规则。很多机构里行政部门其实本来就是可有可无，但他们自己显然不会这么认为，因此会创造出各种例会还有官僚主义的流程与任务来显得很忙。这些会你要说没用吧，但也确实没害处，你要说有用吧，但凡开过例会的都知道除了让中层清点下人头看是不是有迟到的效果外基本也不会产生啥价值。如果你从事的是需要个人思考的创造性劳动，这种例会简直就是灵感绞杀机，关键时刻被叫去开会讨论任务分配其实反而是阻止任务完成的最重要阻力。很多职位的存在并不是因为职位很重要，而更可能是部门领导想多招人来扩大自己的权力，部门人数多了是可以达到想开都开不掉的效果的，而且反而会得到更多的资源。很多部门的核心效率其实只依赖很少的人，其余的老实划水配合下就好了，最怕的就是该划水的突然意识到自己应该发声，那基本就要进入官僚主义的无底洞了。大型机构里为了维持正常运行招人通常是在资源允许条件下尽可能冗余的，假期同时少上几个人完全不影响运转，这些人就属于基本上无害的那一类，在大型机构里招人是职位选人而不是人选职位，定位要清晰。小型机构也不是不想多招人，但资源不允许，经常一个人当两个用。&lt;/p&gt;
&lt;p&gt;现代社会里出现“基本上无害”的流行几乎是必然的，当体制形成后，其所有的努力都会放在维持自己身上。不过，“基本上无害”作为一种生存非必需品也是一种有意义的理念，如果没有基本上无害的研究项目，那么很多课题组可能撑不到在重大科学问题上出结果；如果没有超额的利润吸引去生产基本上无害的消费品，很多阶层间流动性就会完全丧失而变相威胁体制；如果没有基本上无害的行政部门去缓冲，很多员工就很难找到漏洞摸鱼产生有意思的兴趣爱好……我不是一个唯进步论的爱好者，单纯强调效率或梦想或完成任务在我看来都没必要，但对“基本上无害”的东西也没有绝对的反感。毕竟，基本上无害。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科学传播</title>
      <link>https://yufree.cn/cn/2021/08/04/sci-communication/</link>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/08/04/sci-communication/</guid>
      <description>&lt;p&gt;《自然》杂志最近启动了与《科学美国人》杂志的新合作项目，发表论文的作者可以付费（2999美元）让专业的科普作家为你在《科学美国人》杂志上写一篇研究摘要，这份研究摘要可以展示在《科学美国人》的网站且被其推特账户推荐。&lt;/p&gt;
&lt;p&gt;在过去的几年里，学术出版受到了包括开放获取、预印本、社交网络、数据共享等在内的多种趋势影响，大的出版集团开始寻找售卖全文或文摘数据库之外的商业模式。为了应对很多基金对开放获取的要求，原来需要读者付费才能读的文章现在正变成投稿者付费公开的模式。同时，各大出版集团也加强了不同层次论文的分层稿件转移与录用模式，只要数据没问题，一篇论文总会最终被发表在各出版集团自己的框架内提高影响力。因此，短时间内各大出版集团都推出了自己的新期刊，这些期刊共同的特点就是付费开放获取与雇佣职业编辑而非兼职编辑，前者保证了盈利而后者保证了稿件处理效率。&lt;/p&gt;
&lt;p&gt;《自然》杂志新推出的这个付费功能则是进一步迎合当前公众对科学传播的需求来赚钱。科学传播其实一直是研究人员的短板，很多重要的工作公众不关心也不知道，结果会反过来影响研究人员从国家拿到经费的份额。公众的注意力其实长期以来被生活娱乐类新闻占用，过去二十年互联网技术在全球范围内的普及同时拓展了读者与内容创作者的接触面，因此对科技、科研进展感兴趣的人确实需要科学传播行业来满足需求。科学知识的受众并不只是那些学历低的人，还有大量对新发现新知识不清楚的人，如果科学传播不到位，那么盲从、宗教与阴谋家就会用他们的叙事来占领宣传阵地。不过，当前专业研究人员虽然跟同行学术交流问题不大，但是跟公众交流是存在一些术语与思维模式上的障碍的，这也就不难理解《自然》与《科学美国人》的合作来帮助专业人士与公众沟通。&lt;/p&gt;
&lt;p&gt;不过，台面上是引导沟通但台面下却都是生意。2999美元实在是太贵了，不过对比《自然·通讯》这份作者开放获取期刊的在美国与大中国区5560美元的版面费也似乎还过得去。对于研究人员而言，想同时让读者开放获取并让公众读懂，需要付出约5.5万人民币的成本，而我国目前自然科学青年基金每个研究项目也就是15到30万人民币的总预算，这些付费服务算是学术界奢侈品了。过于昂贵是很多研究人员对开放获取持负面态度的原因，加上有些开放获取期刊基本收钱就发的，这就形成了所谓“掠夺性”期刊的说法，很多研究人员会抵制这类投稿。大出版集团利用已经形成的期刊影响力来搞科学传播上的二次盈利，有点利用垄断地位空手套白狼的意思，不过不论读者还是研究人员似乎也没得选。&lt;/p&gt;
&lt;p&gt;除了大的出版集团，很多民间学会也运营着非盈利的期刊，这类期刊或者向学校图书馆收费、或者是通过会员费或赞助运营。不过，因为期刊运营存在很多非职业编辑，运行效率非常低下，对新技术的接受度也低，很多期刊最后会逐渐衰落被大出版集团收购转为职业编辑运营，就像是学术期刊的新陈代谢。事实上，职业编辑大都是学术界外溢的高学历人才，在一定程度上为不想继续学术研究但对研究还有兴趣的人提供了新的就业途径。除了编辑，这里面提到的为学者给公众写文章的人也大都有科研背景，至少也是硕士学位，毕竟传统记者或媒体行业人士很难看懂学术论文。其实这类人才目前市面上的可以说都是野生的或兴趣使然的，不过因为做的早慢慢也就形成了最初的所谓职业人士。&lt;/p&gt;
&lt;p&gt;在美国科学传播的主力也包括这类自由撰稿人，他们大都有科研经历与人脉，可以直接跟专家沟通翻译成公众听得懂的语言。其作品会被报纸或杂志刊登，后期也会按主题结集出版，你经常能在书末看到notes这个章节，里面密密麻麻记录着书中很多观点数据的出处，这跟论文参考文献还不太一样，因为notes里有时候会有很详细的解释，可以看成参考文献的加强版。不过这个行业在国内还不成熟，基本都是些自媒体或新媒体在做，有的过于专业，有的则过于简化。我个人认为这是个吃经验的职业，很难从学校或各类写作课里培养，每一项研究都有自己的特殊性，如果研究者自己说不清楚，让外人讲解要求其实很高。其实按说这事就应该研究者自己来，工具层面现在都有免费的平台，不过我们现在的研究培养体系里这方面其实是缺失的，这给了出版集团盈利的空间。&lt;/p&gt;
&lt;p&gt;学术期刊的读者其实很有限，能跟科普期刊联动算是一个扩大影响力的手段。不过高昂的费用可能让这个趋势变成了出版业新的捞钱手段，最后其实是各国纳税人买单。在我看来，现代研究人员应该掌握一定的科学传播技能，自己要能清楚讲述自己的研究内容与结论。至于是否走付费开放获取期刊，其实并不重要，你可以把论文投稿时同步放到预印本服务器上，这样就一定程度保证了公开也降低了成本。我比较反感的是动不动就摆出居高临下姿态说别人解读外行但又不给理由的做法，所谓反驳，要么逻辑上要么事实上得有东西列出来，单纯表态只会促进盲从。&lt;/p&gt;
&lt;p&gt;科学研究经费取之于民则势必要把不涉密结果公布，但是否要接受大出版集团的高价服务，相信研究人员自己会用脚投票。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>看门人分子</title>
      <link>https://yufree.cn/cn/2021/06/17/gatekeeper/</link>
      <pubDate>Thu, 17 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/06/17/gatekeeper/</guid>
      <description>&lt;p&gt;今年ACS春季会议我做了一个口头报告，提出了“看门人分子”的概念。这大概是我又双叒叕挖坑的一个开端，现在预印本已经放到&lt;a href=&#34;https://chemrxiv.org/engage/chemrxiv/article-details/60c9e3b13fc2cb674c000d4e&#34;&gt;网上&lt;/a&gt;了，这里做下解释。&lt;/p&gt;
&lt;p&gt;这里我关注的科学问题来自于污染物暴露研究，如果一个人暴露给一种污染物，那么就存在导致某种健康状态的可能。在暴露组学研究中，污染物暴露通常作为某种疾病的预测变量，也就是有下面的关系：&lt;/p&gt;
&lt;p&gt;$$健康 = f(污染物，协变量)$$&lt;/p&gt;
&lt;p&gt;然而在代谢组学中，我们会认为健康状态是由代谢物水平变化直接导致的，也就是下面的关系：&lt;/p&gt;
&lt;p&gt;$$健康 = g(代谢物)$$&lt;/p&gt;
&lt;p&gt;这里没有放协变量是因为很多协变量在分子水平上本就可以被某些代谢物来指示，例如性激素水平大概就能指示性别，此时你把性别放到模型里会造成共线性，降低模型稳健度。&lt;/p&gt;
&lt;p&gt;观察这两个等式我们会发现，如果代谢物本身可以体现健康状况，那么污染物也就有可能是通过影响代谢物来影响健康状态。注意，此处代谢物是可以被替换为其他来自人体样本的分子信息的，例如蛋白质、组蛋白、基因甲基化水平等。但本质上是一个环境信息传递到分子生物学信息再传递到健康效应的信息流。考虑上遗传作用也就是：&lt;/p&gt;
&lt;p&gt;$$环境暴露/遗传 \rightarrow 内源响应 \rightarrow 健康$$&lt;/p&gt;
&lt;p&gt;此时我们会发现，遗传影响与环境影响其实都会体现在生物样本的分子信息里，当这三部分都能被观察到时，我们应该可以从分子水平解释环境或遗传对健康影响的机理。遗传那部分不是我关注的，后面只讨论环境影响，这里放上遗传是为了让这个模型逻辑上通顺些，实际不同健康状态的主导影响也是不一样的。&lt;/p&gt;
&lt;p&gt;环境流行病学会关注那些受环境影响更大的疾病，但描述暴露与疾病关系却通常是毒理学家在做，这里经常出现毒理学上证明有影响但流行病学数据看不出来（大多数）或者流行病学看到了影响但毒理学证据不充分（少数）。这里的不一致在我看来主要是因为毒理学所采用的控制实验体系过分简化了环境暴露，很多毒理学上用到的剂量现实生活中很难出现，或者说虽然剂量水平相当，但因为缺乏暴露途径或存在其他拮抗暴露影响的机制。更重要的在于很多时候评价指标如果太过宏观就会不够灵敏，而描述暴露跟健康的数值都可以算相对宏观的指标。&lt;/p&gt;
&lt;p&gt;因此，要搞清楚环境究竟如何影响健康，我们最好是直接测量人群样品的分子水平信息，这就是代谢组学跟蛋白质组学还有表观遗传组学在做的事。但人群样本不可能做到随机化，我们不太容易拿到个体水平的环境信息，例如我可以知道A地当天室外空气细颗粒物浓度，但不太容易拿到某个人当天暴露的细颗粒物浓度，最简单就是如果这个人自己在家做饭，那么他的细颗粒物暴露量是远高于室外浓度的。&lt;/p&gt;
&lt;p&gt;其实，外在暴露的变动范围其实是远大于内源响应的，室外温度可以从零下几十度到四五十度，但人的体温波动不会特别大。从这个角度出发，体内的代谢物分子可以分成两类，一类是对暴露敏感的用来响应与感知外界变化，另一类则是不敏感的用来维持生命系统。可以预想到，人体代谢平衡或者主要代谢通路更多是不敏感的那一类分子在维持，如果暴露真的造成了健康状态改变，那么肯定是先影响敏感分子然后突破敏感分子的信息传播阈值影响到了不太敏感的主代谢通路。那么，这部分敏感的分子就有必要找出来。&lt;/p&gt;
&lt;p&gt;这里我们就会发现一个问题，当进行组学研究时，我们是不预设敏感度的，也就是仪器能测到啥我们就报道啥，但这里就涉及一个统计学多重检验的问题，我们会在完全不敏感的代谢分子上浪费大量的统计功效。毕竟现在错误发现率的控制都是基于检验数的，检验数越多，判断出现差异的要求就越高。例如我去进行污染物A对代谢组影响的研究，结果测到了1000种代谢物，然后要做1000次假设检验才能知道哪种代谢物跟污染物有关，此时就要做错误发现率控制。不过其实从一开始我们就知道不会有太多出现差异的，但这部分知识没法反应到数据分析方法里。&lt;/p&gt;
&lt;p&gt;现在常用的一个做法就是降维或聚类，把趋势类似的代谢物组合为一个新的潜在变量，然后去跟污染物进行相关分析。且不论到头来你怎么再把影响回溯到具体的物质，这个思路并不解决我们收集了一大堆无关信息。我的想法就比较简单直接，在进行污染物与代谢物之间分析之前，先对代谢物内部相关性进行分析。在设定的相关性阈值之下，代谢物会形成代谢网络，绝大多数情况你会看到一个主干网络与零星分布的小代谢网络，这里我们把这类代谢物叫做大陆代谢物，但更多的代谢物是独狼或孤岛，根本无法与其他代谢物产生任何联系。此时，生物信息的流动是构建在代谢网络上的，因此我们只关注大陆代谢物。这是一个基于概率的假设，不可否认会丢掉一些有用信息，但却能显著降低研究难度。&lt;/p&gt;
&lt;p&gt;从我做的案例来看，常规代谢物检测在一个较高相关性阈值下90%以上的代谢物属于孤岛，这样我们通过区分孤岛与大陆就实现了一次基于信息含量的降维。而面对剩下的代谢物，我们会逐一检查其与暴露物的相关性。可以预见，并非所有代谢物都会与暴露物有关系，这样我们就能筛到直接与暴露物打交道的代谢物。因为这些代谢物一方面跟污染物有联系，另一方面又跟其他代谢物有联系，那么很有可能污染物的信息流的接受者就是他们。换句话说，这些代谢物是污染物影响代谢网络的最前线，所以我给他们起名为看门人（gatekeeper）分子。下面是一个简单的看门人分子示意图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yufree/presentation/gh-pages/figure/gkc.png&#34; alt=&#34;gatekeeper&#34;&gt;&lt;/p&gt;
&lt;p&gt;理论上会有两种看门人分子，一种是直接横在暴露物与代谢网络之间的，另一种则是互相为看门人分子。但不论哪一种，看门人分子都应该属于对暴露物比较敏感的，而且在真实数据中，我发现看门人分子可以响应不止一种暴露物。这个发现就说明代谢物层面有可能存在一个相对通用的看门人机制，其实本来环境毒理学就有外源代谢通路的说法，但如果能从小分子层面描述可能更有利于阐明影响机制。&lt;/p&gt;
&lt;p&gt;不过看门人分子只处理了环境暴露跟代谢物的关系，我们最开始的那个问题，也就是影响健康的机制还没有讨论，只是把讨论范围缩小到了具体的代谢物上。在我做的案例中，环境暴露无法直接发现跟健康的关系，但当我用这些暴露物的看门人分子来研究与健康的关系时，可以直接观察到看门人分子与健康状态的关系。也就是说，看门人分子要比直接用环境暴露研究健康影响更灵敏。这倒不难理解，毕竟环境影响的测量不确定性本来也比代谢物测量不确定性要高。&lt;/p&gt;
&lt;p&gt;其实看门人分子这个概念的本质还是基于网络分析的，基因组里比较流行的WGCNA这个包的核心也是发现网络结构后对每个独立网络结构做svd分解，然后取第一个主成分来代表网络进行下一步分析。不过，看门人模型从一开始就是直接针对具体的代谢物来建模的，通过筛选网络结构来找出有实际意义的代谢物，形成假设方便后续检验。也就是有下面的关系：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/yufree/yufree.cn/master/static/images/EMDG.png&#34; alt=&#34;EMDG&#34;&gt;&lt;/p&gt;
&lt;p&gt;这个分析方法的重点就在于我把代谢组限定到了看门人分子这个子集，这些代谢物可能更适合进行环境影响相关的疾病研究（起码初步的结果是这样）。同时，看门人分子不仅仅可以是小分子代谢物，还可以是蛋白质或其他生命大分子。这样看门人分子实际就成为了可以把各种组学连在一起的概念，而且这部分分子要比其他分子对环境因素更敏感，更可能是健康防护的第一条防线。&lt;/p&gt;
&lt;p&gt;关于这个概念我已经做过四次报告了。从反馈上看，做生物信息的把这个方法看成了利用信息量降维的手段；做统计的第一反应是这玩意怎么看着像因果分析；做生命科学的认为这个概念比花里胡哨的分析方法简单，容易设计实验验证；做流行病的则强调一定要把协变量给考虑进去且考虑其在预防医学上的意义，特别要考虑灵敏度问题；做环境的更关心能不能直接给出一个基于人体代谢物的看门人分子数据库。我之所以费劲写这篇介绍就是因为预印本被很多不同背景的人改的一言难尽，所以干脆拿母语把核心概念重写出来算了。&lt;/p&gt;
&lt;p&gt;从我个人角度跟能力，其他方向我做不了但我乐意与之交流，学科间应该有更多的互动而不是互相睥睨。不过，这个概念倒是有可能跟我之前所说的反应组学进行联动。当前的网络结构是利用相关性来构建的，但基于质量差的反应组也可以用来构建网络，而且解释性可能更好些。其实我并不喜欢炒作概念，主要原因是很多新概念只是构建了学科间的壁垒，但看门人分子这个隐喻却有利于学科间的融合，唯一的问题就是当前研究人员是否乐意打破学科壁垒了。&lt;/p&gt;
&lt;p&gt;ps. 我本来起的名字是守门员（goalkeeper），至于为啥改成看门人，那又是个关于政治正确的故事，不提也罢。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>布罗曼的吐槽</title>
      <link>https://yufree.cn/cn/2021/06/01/karl-broman/</link>
      <pubDate>Tue, 01 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/06/01/karl-broman/</guid>
      <description>&lt;p&gt;最近一口气读完 Karl Broman 对自己大学的&lt;a href=&#34;https://kbroman.org/blog/2021/05/06/wtf-uw-1/&#34;&gt;吐槽&lt;/a&gt;，很多体会感同身受，同时我也发现现在学术界能公开讨论这些问题的人实在太少了，大家都在为自己的前程奔波，这里也顺道聊下我的一些感受。&lt;/p&gt;
&lt;p&gt;最能区别懂科学思维的人跟其他人的特点是什么，想来想去可能就是对真假的看重远高于对错美丑，但这显然不是说的所有科学家群体。科学家是现代职业的一种，作为职业价值判断总是第一位的，不然没饭吃。打个比方，你申请了一笔经费研究污染物A对疾病甲的影响，做了半天发现没影响，你要是打算转行那卷铺盖走人就行了，但科研领域的经费逻辑是成功导致成功，你第一个项目不成功第二个申请就费事了，然后你就会看到很多人穷尽各种统计方法去找一个p小于0.05的结论来结题。要是真有科学思维会马上意识到这样的发现发表就是终点，后面的人会引用但懂行的肯定知道不是什么重要发现。我前段时间搜了下常见污染物的流行病学证据，现在吵翻天的全氟化合物的要么流行病学证据不充分，要么就是有限的动物或细胞毒理学证据，但研究这类物质已经养活了一个行业。行业职业化会导致从业人员价值观指导研究，好比戴着有色眼镜做科研，经常只能报道或者拼凑有影响的结果，这显然不是什么科学思维，但这种思维已经深入人心。&lt;/p&gt;
&lt;p&gt;即使看重价值观，研究人员的最基础要求也是要勇于承认错误与无知而不是想办法转移话题掩饰缺点。想搞清楚这个问题，可以去追溯互联网社区的历史，最早的聊天室是全公开的，一个地级市的网民都在一个大聊天室里扯淡，那时候表情包都是标点符号表示的，大家讨论问题倒也和气。同时代还有论坛，论坛里想多发图片都得打上个“多图杀猫”的预警，毕竟那时候网速才28kb或56kb，但意见不同也就是不看。等宽带开始普及，各种论坛小组贴吧就冒出来了，社交网站游戏层出不穷，开始大家都是看啥都新鲜，很多交流带有明显的线下真人属性。但过了一段时间，有人发现线上交流对方根本就不知道你是谁，所以也就开始放飞自我，爽就完事了。这个时候，论坛开始出现小集团化，一开始可能是水区或八卦版闹着玩的，但后来逐渐就有了价值观加持，如果碰上几次版主辞职还有可能看到一个竞争对手出现，经常被称为隔壁论坛或隔壁小组或隔壁贴吧。要是一个论坛没出现过隔壁的讨论，那么显然做的还不够，此时就会出现一些“圈内正确”的观点。新人来了经常一腔热血发几个贴踩了“圈内正确”关键词就被赶到了隔壁，要么就是饭圈化替那些阴阳怪气的老人四处征伐异己，如果没有敌人就创造一个敌人出来打倒。&lt;/p&gt;
&lt;p&gt;“圈内正确”非常可怕，最可怕在于很多人意识不到自己可能犯错，沉浸在精英感之中。他们在自己的圈子里遵守了一切的入乡随俗，忘记掉过往的所有不愉快经历，然后终于认为自己可以站在无过错的一方发号施令，用上位者姿态点评他们眼中的失败者，希望与之隔离开来。有了你我对错成败之分，就有了高低贵贱的价值判断，然后价值判断反过来指导自己的行为，而且最重要的是他们默认自己的判断一定是对的。很多人即使后来发现自己错了，也绝不会去承认错误，因为犯错误在这种人眼里是失败者才会有的。他们从来计划周全，根本就不会允许自己有机会进入到犯错的场景里，有错都是敌人的错。这是一种强者逻辑，永远是自己伟光正且永远只喜欢伟光正的氛围，这种价值观整体而言还是自洽的，不会出现认知失调。但这种傲慢才是最致命的，如果你觉得不是可以参考下台湾政府现在对疫苗的态度，用草菅人命都算是美化了。&lt;/p&gt;
&lt;p&gt;科研很多小圈子也存在圈内正确的现象。我知道有些课题组决不允许发表质疑自己前期工作的论文，也有些学术界的小圈子通过互相引用推荐审稿人来维护圈子内部的高水平发表记录，还有些搞研究的其实是在搞政治还喜欢投文章前去上个香等，这些严格说都算职业化科研的副作用，但跟科学没多大关系了。坦白说，现代职业科研体系并不需要每一个从业人员都有科学精神，对于一所现代化大学或研究机构，搞钱搞人才搞名声才是硬道理，学术成果是产品，很重要，但科学精神属于负战斗力，经常把一些看起来很成功的项目给搞垮。科研明明是件需要试错的事，却被现代化管理搞成了需要不断成功才能持续下去的励志小故事。我曾遇见过很多喜欢做研究的人，但现在遇到更多的是喜欢成功多过喜欢科研的人，他们越来越像项目经理与老板，产出的是流水作业的废纸，对他们而言科研只是体面工作与薪资的保证，而这也是现代化社会运转的一部分。有意思的是，因为当前推动社会进步的主要是技术组合而非科学，所以其实现代科研在某种程度上是鼓励论文流水作业与强者恒强不容置疑的模式的。&lt;/p&gt;
&lt;p&gt;当然，我这也是吃人饭砸人饭碗。不过我接触过很多痛苦不堪的研究生与研究人员，他们找不到方向，看不到希望，最后一走了之。我自己会不会离开也不好说，但我只要还在这个行业里，就会去记录这些事与想法，因为这是真实的科研生活。科研不是理想化的，充满了各种人性，所有有类似体会的人也不是孤独的，但跟寻找科学问题的答案相比，这都不算事。不过，如果你确实做不下去也没必要死磕，世界很大，总有值得做的事。&lt;/p&gt;
&lt;p&gt;我们所过的每个平凡的日常，也许就是连续发生的奇迹。（出自《日常》）&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>平行世界的统计推断</title>
      <link>https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/</guid>
      <description>


&lt;p&gt;最近重新看了下之前对p值的笔记，突然对零假设充满了陌生感。在p值的语境里，当我们看到数据D在零假设下发生的概率低就会做出数据D不支持零假设的判断，这是一个条件概率等价替换的问题：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$$p(H0|D) = p(D|H0)$$&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个当然是有问题的，我真正关心的是零假设是否成立而不应该是数据出现在零假设下概率。而这在假设检验的设计中转化成了零假设成立下出现观察数据的概率，这里最大的不对劲在于数据D不支持零假设依然无法判断零假设是否成立。对于实验科学，我们能收集数据D，但检验零假设似乎没什么道理，零假设是来自于随机过程，我们真正关心的从来都是产生差异的过程，现在却要用随机过程来检验产生差异与否，总感觉哪里不对。&lt;/p&gt;
&lt;p&gt;不过重读了丁鹏老师的&lt;a href=&#34;https://cosx.org/2019/05/recheck-the-lady-tasting-tea/&#34;&gt;文章&lt;/a&gt;后，我意识到当年Fisher搞出的统计推断的背景的女士品茶实验其实是穷举所有可能，因为品茶结果是离散的，所以穷举空间是有限的，此时发生各种情况的概率是离散的，这也就形成了Fisher精确检验的基础。这里面容易被忽视的点在于品茶实验中品茶顺序与结果是无关的，也就是形成正确答案的顺序与答案无关，也就是说如果数据D是真理，那么随机化过程不影响真理对错。&lt;/p&gt;
&lt;p&gt;那么回到前面的问题，Fisher这个p值设计实际上巧妙的规避了&lt;code&gt;$p(H0|D)$&lt;/code&gt;与&lt;code&gt;$p(D|H0)$&lt;/code&gt;的区别，因为在这个离散概率的语境下，空假设提供的实际是一个虚拟的有限平行宇宙，当某个假设成立时，数据一定会支持假设而不成立时数据在有限平行宇宙里只会以很低的概率出现，&lt;code&gt;$p(H0|D)$&lt;/code&gt;与&lt;code&gt;$p(D|H0)$&lt;/code&gt;的讨论在这里就没意义了，虚拟的有限平行宇宙实际是给出了所有可能性空间。也就是说，产生差异这件事被零假设转化成了虚拟的有限平行宇宙，其中有一个宇宙产生了差异，那么这个宇宙下待检验的假设就可以被认为是证实的。&lt;/p&gt;
&lt;p&gt;换句话说，Fisher的零假设是包含了所有假设在内的假设宇宙，在某些宇宙里出现某些数据是正常且合理的，但这些宇宙相比所有假设宇宙的空间非常小，那么在这些宇宙里数据背后对应的规律应该就是真实的。如果假设宇宙本来就不多（当然这个只会在离散结果的条件下出现），那么事实上就形成了统计功效不足的问题。前面我意识到的不对劲其实是误会，因为我脑子里还放着与零假设对应存在的备择假设这个东西，所以我会纠结是不是检验错了。但事实上，备择假设本就是零假设的一部分，其独特性是通过在可能性空间的低概率来表征的。从这个逻辑上看，Fisher的精确检验并不存在现在普遍使用的零假设备择假设这套体系里的问题，而且只要转化一下，Fisher精确检验一样可以用在更广的领域。&lt;/p&gt;
&lt;p&gt;这里最大的问题在于可能性空间的低概率跟数据存在规律性需要是一个东西，这也是Fisher精确检验的核心。现在很多对p值的质疑可能来自于对可能性空间认识的偏误，对于很多人而言，可能性空间是数学意义上的无限空间，但对实验结果而言，在一定观测精度下可能性空间其实是有限的而观测的数据又是一定存在于这个空间之内的，这就导致概率低下进而我们会认为规律存在。举个例子，如果观察我开门这个动作100次，那么我每次都用右手这个事件对比&lt;code&gt;$2^{100}$&lt;/code&gt;这个可能性空间而言概率很低但存在，这件事可能让观察者得出我是右利手的规律性结论。这里统计推断只负责告诉你概率，怎么解释是观察者自己决定的事，p值0.05就是个方便决策的阈值但统计学更关心概率怎么计算。&lt;/p&gt;
&lt;p&gt;也就是说现在对p值的质疑是集中在后面决策步骤上的，但这个决策标准其实本来应该各个学科根据自己的学科规律可能性空间来制定，不能简单把锅甩给统计学家，毕竟他们对不同学科规律可能性空间其实并不了解。很多时候重复性不好的本质是所谓规律性在可能性空间里并不稀有，随机过程就会发生，这个时候应该做的是对规律性给出更严格的定性定量要求与描述，还有种可能就是本来就是伪规律，是噪音被当成了规律，天知道科研人员为了混饭吃会不会把其实不稀有的偶发事件当成规律来报道，这时候应该被质疑的其实应该是实验者而不是统计学决策工具。&lt;/p&gt;
&lt;p&gt;我不太清楚后面是怎么把p值从离散分布推广到0到1之间的连续均匀分布的，但现在我倒是有兴趣看下p值本身在平行宇宙里的分布了。如果有规律的事实在实验限定的空间里发生，其p值的分布应该会与随机过程产生的p值不一样。这里我不打算采用多次随机抽样，因为此时分布事实上是已知的，此时进行随机实验其实是在假设分布存在且成立的条件下判断事实。相反，我会随机生成一组数据但保留这一组数据当成既成事实，但随机化分组过程来检验p值的分布，此时应该更符合事实存在后对假设的判断这个思路，这个应该更贴近Fisher精确检验的思想。这里我们考虑三种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;真实差异固定&lt;/li&gt;
&lt;li&gt;完全是随机数&lt;/li&gt;
&lt;li&gt;固定的真实差异加上随机数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第一种情况是规律完全成立；第二种是完全无规律；第三种是可观察或可测量的数据。生成三组数据后我们对其分组（简单二分）进行10000次随机化操作，然后进行t检验，记录并观察p值。&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
# 真实差异
x &amp;lt;- c(rep(100,260),rep(200,260))
# 随机差异
xr &amp;lt;- rnorm(520)
# 考虑误差的真实差异
xm &amp;lt;- c(rep(100,260),rep(200,260))+rnorm(520)
p &amp;lt;- pr &amp;lt;- pm &amp;lt;- c()
for(i in 1:10000){
        # 随机化分组
        g &amp;lt;- factor(sample(c(1,2),520,replace = T))
        p[i] &amp;lt;- t.test(x~g)$p.value
        pr[i] &amp;lt;- t.test(xr~g)$p.value
        pm[i] &amp;lt;- t.test(xm~g)$p.value
}
# 探索p值分布
sum(p&amp;lt;0.05)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0481&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p&amp;lt;0.5)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5084&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p&amp;lt;0.9)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8978&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pr&amp;lt;0.05)/length(pr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0514&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pr&amp;lt;0.5)/length(pr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4994&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pr&amp;lt;0.9)/length(pr)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9014&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pm&amp;lt;0.05)/length(pm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0493&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pm&amp;lt;0.5)/length(pm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5023&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(pm&amp;lt;0.9)/length(pm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.8991&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow=c(3,2))
hist(p,breaks = 20)
hist(p,breaks = 100)
hist(pr,breaks = 20)
hist(pr,breaks = 100)
hist(pm,breaks = 20)
hist(pm,breaks = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这个结果非常有意思，第一个能看到的现象是如果数据本身存在规律性，那么p值的分布是一个离散分布。这个分布介于0到1之间，越接近0的部分越密集，越接近1的的部分越稀疏，但是如果计算小于0.05，0.5，0.9的比例情况，会发现这种稀疏分布依旧符合均匀分布的概率分布特征。如果数据不存在规律性，那么p值的分布就是很均匀的。如果数据混合了规律性与噪音，依然会显示出这种离散分布特征。下面我用qq图来观察下这个分布跟均匀分布的区别：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(42)
ref &amp;lt;- runif(10000)
par(mfrow=c(1,1))
qqplot(ref,p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqplot(ref,pr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-2-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqplot(ref,pm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-2-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;可以看到，如果数据本身存在规律性，其随机化分组后的p值虽然跟均匀分布很接近，但qq图上确实会表现出前密后舒的螺旋延伸状态。&lt;/p&gt;
&lt;p&gt;我虽然不清楚统计学上有没有对这个p值分布的研究，如果没有我先管它叫 MY Distribution ，谁让我名字缩写就是MY，这个“我的分布”可能对实验学科非常有意义。&lt;/p&gt;
&lt;p&gt;这里为了区别我再做一个仿真，这次我不是对分组随机而是对采样随机：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
# 固定分组
g &amp;lt;- factor(c(rep(1,260),rep(2,260)))
p &amp;lt;- c()
for(i in 1:10000){
        # 随机化采样
        x &amp;lt;-  sample(c(rep(100,260),rep(200,260))+rnorm(520),520)
        p[i] &amp;lt;- t.test(x~g)$p.value
}
# 探索p值分布
sum(p&amp;lt;0.05)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0406&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p&amp;lt;0.5)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5344&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(p&amp;lt;0.9)/length(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9356&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(p,breaks = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(p,breaks = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qqplot(ref,p)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-3-3.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;这里我们同样能看到这种蛇形走位，而且似乎随机化样品看到的趋势更明显。但同样的，这里我的模拟逻辑还是保持数据不变，只是随机化过程。&lt;/p&gt;
&lt;p&gt;实验学科已经被多重检验问题困扰了很久了，通常演示p值分布很多人是喜欢从一个已知分布里反复抽样形成差异，此时的p值分布是有偏的：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)
pvalue &amp;lt;- NULL
for (i in 1:10000){
  a &amp;lt;- rnorm(10,1)
  b &amp;lt;- a+1
  c &amp;lt;- t.test(a,b)
  pvalue[i] &amp;lt;- c$p.value
}
# 探索p值分布
hist(pvalue,breaks = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hist(pvalue,breaks = 100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/cn/2021/05/21/statistical-inference-in-parallel-world/index_files/figure-html/unnamed-chunk-4-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;然后因为随机抽样得到的是p值均匀分布，所以很多错误发现率的控制算法都是在想办法区分这两种分布。现在常用的BH矫正、Q值法或者Bonferroni法都依赖检验数量与前面说的分布差异来决定判断标准或者控制整体错误率。这个看上去很合理，因为你检验多了出现随机相关的可能性就是高了。然而这个过程又很不合理，因为我们测量时有时候并不知道测量的维度是不是跟分组有关系，只是顺手测了，这类测量浪费了大量的统计功效。这也是传统实验学科跟组学实验学科经常扯皮的地方，传统做一对一的控制实验，如果测到了一个有意义的信号就可以发表，但技术进步后，因为我同时测了其他其实无意义的信号，那些有意义的信号被掩盖在随机相关里了。前面所说的多重检验问题的处理思想通常是保留强信号，这样本身有规律的弱信号就被自动忽略了。也许我们可以认为效应比较弱的信号不如效应比较强的信号，但只要存在规律性，作为研究人员就一定要去搞清楚是咋回事而不是用统计学工具给自己做挡箭牌。&lt;/p&gt;
&lt;p&gt;这样，前面那个p值分布的意义就很明确了：如果规律会造成数据异质性而我们的分组过程就是试图发现这种规律性，那么不可避免的会在p值分布上造成离散分布的状态。相反，随机相关则不会呈现出这种p值的离散分布而是均匀分布。这个均匀与离散分布的差异如果能用一个统计量来描述，那么我们事实上就能根据这个统计量（暂且命名为统计量MY）区别出真实规律与随机相关。我现在能想到的构建方法非常原始，就是对直方图概率密度曲线的0.9到1这一段找最大值与最小值，如果比值超过一个阈值就认为有规律性，否则就认为是随机数据。但应该有更数学化的构建方法。&lt;/p&gt;
&lt;p&gt;在这个语境下，我们就不用搞这些p值的阈值矫正了，直接对每一次假设检验进行分组随机化模拟过程，然后生成p值分布。如果其MY值表示为离散均匀分布，那么这一组假设检验的规律性就是有保证的，如果指示为均匀分布，那么这组数据本身就可以判定为无法检测规律而排除。这样我们可以对数据在进行统计推断前做一个规律性测试，只有通过了规律性测试的数据才值得进行统计推断。而且，只要单次统计推断给出小于0.05的p值，我们就可以直接相信，因为那些可能出现随机相关的数据已经被我们排除掉了。&lt;/p&gt;
&lt;p&gt;不过，到这里我的知识水平已经到头了，因为这个MY值如何构建我是不知道的，现阶段我能想到的解决方案一个是直接用眼看，一个是动用图像识别的机器学习算法识别这类图像，也就是让机器看。不过这个思路应该问题不大，说白了就是利用模拟探索产生真实数据的可能性空间或平行宇宙而不是利用分布产生仿真数据，后者其实是先定在了某一种宇宙之中，这里基本延续了Fisher精确检验的思路，计算上也是可行的。&lt;/p&gt;
&lt;p&gt;其实我也不是凭空想思考这个问题，前两天中午有个报告里演讲者提到了Fisher精确检验跟因果分析的关心，我当时忙活着做午饭没听明白她到底讲了啥，但Fisher精确检验的思想确实听明白了。然后吃着午饭就想到了这个随机化分组是不是影响p值的问题，一开始我用的是直方图的默认输出，结果发现p值总是均匀分布感到很丧气，但因为在模拟中本来是1000次多输了一个0就打算看看更精细的直方图，这才看到了这个被掩盖的p值离散分布。我应该不是第一个看到这个分布的，但将其用到替换多重检验的错误率控制上应该是个比较有前景的应用，欢迎读者来给我拍砖，要是没人写过论文（不大可能）也可以拿去写论文，我知道的已经都写出来了，欢迎引用或合作。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>暴露组学中的数据挑战</title>
      <link>https://yufree.cn/cn/2021/03/27/exposome-challenge/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2021/03/27/exposome-challenge/</guid>
      <description>&lt;p&gt;最近做了次闭门分享，是关于暴露组学中存在的数据挑战，也借机整理了下暴露组学的资料，这里也留个底。&lt;/p&gt;
&lt;p&gt;暴露组学认为生物表型或疾病是环境与基因在时间尺度上交互作用的结果，也就是：&lt;/p&gt;
&lt;p&gt;$$P(t) = G(t) * E(t)$$&lt;/p&gt;
&lt;p&gt;而暴露组学更多关注环境影响及其与基因的交互作用，毕竟单纯的基因影响已经被基因组那边搞得差不多了。&lt;/p&gt;
&lt;p&gt;暴露组学(exposome)最早是2005年C. P. Wild 在期刊 Cancer Epidemiol Biomarkers Prev 的&lt;a href=&#34;(https://cebp.aacrjournals.org/content/14/8/1847.short)&#34;&gt;社论&lt;/a&gt;上提出的。2010年，Rappaport 与 Smith 在 Science 上发表了题为 Environment and Disease Risks 的展望&lt;a href=&#34;https://science.sciencemag.org/content/330/6003/460&#34;&gt;文章&lt;/a&gt;，认为暴露不应限制在直接接触到的化学物质，也要考虑更广义的暴露，例如微生物暴露与生活压力等。&lt;/p&gt;
&lt;p&gt;2015年，美国环保署举办了 &lt;a href=&#34;https://sites.google.com/site/nontargetedanalysisworkshop/&#34;&gt;Non-Targeted Analysis Workshop&lt;/a&gt; 来讨论环境与生物介质中外源化合物的标准筛选方法、标准品制备与谱数据库的开发，后来演变成了涉及来自学术界、政府、公司近30家实验室的 ENTACT(EPA&amp;rsquo;s non-targeted analysis collaborative trial) 项目。ENTACT 项目的参与单位包括八家政府机构 (California Dept. of Public Health, California Dept. of Toxic Substances Control, Eawag, EPA, NIST, Pacific Northwest National Laboratory, Research Centre for Toxic Compounds in the Environment, US Geological Survey)，五家公司（AB Sciex, Agilent, Leco, Thermo, Waters）与十五家学术机构（Colorado School of Mines, Cornell Univ., Duke Univ., Emory Univ., Florida International Univ., Icahn School of Medicine at Mt. Sinai, North Carolina State Univ., San Diego State Univ., Scripps Research Institute, Univ. of Alberta, Univ. of Birmingham, Univ. of California at Davis, Univ. of Florida, Univ. of Washington, WI State Laboratory of Hygiene）。在环境领域要想做 NTA 最好去这些地方，因为参与 ENTACT 项目的机构定期会测盲样进行方法比对，基本可以接触到 NTA 最顶尖的技术，相信以后相关环境标准也会脱胎于这个项目。欧洲也有个类似的项目叫做 &lt;a href=&#34;https://ec.europa.eu/programmes/horizon2020/en&#34;&gt;Horizon 2020&lt;/a&gt;，国内目前还是野生游击队状态，不论学术界还是业界大都在炒概念，落地案例有限。&lt;/p&gt;
&lt;p&gt;除了化学污染物，暴露组学也会涉及到社会科学的研究方法。2016年，Global Burden of Disease (GBD) 项目估计全球59.9%的死亡来自各类外部风险，16%的&lt;a href=&#34;https://pubmed.ncbi.nlm.nih.gov/29056410/&#34;&gt;全球死亡&lt;/a&gt;来自于水、大气、土壤污染，其造成的健康相关开支每年约4.6万亿美金（16%的全球经济产出）。基于双胞胎的&lt;a href=&#34;https://www.nature.com/articles/s41588-018-0313-7&#34;&gt;研&lt;/a&gt;&lt;a href=&#34;https://www.nature.com/articles/ng.3285&#34;&gt;究&lt;/a&gt;也发现遗传因素大概能解释49%的人类特质，剩下的部分就可能来自各类广义上的暴露。&lt;/p&gt;
&lt;p&gt;基于化学污染物的暴露组学在方法学方面主要借鉴全基因组关联分析研究（GWAS）发展为&lt;a href=&#34;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0010746&#34;&gt;全暴露组关联分析研究（EWAS）&lt;/a&gt;。但广义的暴露组学涉及的学科非常广，不同学科背景的研究人员可能会使用完全不同的研究思路，整合这些跨学科知识是非常困难的，学科术语墙造成的交流障碍及精细化专业分工导致的研究人员的视野狭隘经常让合作举步维艰。最简单的例子就是当你真的系统性发现某种暴露的意义是远大于另一种暴露时，这对研究重要性比较弱的那部分科研人员的事业发展是毁灭性的，经济或者利益集团在某种程度上已经阻碍了综合性科学问题的探索。&lt;/p&gt;
&lt;p&gt;暴露组学核心科学问题有两个：窗口期与组学。因为健康相关的暴露问题大都是慢性且长期的暴露，需要根据时间尺度变化来推导影响，遗传因素当然也会有时序表达问题但更为保守些，环境因素变化影响可能更大，很多暴露的影响存在窗口期，例如人们孕前或幼儿时期的暴露可能敏感度更高。目前在数据分析方法上，时间序列分析可用来研究被观察者时间尺度上的变化，显著性差异分析可以在实验设计中研究被观察者在单暴露因素下的变化，所谓窗口期，就是找出时间序列分析中被观察者在单暴露因素下的变化时间段。分布滞后模型 Distributed Lag Models (DLM)常被用来讨论时序数据中相关系数与回归因子在时间尺度上的变化。&lt;/p&gt;
&lt;p&gt;而组学涉及更多的是多暴露问题，也就是暴露组学研究并不只关注一种暴露而是系统性关注多种暴露及其相互影响，这点提高了研究的复杂度。现在多暴露数据来源大体可以分为三类：问卷、生物样品及环境样品。问卷数据可以是流行病学调查报告、基于行为的人群画像、基于邮编的社会经济地位或医院的电子病例还有心理学量表；生物样品可以是人的血样、尿样、粪便、头发、牙齿、指甲、汗液等；环境样品则可以是室内灰尘饮用水这类比较个人化的样品分析，也可以是遥感数据、环境监测或被动采样技术下拿到的区域数据流，还可以是更大尺度上的气候变化模型的预测值。这里单人单样本单时间点的暴露组维度可以上万，毕竟就算描述一个小分子，我们能给出的分子描述符也可以成千上万，暴露组涉及成千上万的小分子与各类其他指标，这里降维是必须要做的，不然单是描述暴露组都成问题。不过暴露组并不像遗传信息那样比较稳定，暴露组的动态变化是一定存在的，不同疾病的相关暴露组是不一样的，提高动态数据中信噪比的难度不小。当前的数据分析思路就是通过构建整体影响指标来指代不同污染物的综合加权影响，但又要保证可以回溯出单一污染物的影响。用统计学语言来说就是构建潜在变量，计算不同暴露在该变量上的投影。说到这里可能你会认为不就是因子分析，但我们能拿到的真实数据并不总是连续的，有些还存在严重的缺失问题，对此加权分位数加和回归 Weighted Quantile Sum (WQS) regression 提供了一种思路。&lt;/p&gt;
&lt;p&gt;从数据挑战上看，除了关键的术语壁垒问题，另一个挑战就是高质量的数据采集与管理，这看上去像是技术问题但所有洗过数据的人都知道其中存在多少莫名其妙的问题，这里行业内一定要同一标准，否则大量资源会被浪费在高噪音数据中。高维数据处理其实可以借鉴机器学习的一些思路与方法，但一定要先理解实际问题，因为现在仪器能采集的信号实在太多，最好的降维就是利用专业知识排除掉噪音。缺失值与宏模型训练也是一个挑战，一个人的暴露组数据几乎一定是不全的，你可能只有A的血样与环境样品而有B的尿样与调查问卷，这里很有可能A跟B的数据都包含了足够预测某种疾病的信息，这里就需要训练一个模型的模型来处理暴露组不全的预测问题。此外，暴露组与基因组给出的结论可能在传统的病理学研究看来是离经叛道甚至不合逻辑的，如何跟传统学科对接也是要处理的问题。当然，前面的讨论还都是建立在有数据的前提之下，暴露组还面临个人隐私泄露相关的医学伦理问题，恐怕只能依赖密码学的发展提供工具。&lt;/p&gt;
&lt;p&gt;在当前的阶段，讨论暴露组学更多还是在厘清科学问题并搭建方法与模型的阶段，虽然研究目标很明确但涉及问题过于复杂。我现在其实在为回国找工作，问了一圈高校的环境学院，能单独配高分辨质谱做相关研究的地方一只手就能数过来，现在已经基本放弃去环境学院打算找医学院或交叉学科研究机构了。不过这个方向我还是很看好的，越是复杂的问题，解决起来才有挑战性，如果以后继续科研这条路，我会设计一个上万人的队列研究，追踪一批人至少十年收集一组可重复进行各类研究的样品与数据，希望能得出些许靠谱点的结论。只希望技术发展再快一点，把追踪的成本降到合理范围，用高质量数据回答科学问题而不是像现在这样天天证（chao）明（zuo）概念。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>中介分析</title>
      <link>https://yufree.cn/cn/2020/12/25/mediation/</link>
      <pubDate>Fri, 25 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/12/25/mediation/</guid>
      <description>&lt;p&gt;最近看到有研究开始把中介分析引入到环境健康分析里来了，考虑到实验学科的数据分析能力长期落后统计分析，我这里也做个中介，把这种方法通过问题导向方式解释下。&lt;/p&gt;
&lt;p&gt;首先说下中介分析的背景，中介分析现在可以划分到因果分析中，但历史比因果分析要长，其解决的基本问题就是回归的解释问题。打个比方，一个人的身高影响因素可能来自于遗传，也可以来自后天营养水平，如果我仅仅研究遗传那部分，那么可以列一个公式：&lt;/p&gt;
&lt;p&gt;$$Y(身高) = X（遗传）+\epsilon$$&lt;/p&gt;
&lt;p&gt;遗传最简单的就是用父母平均身高，这个回归公式可以说是线性回归的起点。然而，父母身高虽然可以作为一个综合指标可以用来做预测，但我们并不知道机理，也就是究竟是什么样的遗传机制决定了身高。今天我们组学技术泛滥，可以在分子水平去定量身高的遗传影响机制，假设我们关注的是基因，也就有了下面这两个公式：&lt;/p&gt;
&lt;p&gt;$$Y(身高) = M_1（基因1）+ M_2(基因2)+&amp;hellip;+M_n(基因n)+\epsilon$$&lt;/p&gt;
&lt;p&gt;$$X(遗传) = M_1（基因1）+ M_2(基因2)+&amp;hellip;+M_m(基因m)+\epsilon$$&lt;/p&gt;
&lt;p&gt;这里基因就成了解释遗传影响身高的中介，要知道这个中介身份不是任意找的，是学科知识引导的，你只有认可基因决定遗传这个生物学遗传学的说法，才能构成这个身高-基因-遗传这个中介关系。也正是因为这一步依赖理论逻辑，所以可以纳入因果分析之中考量，用来回答因果机制问题。这里果就是身高，因的笼统指标就是父母身高，机制指标就是各种基因。这个结构范式很容易用到其他领域，用来解释两个综合指标间发生联系的具体机制，例如在暴露组学中，发现某种污染物与某种疾病间的联系是比较容易的，但解释污染物导致疾病的分子机制就需要毒理学研究。但一个很可能出现的情况就是污染物A影响了代谢物甲，代谢物甲会影响疾病1，但我们却不能直接观察到污染物A与疾病1的关系，这里的盲点在于代谢物甲的调节机制可能是非线性的，但如果不发现这个调节机制我们对污染的评价就是不全面的，这里就需要中介分析。&lt;/p&gt;
&lt;p&gt;在中介分析的语境下，我们听到更多的是直接效应与间接效应，此时有可能同时存在X对Y的直接影响与X通过M影响Y的间接效应。当然你也可以理解为X是一个综合因素，我们提出的M只能解释X的一部分，剩下解释不了的都成了X的直接效应。但无论如何，这个中介物一定要是比X解释性更强的因素而不能是更综合的，否则你没法分析机理，打比方身高你可以用牛奶饮用量作为X，用牛奶里某种维生素作为M，但要是你打算解释维生素如何影响身高，就不能把牛奶饮用量当中介物，统计模型上是没问题的，但因果逻辑上属于胡说八道，除非你打算提出一个新理论说维生素通过改变牛奶成分影响身高，不出意外会被审稿人花式玄学调侃。&lt;/p&gt;
&lt;p&gt;那么中介分析怎么做，其实你问题想明白了解决思路也就比较清晰了，首先做直接的回归：&lt;/p&gt;
&lt;p&gt;$$Y = X+\epsilon$$&lt;/p&gt;
&lt;p&gt;然后，用你的M去解释下X：&lt;/p&gt;
&lt;p&gt;$X = M+\epsilon$&lt;/p&gt;
&lt;p&gt;之后，把M跟X结合起来去解释下Y：&lt;/p&gt;
&lt;p&gt;$Y=X+M+\epsilon$&lt;/p&gt;
&lt;p&gt;从第一个公式，你可以知道X是否影响Y；从第二个公式，你可以知道中介M有没有找对；第三个公式，你可以知道控制了M后X是否还有直接影响。这里所谓的是否有影响就是看回归系数是否与0有显著差异。在最后一个回归上，如果加入M后，X没直接影响了，那么这个中介就能完全解释Y了，也就不用考虑X了。然而，如果存在直接影响，那么就可以进一步评价直接与间接影响大小了。这三个回归做完，基本就清楚中介效应是否存在了。当然，这个框架没法处理我前面说的非线性问题或交互作用，不过基本就能厘清传统中介分析怎么做了。你可以得到中介效应（ME）与直接效应（DE），总效应自然就是第一个回归给出的结果，其实也就是前面两个效应的加和。不过真实实验数据，M与X可能同时被其他因素影响，X与Y也可能被其他因素影响，这些因素可能已知，可能未知。数据的收集也很难符合X跟M都随机的要求。&lt;/p&gt;
&lt;p&gt;此时就要引入因果分析了，其实就是对传统模型泛化，把直接效应与间接效应再各分为控制的（controlled）与自然的（natural）来将交互作用纳入到效应考察之中。这里需要额外做四个假设：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对控制效应与自然效应，要保证X与Y之间没有混杂因素，也就是共果&lt;/li&gt;
&lt;li&gt;对控制效应与自然效应，要保证M与Y之间没有混杂因素&lt;/li&gt;
&lt;li&gt;对自然效应，要保证X与M之间没有混杂因素&lt;/li&gt;
&lt;li&gt;对自然效应，要保证M与Y间没有由X引发的混杂因素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个数据要求就比较高了，特别是最后两个，但如果假设没问题，可以用 Pearl’s mediation formulas 去估计总直接效应与纯间接效应或总间接效应与纯直接效应，此时X与M的交互作用会被总效应吸收。不过这些计算交给软件去做就可以了，你只需告诉模型是否要考虑交互作用，或者可以都试试。另外，中介效应需要做敏感性分析，一般用bootstrap来做。&lt;/p&gt;
&lt;p&gt;如果你真打算用中介分析，一定要搞清楚你的模型假设是啥，要对数据结构有充分理解，这也是所有因果分析都需要注意的。对数据假设越多，模型系统偏差可能就越多或越少，不要为了用中介分析去用中介分析，有时候很简单的模型或许粗糙，但结论却更可靠，只要你清楚你在干什么。&lt;/p&gt;
&lt;p&gt;参考资料&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.publichealth.columbia.edu/research/population-health-methods/causal-mediation&#34;&gt;因果中介分析的介绍&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cran.r-project.org/web/packages/mediation/index.html&#34;&gt;R的中介分析包：mediation 包&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/doing-and-reporting-your-first-mediation-analysis-in-r-2fe423b92171&#34;&gt;基于鸢尾花数据做的中介分析案例&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>现代科研指北</title>
      <link>https://yufree.cn/cn/2020/11/21/sciguide/</link>
      <pubDate>Sat, 21 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/11/21/sciguide/</guid>
      <description>&lt;p&gt;《现代科研指北》这本书目前初稿完成，现在把前言放在这里做个导读。这本书可在&lt;a href=&#34;https://bookdown.org/yufree/sciguide/&#34;&gt;bookdown&lt;/a&gt;上在线浏览，也可点击&lt;a href=&#34;https://bookdown.org/yufree/sciguide/sciguide.pdf&#34;&gt;下载&lt;/a&gt;全文PDF文档离线阅读。书里面有些内容在博客发过了，这里算是个总结，各章节相对独立，应该是本不错的厕所读物。目前网上有个半成品版本在流传，但那时候有些坑我后来或者弃了或者填了，还是以这个2.7版为准。下面是前言：&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本书初稿写作于我处于学生与独立科研人员或转行的过渡期，也就是博士后阶段。在这一阶段身处海外的我意识到了现代科研的一些趋势与这个年龄段科研人员的种种迷茫，为了铭记，也为了启迪，我将这一阶段对于现代科研的一些思考整合为一本在线电子书。这本书是开源的，在初稿完成后开放协作，我也鼓励科研人员能记录自己的成长经历，如果实在不知从哪下手，可以参考这本书来整理。是否认可本书观点并不重要，但没有自己的科研思考过程对于科研人员是一种悲哀。&lt;/p&gt;
&lt;p&gt;本书的出发点是 Jeef Leek &lt;a href=&#34;https://leanpub.com/modernscientist&#34;&gt;《How to be a modern scientist》&lt;/a&gt;与 Phillip J. Guo 的&lt;a href=&#34;https://www.goodreads.com/en/book/show/15731248-the-ph-d-grind&#34;&gt;《The Ph.D Grind》&lt;/a&gt; 读后感，前者介绍了当前科研过程中的一些趋势而后者完整给出了个人读博士成长的经历，本书则更像是两者的结合体。由于文化差异与技术进步，当2017年我整理前一本书笔记时发现有些内容已经需要更新了。这样我开始是保留其框架然后填上新的内容，有的内容直接是其他书的笔记，如同忒修斯的船一样，当零件换到一定程度结构也就需要重新调整，调到最后已经看不出跟原书有多大关系了，整体思路收敛到了我的个人经验上，此时就更像是后一本书了。&lt;/p&gt;
&lt;p&gt;没错，这本书的一个重要来源就是我从事科研工作十年的实际感受。我非常重视从源头思考或第一推动原理，希望找到科学问题的最原始的出发点去探索，过程中会对比其他人的思路去验证或优化，这个重复造轮子的过程虽然效率不高，但会保证思路的清晰与独立性，在不断试错中步步为营，扎实推进。与之对比的是简单模仿前人的做法，这样虽然比较快，但一方面会失去探索乐趣，另一方面很难产生新洞见。很多章节我倾向于在给出解决方案前阐述这样做的原因，科研需要黑箱模型，但思路不能单纯照搬别人黑箱。这部分内容在第章现代科研、第四章思维工具第五章实验上有所体现。&lt;/p&gt;
&lt;p&gt;之所以带上“现代”，是因为科研走到今天变化非常快。很多看法现在看或者是刻板印象，或者已被取代，这类关于科研的偏见不仅仅存在于非科研人员，甚至科研人员自己也会把某些“约定俗成”的说法看作科研特性。此外，加上现代就说明我们也面对很多之前科研进程不具备的一些新问题新趋势，这里面最严重的可能要数可重复性危机与开放科学的兴起：如果我们不解决可重复性危机，大量的研究资源会被浪费在无意义的项目上；如果我们不了解开放科学，学术交流的效率就会明显落后于时代。这部分内容在第三章科研现状概览有所体现。&lt;/p&gt;
&lt;p&gt;另一个现代化问题则是技术进步带来的，现代科研使用大量信息技术进步带来的软硬件及标准操作流程，熟悉这些技术与管理理念有利于提高科研效率，这在本书第六章数据处理、第七章文献与第八章学术生活中有所体现。这部分是研究生或初级科研人员最需要知道但教育体系目前没有很好覆盖的知识。基于科研职业化问题，本书最后一章介绍科研外就业问题，为科研人员提供一点出圈的思路。&lt;/p&gt;
&lt;p&gt;本书有三个附录，第一个附录是科研工具软件的选择与推荐，第二个附录是我理想中全栈科学家的一套自测题，第三个则是一些科研俚语，希望读者永远不要忘记幽默。&lt;/p&gt;
&lt;p&gt;本书涉及的主题是我这些年体会到的比较重要的问题，但并不是说别的主题不重要，只是我个人经验覆盖不到。同时，能力有限，即便我所覆盖的部分只是我了解的部分，肯定带有偏见，一定时刻存疑，当你开始思考这些问题就会有收获。&lt;/p&gt;
&lt;p&gt;虽然这本书关注的是科研，但科研不过是生活的一部分，希望读者不要被职业固化生活，去看日出，也去看日落；上得了高山，也下的了盆地；去经历风雨，也能闲观虹霓…充分感受每一过程中的冲突、意外、美丑，科学只是一个视角但人要有更大的视野。&lt;/p&gt;
&lt;p&gt;这本书会通过协作方式不断在线更新，版本号从2.7开始，会以自然底数为模版不断增长，没有尽头。这本书现在初稿完成，完全开放协作，希望协作者不要忘记为现代科研人员服务的初心，我自己也会不定期更新。在此特别感谢谢益辉博士开发的 &lt;a href=&#34;https://bookdown.org/yihui/bookdown/&#34;&gt;bookdown&lt;/a&gt; 包，没有基于 rmarkdown 的完整软件生态，这本书不会落地。&lt;/p&gt;
&lt;p&gt;本书框架如下：&lt;/p&gt;
&lt;p&gt;第一章前言。&lt;/p&gt;
&lt;p&gt;第二章介绍现代科研的知识背景与认识框架。&lt;/p&gt;
&lt;p&gt;第三章介绍当前科研趋势与问题。&lt;/p&gt;
&lt;p&gt;第四章介绍科研思维。&lt;/p&gt;
&lt;p&gt;第五章介绍实验。&lt;/p&gt;
&lt;p&gt;第六章介绍数据分析。&lt;/p&gt;
&lt;p&gt;第七章介绍文献管理。&lt;/p&gt;
&lt;p&gt;第八章介绍学术生活。&lt;/p&gt;
&lt;p&gt;第九章介绍离开学术界的就业途径。&lt;/p&gt;
&lt;p&gt;附录一 现代科研工具包。&lt;/p&gt;
&lt;p&gt;附录二 检验科研思维的试题。&lt;/p&gt;
&lt;p&gt;附录三 研究生与留学生的特殊词典。&lt;/p&gt;
&lt;p&gt;视频版介绍可以在&lt;a href=&#34;https://youtu.be/58ahfqUGwmI&#34;&gt;油管&lt;/a&gt;或&lt;a href=&#34;https://www.bilibili.com/video/BV1Ct4y1e7j1&#34;&gt;B站&lt;/a&gt;找到。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>开放科学实践</title>
      <link>https://yufree.cn/cn/2020/11/14/open-science-practice/</link>
      <pubDate>Sat, 14 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/11/14/open-science-practice/</guid>
      <description>&lt;p&gt;21世纪开始这二十年科研最大的变化就是开放科学的流行，开放科学并不是面向大众的科普，而是面向科学家团体的全流程开放，最大程度保证研究的透明度。之所以会产生开放科学的需求，一方面是因为最近十年可重复性危机的蔓延让科研经费的提供方与公众越来越担心科研资助的质量，科学家自身会有自证清白的制度设计需求；另一方面则要归功于技术进步或出版方商业模式转换使得全流程透明可以落地，也就是经济技术环境允许。&lt;/p&gt;
&lt;p&gt;其实科学家一直就是一个带有乌托邦色彩的全球化大社团，为了让学术资源更好共享，科学家会从政府、私人基金或企业那边募（hu）资（you），然后培养年轻科学家或同同行合作来产生新知识并通过学术出版公之于众。这个团体内部其实非常开放，例如很多大科学装置是开放给所有人申请使用的，并不限制国籍，只是会事先审核申请人资质且自理食宿，收费很多时候相比成本只能说象征性的。同时大量的培养资金或研究经费也是开放给所有人来申请的，当然潜在的门槛是知识水平或认证过的学位，否则必然民科泛滥。不论哪个国家或地区，科研系统的交流术语都相对通用。你写个H2O，就算母语完全不同但也知道这是水，科学家从很早就致力于构建通用科研交流标准与语言来降低交流障碍，目前来说英语是主要载体。现在很多交流方式例如电子邮件传入国内就是中科院高能所为了研究拉的线，跨国研究科学问题在很多学科例如高能物理、气候变化、生物信息里是不言而喻的很正常的事，反倒是政治经常阻碍科研交流。&lt;/p&gt;
&lt;p&gt;现在一个典型的开放科学项目的资助来源可能很复杂，但成果的展示基本要求去商业化与透明化，例如尽量使用开源软件而非商业软件，成果中后来人可以用到的例如病毒序列这种要按照标准格式提交到学科内常见的数据库里，论文要求可以开放获取或锁定一段时间后可开放获取，论文中图表要使用cc授权方式且生成图表的过程要具备可重现性，论文初稿要在预印本服务器上发布且接受开放审稿，而论文发表过程中也要接受审稿信息的公开，方便读者回溯流程，论文发表后相关文件、数据、处理脚本要打包上传到公开数据库里方便查阅……&lt;/p&gt;
&lt;p&gt;总之，现阶段要想完全符合这个标准还是很有难度的，最难的莫过于开放审稿与提供图表再现细节。开放审稿的难度在于很多审稿人质疑的问题可能没有完全解决，公开后被二次质疑概率高。而提供图表再现细节的难度则是技术性的，很多科研作图软件是图形界面点点点的，连图片生成人都不一定记得住自己做了哪些操作，可重复性高的命令行式脚本对于非统计或计算机相关专业的研究人员而言门槛过高，且公开原始数据对于很多课题组而言是非常谨慎的，他们会在论文里写如有需要可以联系通讯作者拿数据的话。&lt;/p&gt;
&lt;p&gt;就我个人而言，这种程度的公开是完全没问题的，从博士阶段开始我就想做出一个完全符合开放科学标准的案例或实践。但那个时候要么是有些图的代码生成我实现不了（因为是跟仪器绑定的），要么是论文的合作者处于各种原因否定了数据公开仅接受邮件索要，要么则是太过超前的概念期刊不接受，例如开放审稿与预印本。但到了神奇的2020年，我想方设法完成了一个案例。&lt;/p&gt;
&lt;p&gt;为了把案例做到典型化并督促我自己，我采用了先吹牛后补票的方式，从2019年我就利用开会到处宣传我要做基于质谱的“reactomics”，甚至这个词都是开会为了凑摘要现编出来的。不过我也承认确实在我之前这个词有人用了，但没用到质谱上。这样其实19年很多人就知道我要做一个新东西，原理也都公开了，这样其实就是拼写文章快慢了。而那个时候，我对文章咋写一点概念都没有，原因很简单，传统论文的套路我是很熟的，但介绍概念的论文我确实读的不多，所有概念都是教科书里学的而教科书显然不会写成论文的格式。19年回国休假结束后，我就一直在想怎么写，这样在19年底我才好不容易完成了初稿。但我的老板也没见过这种没有实验数据的数据挖掘向文章，一直说这就不是论文，需要拆分重写成传统格式。但我比较清楚的是如果用传统格式，那么根本不会产生影响力，所以就硬顶着不改，还软磨硬泡获得同意后送到了预印本服务器上。然后就写了篇博客，用中文说了一遍。这篇文章在预印本服务器biorxiv上的前三个月一直是生物信息学这个分类浏览量前十的文章，但其实这是一篇属于分析化学的文章。&lt;/p&gt;
&lt;p&gt;较高的浏览量给了我一些信心，但投稿就头疼了，因为这次我怎么说都不让尝试顶级期刊，说是浪费时间。最后折腾到了PNAS，那边换了两个编辑后给了个评论，想法很好但文章技术性太强，受众太窄，建议投化学类期刊。最先尝试肯定是JACS，结果那边又说了同样的话，建议转AC，真转到AC上后来了个啥都不懂的审稿人，说没实验没意义。当时我已经气的够呛了，就推说要转格式把稿件扔到一边了。但此时biorxiv上却来了开放审稿意见了，芝加哥那边有个课题组组会上讲了我这篇文章，他们老板把意见汇总了下发了过来，大意是评都评了，你看着改吧。这份审稿意见是我收到的第一份有实质内容的意见，之前的意见都没给出问题在哪，这对我而言就是浪费时间。&lt;/p&gt;
&lt;p&gt;其实我自己给别人审稿，定位从来都是帮着那边完善内容，因为所有投出来的稿子最后都会发表，审稿人的角色是帮助提升文章的而不是发表个人观点的，哪怕拒稿我也会给出修改方向。但我自己的稿子经常遭遇极端化审稿，要么完全提不出问题，要么就是找茬，我之前有篇稿子改了五六轮换了十几个审稿人，但每次都有个审稿人来找茬，没有具体问题就说不行，最后还是拒了，后来我才知道这里面有些个人恩怨（不是关于我的）。不过但凡吃这碗饭，就少不了这种事。&lt;/p&gt;
&lt;p&gt;在公开回复了开放审稿意见后，我再一次打算投稿，这次想投的期刊在我投的前一天爆出了歧视中国人的新闻。然后我就连夜又把格式改了投《自然·通讯》，然后那边过了半个多月回来说想法很好，但太技术，让我转到他们一个新期刊里（其实比我更技术的文章他们也发，但对于从未发表过且没有大牛背书的人而言，初次审核都格外严格）。另外，我当时如果不转，这边老板一定让我重写成传统格式，所以就转了过去。不过这次一周就给意见了，当时我觉得完蛋了，又是拒稿，结果却是返修的审稿意见。提的问题并不难，不过当时我在同时处理好几篇稿件，在我这里耽误了几天，修回去就接收了，审稿返修一共用了一个月时间。当然在期刊那边改格式做技术审查耽误了很久，然后10月2号接收拖了一个多月后才上线，不过这时我注意到了他们可以公开审稿信息的选项，所以顺道就把审稿信息也都公开了。&lt;/p&gt;
&lt;p&gt;其实开放审稿在开源软件开发是更是家常便饭，这里顺带说下统计之都也是开放审稿的，虽然还不是学术期刊，但这种低成本运营的方式应该更符合科研乌托邦式的要求。如果我们能直接在互联网上利用GitHub或Gitee这类平台打造低成本开放获取开放审稿的期刊，那么科研交流会更透明，也更回归科学讨论，现在开放获取已经被很多掠夺性期刊与高收费搞臭了。不过据我了解很多依赖协会建立的期刊其实自己运营都不太好，最后或者被出版集团收购，或者月刊改季刊，季刊改半年刊这样消亡。我想统计之都目前也算是一种尝试，如果能走通且推广，那么应该可以让现有出版方式接纳开放审稿与发表后审稿的模式，毕竟发表只是一个起点，科研进展都是在已有工作上做的改进，如果能公开追踪并更新版本，要比每个人各写各的重新造轮子要好很多。这样可以把科学问题当软件，科研人员把相关研究都更新到一个主题下面，有人跟进就不断更新版本号，没人跟进就停滞自生自灭，这样期刊只要定好主题大家就像是协作维基百科一样去发展就可以了。当然制度设计要有激励与惩罚，这点可以交给所有参与者自行评判，问答网站上有很多可以借鉴的经验来让审稿者作者都得到恰当的透明的可追溯的认可。不过，去商业化运行的后果就是低效，但老实说如果把灌水文章去除，绝大多数期刊的学术交流效率也不高，反倒是养活了出版行业。&lt;/p&gt;
&lt;p&gt;这次为了做这样一个案例，我把代码与数据也都公开了，里面甚至包括了实时从kegg抓数据洗数据的方法。论文中出现过所有的图与表都有重现的代码，为此我把随机数的seeds都写死了。做完这些后出版方那边又发过来一个邀请写篇博客介绍下，当然可以了，毕竟我提前一年就写了中文博客了。这样这个开放科学的案例就比较完美了……才怪。&lt;/p&gt;
&lt;p&gt;我其实更近了一步，这个反应组学的概念从头到尾都是我造出来的，所以我又做了一个大胆尝试，那就是把日常科研进展更新到在线幻灯片里，这个幻灯片我可以反复用且经常更新。这一步是很危险的，因为我只敢把反应组学这个项目的进展幻灯片完全公开，这个项目没有用到任何我现在实验室的数据，全都是展示的开放数据的证据。这恰是我觉得最难的地方，因为我提出的概念自己验证经常是可以通过控制实验很好完成的，但要是用别人的数据验证，那就必须保证概念的通用性或鲁棒性非常强，可以在不是为自己设计的实验里依然被验证，这次我是用一组肺癌患者的尿样来验证的。其实这也是我自信的地方，因为如果一组概念或想法真的经得起检验，那么其预测性就必须足够强大。&lt;/p&gt;
&lt;p&gt;我把项目进展完全实时公开这个做法（现在里面也有不少没发表的内容），就像是写了一本本格推理小说，挑战读者能不能跟我一起找出答案，这种本格科研形式应该是开放科学里最激进的玩法。同时解谜的科研过程非常刺激，我其实知道很多课题组在用我做的东西，有些跟我打招呼，有些是不打招呼的，不过我即不防君子也不防小人，你要看就给你看，咱们打明牌，反正我不缺想法，就怕好的想法没有人去跟进。同时，我在会议上做的报告录像也是公开的，我并不担心有人跳出来说你错了，因为错误使我进步，更好利用技术手段把成果传播出去才是我的目的。这次我动用了公众号跟知乎专栏，加上在出版方那边的英文博客，就是为了证明开放科学这条路我是能走通的。当然如果你仔细看会发现这篇文章只有两个作者，因为人多了估计是无法接受如此激进的投稿策略的，且确实也就我跟老板在沟通这篇文章，且老板更多时候是劝我放弃的那一个，两人合作都有一个负战斗力，人多了协调起来跟灾难差不多，不过也可能是我水平不到家。&lt;/p&gt;
&lt;p&gt;当然了，这篇文章也确实没有发在特别值得说的期刊上，但对我而言更多是一次完整开放科学的体验，以后讨论开放科学也不至于纸上谈兵了。但预印本上700多全文阅读与论文发表一周后近500的阅读量我还是满意的，毕竟我大部分其他论文下载量连这篇的零头都不到，就让子弹飞吧。显然，我会在以后的研究中更多使用这种开放科学的思路，做研究就不应该怕被检验。特别我属于做基础研究的，做出的东西距离应用与盈利是有距离的，这时候要不能把成果很好传播出去，守着自己一亩三分地也没意思。&lt;/p&gt;
&lt;p&gt;下面是相关资料：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://yufree.cn/cn/2019/11/26/reactomics/&#34;&gt;2019年博客&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.biorxiv.org/content/10.1101/855148v1&#34;&gt;预印本，可以查到开放审稿信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=-mT3HcVygHE&amp;amp;feature=youtu.be&#34;&gt;会议报告视频&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://yufree.github.io/presentation/reactomics/pres#1&#34;&gt;进展幻灯片&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nature.com/articles/s42004-020-00403-z&#34;&gt;正式发表论文，附带了所有数据、脚本及审稿信息&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yufree.github.io/pmd/&#34;&gt;对应R包及教程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/280618267&#34;&gt;知乎专栏&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI2MTkxMzcyNQ==&amp;amp;mid=2247486517&amp;amp;idx=1&amp;amp;sn=959a14eeff9266d9adbc6fb2ab16f61f&amp;amp;chksm=ea526127dd25e8311b2a252f4d0b03007e88887888dc0a7d11d69fad4d958d600ab92e5d27bd&amp;amp;scene=178&amp;amp;cur_album_id=1441268261571756034#rd&#34;&gt;公众号&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://chemistrycommunity.nature.com/posts/measurement-of-chemical-relationship-by-pmd-based-reactomics-4706ed0e-31aa-483a-92d2-c87a55327574&#34;&gt;nature 英文博客&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cosx.org/contribute/&#34;&gt;统计之都投稿指南&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后，欢迎大家踊跃投稿统计之都！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>线性模型</title>
      <link>https://yufree.cn/cn/2020/10/12/linear-model/</link>
      <pubDate>Mon, 12 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/10/12/linear-model/</guid>
      <description>&lt;p&gt;线性模型的基本形式就是因变量是由自变量作用加和而成，在这个语境下，其实把自变量改为变量，放宽独立性限制，也能将一些非线性部分，例如高幂次的自变量及变量间的乘积或交互作用考虑进去，这样，线性模型几乎可以覆盖绝大多数科研中常用的假设检验与模型。在实际问题的抽象上，只要可以把目标数值的变动用其他数值的拆解或组合表示出来，那么可以粗略认为标准化后其他数值的回归系数可用来比较不同数值间的贡献，而对于该系数的显著性检验则可以说明该系数的影响是否显著。&lt;/p&gt;
&lt;p&gt;打个比方，流行病学里常说的某种疾病发病率或风险比在考虑了人群性别、年龄、BMI、吸烟史等的影响后发现某污染物起了显著影响，这就是说在一个目标变量为病发病率或风险比的线性模型中，性别、年龄、BMI、吸烟史作为协变量而污染物作为自变量，模型拟合结束后发现污染物的系数经假设检验为显著差异于零，也就是没影响。这里，协变量与自变量在回归上是平等的，可以把协变量理解为控制变量，如果你考察吸烟的影响，那么吸烟与否就是自变量，包含污染物在内其他项就成了协变量。不过所有考察变量选择的原则在于其理论上或经验上被认为与目标变量有关系且无法通过随机采样、配对等手段消除影响，这种情况对于观测数据比较常见。&lt;/p&gt;
&lt;p&gt;当线性模型的自变量只有一项时，其实考察的就是自变量与响应变量间的相关性。当自变量为多项时，也就是多元线性回归，考察的是你自己定义的“自变量”与“协变量”还有响应变量的关系。如果自变量间不能互相独立，那么最好将独立的部分提取出来作为新的变量，这种发现潜在变量的过程归属于因子分析，可以用来降维。自变量本身存在随机性，特别是个体差异，这种随机性可能影响线性模型自变量的系数或斜率，也可能影响线性模型的截距，甚至可能同时影响，此时考虑了自变量的随机性的模型就是线性混合模型。线性混合模型其实已经是层级模型了，自变量的随机性来源于共同的分布。如果自变量间存在层级，例如有些变量会直接影响其他变量，那么此时线性模型就成了决策/回归树模型的特例了。如果层级关系错综复杂，那不依赖结构方程模型是没办法搞清楚各参数影响的。然而模型越复杂，对数据的假设就越多，对样本量的要求也就越高。同时，自变量或因变量有些时候也要事先进行连续性转换，这就给出了logistics回归、生存分析等特殊的回归模型。科研模型如果是依赖控制实验的，那么会在设计阶段随机化绝大部分变量，数据处理方面到线性混合模型就已经很少见了。但对于观测数据，线性混合模型只是起点，对于侧重观察数据的社会科学研究，样本量与效应大小是结论可靠性的关键，精细的模型无法消除太多的个体差异。&lt;/p&gt;
&lt;p&gt;高维数据是线性模型的一大挑战，当维度升高后，变量间要么可能因为变异来源相似而共相关，要么干脆就是随机共相关。在某些场景下，高维数据可能都没有目标变量，需要先通过探索性数据分析找出样本或变量间的组织结构。这种场景下应通过变量选择过程来保留独立且与目标变量有潜在关系的变量。也就是说，变量选择的出发点是对数据的理解，优先考虑相关变量而非简单套用统计分析流程。当然，统计方法上也有变量选择的套路，评判标准可能是信息熵或模型稳健度的一些统计量，可以借助这些过程来简化模型或者说降维。对于线性模型而言，就是均方误、Mallow’s $C_p$、AIC、BIC还有调节R方等，可借助回归模型软件来完成。&lt;/p&gt;
&lt;p&gt;回归或模型拟合都存在过拟合的风险，所谓过拟合，就是模型对于用来构建模型的数据表现良好，但在新数据的预测性上却不足的情况。与过拟合对应的是欠拟合，此时拟合出的模型连在构建模型的数据验证上表现都不好。这里的表现可以用模型评价的一些指标，其实跟上面进行变量选择的指标是一样的，好的模型应该能捕捉到数据背后真实的关系，也因此在训练数据与新数据上表现一致。&lt;/p&gt;
&lt;p&gt;在统计学习领域里，工程实践上最简单的验证过拟合与欠拟合的方法就是对数据进行切分，分为用来构建模型的训练集与验证模型预测性能的检测集，更细的分法则将检测集分为可在模型调参过程中使用多次的检测集与最后最终评价模型的一次性验证集，三者比例大概6:3:1，也可根据实际情况来定。也就是说，模型的构建不是一次性完成的，而是一个反复调整模型参数的过程来保证最终的模型具备良好的预测性与稳健度。&lt;/p&gt;
&lt;p&gt;在技术层面上，调参过程有两种基本应对方法，第一种是重采样技术，第二种是正则化，两种方法可以组合使用。重采样技术指的是通过对训练集反复采样多次建模来调参的过程。常见的重采样技术有留一法，交叉检验与bootstrap。留一法在每次建模留一个数据点作为验证集，重复n次，得到一个CV值作为对错误率的估计。交叉检验将训练集分为多份，每次建模用一份检验，用其他份建模。bootstrap更可看作一种思想，在训练集里有放回的重采样等长的数据形成新的数据集并计算相关参数，重复多次得到对参数的估计，计算标准误。在这些重采样技术中，因为进行的多次建模，也有多次评价，最佳的模型就是多次评价中在验证集上表现最好的那一组。&lt;/p&gt;
&lt;p&gt;正则化则是在模型构建过程中在模型上对参数的效应进行人为减弱，用来降低过拟合风险。具体到线性模型上，就是在模型训练的目标上由单纯最小化均方误改为最小化均方误加上一个对包含模型参数线性组合的惩罚项，这样拟合后的模型参数对自变量的影响就会减弱，更容易影响不显著，如果自变量过拟合的话就会被这个正则化过程削弱。当惩罚项为模型参数的二次组合时，这种回归就是岭回归；当惩罚项为模型参数的一次绝对值组合时，这种回归就是lasso；当惩罚项为一次与二次的组合时，这种回归就是弹性网络回归。实践上正则化过程对于降低过拟合经常有神奇效果，同时正则化也可作为变量选择的手段，虽然岭回归无法将系数惩罚为0，但lasso可以，这样在参数收缩过程中也就同时实现了变量选择。&lt;/p&gt;
&lt;p&gt;为了说明实际问题，有时候单一形式的模型是不能完全捕捉数据中的变动细节的，我们可以在工程角度通过模型组合来达到单一模型无法达到的预测性能。模型组合的基本思想就是对同一组数据生成不同模型的预测结果，然后对这些结果进行二次建模，考虑在不同情况下对不同模型预测结果给予不同的权重。这种技术手段可以突破原理限制，而最出名的例子就是人工神经网络里不同神经元采用不同核函数的做法了。&lt;/p&gt;
&lt;p&gt;对于科研数据的线性回归，还有两个常见问题，一个是截断问题，另一个是缺失值处理。截断问题一般是采样精度或技术手段决定的，在数值的高位或低位无法采集高质量数据，此时可以借助截断回归等统计学方法来弥补。另一种思路则是在断点前后构建不同的模型，这样分别应对不同质量的数据。对于数据缺失值的问题，统计学上也提供了很多用来删除或填充缺失值的方法，填充数据不应影响统计推断，越是接近的样本，就越是可以用来填充缺失值，当然这个思路反着用就是个性化推荐系统模型的构建了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研项目管理</title>
      <link>https://yufree.cn/cn/2020/09/20/project-management/</link>
      <pubDate>Sun, 20 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/09/20/project-management/</guid>
      <description>&lt;p&gt;科研项目的日常管理的原则可以有效提高工作效率，这部分内容即使离开学术界也对后续从事其他工作有帮助。虽然会涉及很多技巧，但技巧只是程序上简化思考的一种方式，沉溺于技术细节与选择不会真正提升效率，更重要的是打磨出适合自己可长期坚持的工作习惯。我个人认为有且只有两个技巧算是适合所有人的，一个是列清单，另一个是定期回顾。&lt;/p&gt;
&lt;p&gt;想开展项目，搞清楚研究目的，项目的进行一定是推动个人或课题组成长的，与目的违背的项目源头上否定。要先对自己跟同行有清晰的了解，知道优势跟局限性。这里推荐 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%BC%B7%E5%BC%B1%E5%8D%B1%E6%A9%9F%E5%88%86%E6%9E%90&#34;&gt;SWOT分析&lt;/a&gt;：先列举自己技术的优势与劣势，再列举外部环境的机会与威胁，对内外进行组合，设置对策，优势机会要扩张，劣势机会要补充不足，优势威胁要有预案，劣势威胁要对冲风险。&lt;/p&gt;
&lt;p&gt;每一个项目事先要进行规划。项目规划期间要发挥团队作用，进行内部头脑风暴，每个人都提出跟主题相关的内容，做成思维导图。然后对事项按工作量与影响力进行区分，选取工作量低但影响力大的方案。计划的目的是了解情况而不是制定教条，要预留结果不理想后的其他方案或灵活度。然后分拆出具体有时间期限的可执行的步骤，时间安排上可根据&lt;a href=&#34;https://wiki.mbalib.com/wiki/%E6%97%B6%E9%97%B4%E2%80%9C%E5%9B%9B%E8%B1%A1%E9%99%90%E2%80%9D%E6%B3%95&#34;&gt;紧急重要四象限&lt;/a&gt;来设计，优化步骤让所有事都在重要但不紧急的阶段完成。然后对项目的安全与经济风险进行列表，设计紧急预案，做到执行成本可控。&lt;/p&gt;
&lt;p&gt;实际科研并不是围绕单一项目，每个个体会有自己主导的课题，也会参与其他人的项目或同时主导多个课题。此时要做好整体时间安排，利用不同研究项目切换来转移压力放松，保证时间都浪费在有意义的事上，这里可以使用&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%94%98%E7%89%B9%E5%9B%BE&#34;&gt;甘特图&lt;/a&gt;来做时间规划。以项目为中心的管理是不同于被安排分工的传统模式的，需要扁平化管理，每个项目立项后有独立责任人与分工，项目完成则解散项目组。团队超过10人就要分拆，项目由需求与进展来指定或轮转个体角色，更好锻炼团队每个成员的综合能力，也避免个体螺丝钉化。&lt;/p&gt;
&lt;p&gt;项目执行中最大问题是拖延症，此时可参照计划中分拆出具体可执行的步骤来按部就班，执行时不思考整体，关注当下并进行记录，分阶段有始有终，每一阶段要停一下或定期整理记录并思考过程中出得问题与解决方案。如果对后续执行作出修改，一定知会所有团队相关成员。拖延症本质上是跟未来的自己博弈，如果自己对自控力没信心，可以尝试软件开发中的&lt;a href=&#34;https://www.allthingsdistributed.com/2006/11/working_backwards.html&#34;&gt;向后工作法&lt;/a&gt; ：先公开新闻稿，写问答，写用户文档，最后去写代码。在向后工作法中，你会受到来自外界的监督压力，也会在项目开始阶段就考虑审稿人或同行的批评，这样执行时目的更明确。项目进行中遇到新知识或者请教懂得人，或者自学，不要不停犹豫不前，随时把执行放在第一位。如果需要自学，推荐- &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%BA%B7%E5%A5%88%E5%B0%94%E7%AC%94%E8%AE%B0%E6%B3%95&#34;&gt;康奈尔笔记法&lt;/a&gt;与费曼学习法。前者强调回顾，后者强调通过教或写文章总结来学，一般人对新知识自己理解要求低于对他人输出知识的要求，当你需要教别人或公开自己的学习笔记时，会更严谨对待，也是跟自己惰性的博弈。&lt;/p&gt;
&lt;p&gt;项目完成后要对项目进行回顾并整理成报告存档。项目计划就是项目报告的前身与扩展，做好文档的版本管理即可。项目计划的步骤与实际步骤没必要一一对应但要有记录，报告要附带对原始记录的索引或直接将原始记录贴上去，所有针对项目的讨论与进展都要体现在报告里。报告可以同时附带更新幻灯片版，在拿到数据的同时做出发表质量的图像，如果需要对外报告可以在半小时内拿出成品。最终报告除了结果也要总结过程得失，特别是对比实际过程与计划步骤的差距，进而优化下一个项目的计划。&lt;/p&gt;
&lt;h3 id=&#34;项目报告模版&#34;&gt;项目报告模版&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;题目/开题时间/项目参与人&lt;/li&gt;
&lt;li&gt;研究目的&lt;/li&gt;
&lt;li&gt;SWOT分析&lt;/li&gt;
&lt;li&gt;团队头脑风暴脑图与预案分析&lt;/li&gt;
&lt;li&gt;可执行步骤的时间规划&lt;/li&gt;
&lt;li&gt;风险预案&lt;/li&gt;
&lt;li&gt;实际步骤记录与分阶段总结&lt;/li&gt;
&lt;li&gt;结果与讨论&lt;/li&gt;
&lt;li&gt;结论&lt;/li&gt;
&lt;li&gt;得失与下一步计划&lt;/li&gt;
&lt;li&gt;附录&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>启发法</title>
      <link>https://yufree.cn/cn/2020/08/24/heuristic/</link>
      <pubDate>Mon, 24 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/08/24/heuristic/</guid>
      <description>&lt;p&gt;最早接触启发法是在初中时学校半强制推销的一本书，名字大概是启发法解数学题之类的，通读下来最大感受就是那些题都是稀奇古怪的，解法也是类似灵光乍现的那种。到今天我是一道题都记不起来了，但当时确实没搞懂书名里那个“启发法”是什么鬼，其英文 heuristic 也是字如其名，搞不清词根哪来的。启发法的较正式的解释是非最优非理性快速解决问题或作决策的方法，包括试错、经验法还有拟设（类似假设检验），类似直觉经验判断的混合体。我相信你看这个估计脑子里也犯嘀咕，能不能说人话？&lt;/p&gt;
&lt;p&gt;我理解启发法大概就是瞎猜的艺术。说瞎猜是因为启发法通常用在资源不够的情况下，例如求解一些解析解非常复杂的函数方程，说艺术是因为瞎猜给出的解决方法很多情况下不是最优的，也不是唯一的。换句话说，启发法是用来完美解决问题的既不必要也不充分条件，属于没办法的办法，想到这一点我才突然发现已经在启发法的坑里玩了很久泥巴了，这不就是科研过程吗。科研外人看是有章可循的但到了前沿领域是没有完全可靠的排列组合路线的，例如当前疫苗开发，虽然各国都在搞但实话说没个几年是拿不到安全性评价的，副作用大家都是猜，甚至新冠病毒的最致命靶点究竟是不是只有肺都没搞清楚，有没有引发慢性病可能也是一头雾水。面对这种未知情况，其实初期用的都是类比与启发法，类比相似病毒，尝试各种可能方案。&lt;/p&gt;
&lt;p&gt;如果把启发法当算法来理解，一般包括两步，随机寻找与爬坡，随机寻找进行尝试，根据结果向着期望方向寻找直到达成目标或时间用尽。此时，使用者知道如何检测结果但不知道如何生成出现结果的机制。与启发式相对的是解析式问题（例如梯度优化），此时我们知道问题原因，可以根据原因来求解，例如有函数我们可以求导来算极值，而启发式则是只知道要求极值但函数未知，常用来解决黑箱难题。&lt;/p&gt;
&lt;p&gt;启发法里也存在一组制衡：探索（exploration）与利用（exploitation）权衡。探索侧重复杂空间例如完全随机搜索，利用强调快速求解例如爬坡。启发法中一个关键步骤就是探索完一次得到继续探索信号后如何生成新参数，微小的参数改变有利于寻找方向而较大的改变有利于摆脱局部最优。也就是说在资源有限条件下，想更多探索解决方案空间就没法获取很高的求解精度，反之，在局部解决方法上反复优化就没法探索更大的解决方法空间。&lt;/p&gt;
&lt;p&gt;不过，启发法本身的设计却可以很艺术的去探索两者的平衡。模拟退火算法的核心思想是在随机寻优结果是负面的时候也会以一定概率接纳，负面越高越不接纳，也就是尽可能引入改变来防止局部最优。禁忌搜索（tabu search）算法会预先设定一个列表，最优的结果都存到里面，存入后就不再考虑对应的参数修改方式，这个过程反复进行填满列表后最早的就可以踢出去重新考虑了。这也是防止局部最优的策略。迭代式局部搜索则从时间上做文章，先进行一段时间爬坡找到局部最优，然后进行较大的随机行走，在新位置上爬坡找最优，跟之前对比留下好的，然后继续迭代。&lt;/p&gt;
&lt;p&gt;上面这些策略都可以用，也可以组合使用。除了这类单一状态优化外，另一类启发法则是从种群角度进行计算的，同时进行多组扰动，根据结果探索变化方向。这个思路来自生物学里的进化算法，包括遗传算法与进化策略。基本思路是设置初始种群，计算适应度，然后选一部分个体进行一代遗传，遗传过程伴随突变，之后重新计算适应度，最后留下适应度高的继续遗传。&lt;/p&gt;
&lt;p&gt;种群初始化时要尽量多保持多样性，可以用哈希表来存储独立个体。在进化策略上，计算完个体适应度后只保留部分高适应度个体进行遗传，下一代数目与初始种群一致，例如每代10个个体，但只选2个最高适应度的遗传突变，下一代数量还是10个。当然，也可以在下一代里把第一代也都考虑进去进行筛选，如果一代不如一代，至少还保留了上一代的优良基因。突变率依赖正态分布的方差，经验法则就是如果多于五分之一子代表现更好，需要增加方差防止局部最优，如果少于则减少方差，等于则不变。&lt;/p&gt;
&lt;p&gt;在遗传算法中，子代生成是有父母贡献一半进行杂交然后加上突变的，这里面多一个随机翻硬币来决定子代那一部分交换的步骤，此时遗传部分的可能性空间是确定的，另外杂交过程也可以对连续变量进行线性插值。在进行适应度选择上，可以根据概率去选，也可以用非参方法排序来进行选择。&lt;/p&gt;
&lt;p&gt;在启发法特别是基于种群的启发法中，并行计算特别重要，你可以并行多组启发算法，或者在同一台机器多线程计算适应度，或者用分布式计算来分散汇总结果。如果需要多目标优化，就设计一个由多目标加权组合的新适应度指标。启发法也可以用在组合优化问题例如背包问题或邮差送信问题。此时可以先构建出一个组合，然后在有限时间内进行组分调整计算适应度，最后留下好的。蚁群优化则是先构建一组备选方案，然后计算适应度，记录各个组分的表现（信息素），重复这个过程，然后根据各组分信息素多少来选择最终组合。这个过程信息素可以挥发，备选方案也可以进行一定的爬坡，也可以用禁忌搜索来禁用掉一部分组分。同时随机数生成对于启发法也很重要。&lt;/p&gt;
&lt;p&gt;了解启发法的相关算法对科研是有帮助的，因为科学问题的求解通常面临资源有限的情景，此时预实验或探索性数据分析就要借鉴启发式算法的思想，不仅仅优化自己熟悉成熟的解决策略，还有留足够的随机行走空间。时至今日，很多科学问题可以通过仿真手段来验证与求解，怎么设计一个探索性仿真策略也需要对启发式算法有一定的理解。&lt;/p&gt;
&lt;p&gt;但最重要的是，启发法其实与认知偏误有时是伴生的，很多直觉性尝试都埋伏了认知偏误而容易导致陷入局部最优而不自知，而完全随机尝试的启发法其实是反直觉的。如果所有人都在用一套解题策略来攻克一个科学问题，那么尝试下从所有思路里随机选择可能会发现更好的解题策略，也就是要试错。不知道从什么时候开始，流行文化里对正确与成功的故事给予了很高的认可，很多人不能也不敢犯错，按部就班走流程排列组合在科研论文中形成了新八股的趋势。我们只能看到漂亮且显著的结果而不知道论文背后的试错过程，很多研究事实上脱离实际且不易重复，这种趋势会把科研人员的思路锁在那些四平八稳不犯错的研究而不是真正解决问题，把科学沦为了技术。&lt;/p&gt;
&lt;p&gt;现在我们很少在算法之外的课程里看到关于启发法的介绍，一方面是因为很多学科已经有了比较固化的研究模版，不愿意尝试高风险的启发法；另一方面则在于启发法里瞎猜与艺术性很难通过课程来学习，更多是一线人员自己摸索。不过，如果各学科可以更多介绍启发式思维，在有限资源下权衡好探索与利用，相信对于学科自身的发展也是有帮助的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研软件</title>
      <link>https://yufree.cn/cn/2020/06/21/sci-software/</link>
      <pubDate>Sun, 21 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/06/21/sci-software/</guid>
      <description>&lt;p&gt;我本科阶段用过的能沾上边科研软件大概就是 Excel 外带 origin 7.0 的破解版，后者还是从学长学姐那边拷过来的，顺道附带了我们学校打印店的病毒全家桶。我记得我们那时候高数课本是附带3.5英寸软盘的，里面有Matlab的实验习题，我倒是跑到数学院机房做过一次，但印象用的电脑中软驱坏了就很愉快地去听看别人下载在重启不删文件夹下的电影了。至于说当时大学生技术基础课里教的 C 语言，刷完南开一百题过了三级后基本就再也没用过。曾经在专业课学过 MapInfo 跟 CAD，但我们学院那个破机房，几十台机子里不是中病毒就是压根开不了机，上了几次课也就学了个基本操作跟概念。我们作为一级学科的工科与二级学科的理科，课程设计里连环境系统分析这种对计算模型要求非常高的课都安排了，但作为基础的数理统计与概率论却没有，学起来全靠自己悟性。后来系主任知道了去查了记录才发现我们学院前几届跟后几届的课程培养计划里都有概率论，偏偏我们这级给略过去了，只学了高数跟线代。当时本科研究里拟合个污染物吸附曲线都得靠搜索引擎跟学长学姐时而靠谱，时而废柴的经验，命令行界面基本是能躲多远就躲多远。大四毕设时我接触了文献管理软件，主要看的是罗昭锋老师的课，有了一点软件辅助科研管理的概念。&lt;/p&gt;
&lt;p&gt;真正接触科研软件还是去玉泉路读大五的时候，我说这是大五是因为中科院要求大部分研究生第一年都送到北京集中教学，第二年才回各自研究所开展科研工作。这一年有三个学期，课制则是上完一门就考一门的医学院体系，想读博的要一年修够博士阶段的学分，所以我第一年研究生忙得跟狗一样到处上课。玉泉路那边其实是科大的老校区，所以还有点校园生活相当于读了个大五，跟后面回所的日子天差地别。在玉泉路时，因为清楚自己要走科研的路，所以选了Matlab跟SPSS还有统计分析的课，当时就感觉原理懂不算懂，必须要掌握工具。那时候我也开始接触非 office 体系的排版软件并转向 Linux 系统，我记得当时有次交作业我是用 tex 文档编译的 PDF 文档，当时就为解决个中文输出及 bibtex 文献管理的编译就费了我一整天时间，最后搞出来的文档显示是中文，复制是乱码，相信很多朋友都有类似的折腾经历。我记得还用了 QtiPlot 这个软件一段时间来替代 origin，但其实也没太搞明白使用逻辑。那段时间感觉自己就是受虐狂还乐在其中，完全在盲人摸象中前进。&lt;/p&gt;
&lt;p&gt;等到了所里真正开始科研，软件用的就多了，例如化学结构需要 chem3D，作图需要 sigmaplot，SPSS等，文献管理用 Endnote，这些软件无一例外都是要交钱的。但我就没这个问题，因为这些软件都没有适配 Linux 系统，那时我疯狂寻找一切在线数据分析的网站，说起来，美味书签这个应用也是那个时候流行，后来销声匿迹。这种打补丁的分析持续到我博士的第二个项目，做化学信息学数据分析使用了 e-dragon 算了几百个分子描述符（好像还用了 mopac 的分子动力学软件做构型优化，但高斯那种巨无霸的坑我是掉头就走的），然后要构建 QSPR 模型，其实就是个多元线性回归配合变量选择。这个活就不能用图形界面软件或在线应用来做了，基本都得死机，然后我就去东北大学的六维论坛上拖回了Matlab并给电脑装了个虚拟机来死磕。我当时其实不懂变量选择的方法，因为大五我就没学过多元分析，这时我自作聪明根据不同分类的分子描述符提取了主成分，然后用超过80%方差的各分类主成分作为新变量去做回归，其实就是重新发明了分组主成分回归还是半自动做的。然而，在使用过程中我深刻感受到Matlab在建模上的强大，想系统学习然后就搜到了吴恩达的机器学习公开课。&lt;/p&gt;
&lt;p&gt;很多人机器学习的启蒙课就是吴恩达在C站上的机器学习，但我学的那会是字幕组翻译的课程录像，C站上线这个课大概是一年后的事。那时我每天中午会去半导体所边的小平房买份盒饭，回来就在办公室戴上耳机一边吃盒饭，一边看视频，一边记笔记。然而这门课确实给我打开了公开课的新大门，我开始到处找数据分析的公开课学，那个时候 来回切系统用 Matlab 非常不方便，而当时 Jeff Leek 在C站开了门数据分析的课（后来扩展成了C站最火的数据科学系列课程之一），使用了R作为工具。当时我对 IDE 不了解，那门课的作业全是在命令行里敲出来的，快结束时发现有款 RStudio 的IDE在课程论坛里被反复提及，所以就装上了而且几乎上手立刻就理解了项目管理对数据分析及科研项目的重要性。那时我基本圈定科研软件需要排版软件、文献管理与数据分析及制图软件，后面逐渐加入实验室管理软件与数据同步分享软件。&lt;/p&gt;
&lt;p&gt;这里插一段关于科研笔记软件的回忆，一般来说文献管理软件都附带这个功能。本科结束时我 Endnote 里的文献也有三位数了且科学院国科图事实上也购买了正版给学生用，但后来我还是转到开源的 Zotero 。一个很直接的原因就是 Endnote 的题录是需要数据库支持的格式，那时不管摘要数据库还是全文数据库也都提供结果的导出但格式很不统一，Zotero 那时只是火狐浏览器的插件但实现了自动识别题录并保存的功能，我转到 Zotero 其实就看重这一个功能，当然后来主流文献管理软件都支持这个功能了。不过在实践中我发现在里面记的笔记是真的没有用，笔记是探索别人的思路去记录每个文献的知识点，而自己用的时候需要让自己的理论体系里存在这个知识点，如果我在每一篇文章里记录知识点，哪怕文章结构组织再好也始终是分散的。所以后期我是用 Evernote 来长期管理科研笔记的，在 Evernote 里知识是重整为我知识框架的工具，每个主题一篇笔记，里面有原文链接但写的时候就当成综述一样。其实 Evernote 也是我付费订阅的第一个软件服务，不过大概率今年到期后我就不再续费，因为后面改用了 bookdown 的在线电子书形态来记录整理，保证新文献要快速消化到已有知识体系里，前些日子也整理了 Evernote 里四位数的笔记导出到 joplin 里，算是正式退休。其实这里面有段时间我是在用思维导图整理主题的，但那个时候 doi 还不流行，直接插入的链接很丑且对 Evernote 不友好。现在其实很多痛点都已经被解决了，但基于习惯的顽固我也没有转回去，相信后浪们一定能基于自己的经历去选择对自己最合适的，而不是始终沉溺于工具的选择。&lt;/p&gt;
&lt;p&gt;有意思的是，我这个软件工具的探索过程几乎都是始于付费破解软件，最后落脚到开源软件。一方面那个时候我实在是穷，但已经不太能接受去使用破解版软件了，最后的折衷就是来一整套开源软件，彻底远离那些破解与图形界面。另一方面则是当你真正使用一个软件，需求是放第一位的，如果开源能满足要求，我其实很反感一个大而全的界面而更喜欢一个软件或一个命令做一件简单的事。很多时候让我放弃商业软件，特别是图形界面的商业软件的最后一根稻草是因为功能界面搞的太繁杂，新功能我感觉用不上或者花钱（实际并没有）买了不需要的服务，你给我原料我来组装就可以了，你组装好了我还得适应你的组装思路就感觉花钱买罪受。不过最庆幸的是这一切都发生在我研究生涯的初期，软件选择是路径依赖问题，初期偷懒选破解，后面会有一屁股债要还，路越走越窄，会被商业公司牵着鼻子走。反之初期选了开源软件，了解更底层的需求，后面不论用开源还是用付费都得心应手，属于路越走越宽。时至今日，我对科研软件的选择原则基本是开源软件优先，在线应用补充的策略（也就是用关键词加 online 去搜索应用或直接在 GitHub 里搜索关键词或关键代码段）。而且我会尽量避免图形界面，这倒不是装腔，而是图形界面的参数设置很多论文里根本就不写，降低了可重复性，如果是脚本就很大程度避免了在数据操作阶段动手脚的风险。&lt;/p&gt;
&lt;p&gt;其实，多数情况下我也不会真的去查源码，但一定要保留这个选项，因为也确实出现过好几次代码报错作者联系不上然后我只能自己 fork 了去填坑的情况。不过，开源不意味免费而更多意味信息透明，你知道自己在做什么，任何一个软件包维护起来都是有成本的，用爱发电出现的各个软件社区其实是间接烧的科研经费或个人兴趣。这里一个很神奇的异类就是前面提到的 RStudio ，做的是开源软件也没耽误赚钱，用开源来构建社区生态，用生态吸引对商业版的付费用户且提供更高级功能。其实这个商业模式在科研软件圈非常不常见但在开源社区似乎已经是很成熟了，Linux 基金会目前也是主要依赖软件咨询与培训来盈利。其实今后我感觉科研软件开发者可以走类似思路，软件不要收费且通过开源来吸收社区贡献，个人版免费并通过模块化来维护高级版独占功能，然后卖订阅服务就是了，软件脱实向虚保持开源会避免很多知识产权的麻烦且不耽误赚钱。独占的知识产权与盈利其实不是互相依存的，对于科研软件而言，原始算法其实都能追溯到发表的文章，软件公司对其的速度优化可以作为高级版卖点但得有个面向个人的免费基础版，否则用户群上不去。&lt;/p&gt;
&lt;p&gt;说到底，科研软件有个不可能三角：源码开放度-用户群-学科习惯。如果软件闭源且用户群已经很大，就会导致产生僵化古板的学科习惯，新功能加不进去，例如 Endnot 的在线导入题录就落后 Zotero 很久；如果用户群大且学科对新功能需求高，就得依赖开源社区提供活力；如果闭源且学科对外开放，用户群很难做上去因为培训用户的成本很高。很多老牌科研软件的市场地位被前浪给锁定了，例如 SAS 在流行病学领域极为流行很大程度是整个学科很早期就形成了使用这个软件的传统，再比如 Matlab 在工科仿真几乎是行内通行标准。我们会看到新学科的科研软件例如基因组学、机器学习等基本是没有历史包袱而拥抱开源文化实现快速迭代升级，而老学科里开源软件的渗透就非常小众，积重难返，其实是挟持了行业标准来绑架用户。作为科研这种拼想法拼新意的领域，实现目的其实要优于对标准化的需求，简单粗暴的高级语言 REPL 最好，一行代码解决一个问题最好，如果要适配语言的复杂语法就可能让用户不爽。这个问题在 tidyverse 这个 R 语言的分支中已经有体现了，虽然出图漂亮，逻辑结构完整，但不断变动的语法框架会降低代码的可重复性，这对科研用户特别是前浪用户来说是无法接受的，如果新用户足够多倒也不用管前浪用户，但科研用户里具体到研究方向而言前浪用户的话语权就很重了，很多本身就是开发级用户而不是应用层的，天天为底层依赖的奇怪变动捉虫估计会有怨言。&lt;/p&gt;
&lt;p&gt;最近 Matlab 跟 ChemOffice 都爆出了因为政策或商业原因而停用用户许可的新闻，这种政策风险对于科研用户而言其实非常高，就好比选了个“美国为啥抓不住萨达姆”的课题做研究，新闻一来，吃饭工具都给你没收了。国内科研软件到今天都有放任盗版与破解版的黑历史，很多科研人员被商业软件驯化良久，想改变最大的敌人不是没有备选项，而是高昂的再学习成本。这口锅其实自己得背至少一半，另一半就是各学科在制定教学大纲时需要考虑风险而更多提供底层、开源的科研软件工具，不过很明显这是正确的废话，大学教学本质是服务就业，脱离行业要求估计市场也不认，而很多行业其实已经被某一两款软件事实垄断了。但在研究生科研工具的引导上则可侧重于可重复性与开源优先，一方面即使就业，研究生层次培养的能力从开源软件转闭源软件属于降维打击；另一方面纳税人的钱要用来产生公共知识反馈社会而不是养肥个别公司。在这一点上有另一个类似的利益集团：学术出版行业，吃相也是相当不体面，利用开放获取与数据库订阅两头拿钱而学术审稿人都是免费劳动力，超额利润不是一般的高。&lt;/p&gt;
&lt;p&gt;以后会怎么样呢？其实这次的停用许可对于公司与用户是双输，好不容易培养的付费习惯被强行中断，用户再学习成本也很高。如前面所说，这些老牌公司应考虑将基础功能开源化，不要去卖软件而是去卖服务与培训，把高级版功能作为咨询服务提供，脱实向虚，这样业务可持续性会好，砍掉销售聘用更多技术人员可以防止走传统行业拼营销而恶意竞争的老路。毕竟每年都有几百万的大学新生，这个市场撑得起头部好几个竞争者。如果固守软件本身的销售且不去建设开源社区，碰上懂王发飙就只能自认倒霉。这其实也是大趋势，Matlab 在科学计算上已经落后于 Julia 或 Python 了，ChemOffice 的基础功能我读研的时候就用在线应用替代了，开源后不仅能快速吸纳二次开发者回流，也能保持软件更新的活力，通过新功能定向咨询与基础功能培训就能维持可持续盈利，毕竟连微软都开始支持开源软件了。至于学术出版，我依旧看好预印本配合开放审稿的模式，学术期刊的运营也应该去公司化，类似统计之都主站模式，利用持续集成与容器技术将学术成果的运营开源化、社区化、公开化，用最少的维护成本实现最高效的学术交流。我不是说商业化效率低，而是商业化性价比太低，学术圈要是都搞不出一个自己用着顺手的开放交流体系，就只能掏纳税人的钱去养活这些养尊处优不思进取的行业。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>润物无声</title>
      <link>https://yufree.cn/cn/2020/05/09/drift/</link>
      <pubDate>Sat, 09 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/05/09/drift/</guid>
      <description>&lt;p&gt;在学生态学时，有一个概念我印象很深，叫做遗传漂变。大概的意思就是在遗传过程中会随机出现一些突变，子代等位基因的频率跟亲代会不一样，但持有突变的个体在初期是很少的，假如恰好被某些不可抗力团灭了，这种突变产生的多样性就消失了。我对这个概念印象深是因为很多人简单把进化论与自然选择等同，认为物竞天择剩下的就是有理的，但遗传漂变却提示很多剩下的特性其实就是个运气。进化论是少有的可以作为很多学科基础的理论，例如生态学、遗传学、生理学乃至心理学，很多时候现象解释不通了就会来一句，这是千百万年进化后的结果，具备最优适应性。&lt;/p&gt;
&lt;p&gt;作为科研人员，给不出解释是很狼狈的，甚至逐渐成为了不被允许的，很多人动辄说我们养了这么多科学家，结果最简单的现象都解释不了。然而解释或者理论其实不是科学的核心，科学家很喜欢提出新理论然后去验证，但不代表他们认为这些东西是对的。现代化社会将科学职业化与专家化是违背科学精神的，很多现象既不能证伪也不能证实理论而仅仅就是随机事件，然而这个随机却是公众很难理解的。&lt;/p&gt;
&lt;p&gt;拿遗传漂变举例，我们在A岛曾有一种没天敌的虫子，种群规模上不存在灭绝的理由，然而事实就是其中有一种对同族攻击性很强的突变株灭绝了，因为这种昆虫从出现突变到消失一共就繁衍了三代，正准备侵略同类时A岛被流星集中，赶巧击中了这一窝虫子，虫子们当场汽化去世而这个突变也确实没再出现。后来调查人员上岛调查就根本没看到这个突变株却在不远的B岛上发现了大量突变株，而A岛与B岛差异就是A岛上人不洗脚。然后研究人员认为自己发现了不洗脚跟昆虫种群差异的关系，构建了不洗脚对昆虫的自然选择理论体系，著作等身。但真实情况确实就是一颗没有被记录的陨石开的玩笑，但很遗憾谁也没记录这个事件。&lt;/p&gt;
&lt;p&gt;如果这个例子不明显，我们还可以从人类行为上去看这种现象。例如，蕃茄酱要不要放冰箱？豆腐脑甜咸哪个好吃？你用 Vim 还是 Emacs？这些东西可以看作文化或亚文化中的遗传漂变。这些争论有没有正确答案？或许有，但事实层面上就是个概率对立，持不同观点的人或许可以一起吃酒，但只要碰到这个论题就得大打出手。这里面有科学问题，但争论的人争的却不是科学问题，他们只是借鸡下蛋。对此，最好的应对就是不盲目归因，很多问题到今天没有答案就是还没搞清楚且对生存不构成威胁，既然对生存不构成威胁，也就没有必要进行非黑即白的选择与站队。很多人看似捍卫真理，其实是在捍卫自尊与社会经济地位。学者可以接纳不同观点而职业化专家才会打压不同观点，学者一直在事实中学着而专家依赖术语体系谋生，打压是为了在分工体系里保持权威，毕竟互相也看不懂。&lt;/p&gt;
&lt;p&gt;很多人质疑为什么最近100年出不了科学大师，这里面有两个问题：大师情结与现代化。有大师情结的人认为需要存在知识道德登峰造极的楷模，但其实科学研究就不存在峰，科学家都是现象面前的学生，一直被教做人，你让霍金去研究病毒他也懵圈。而现代化更是阻止了大师的出现，分工体系与术语体系构建出的利益共同体的生存法制里需要的是经费输出输入的循环，是资本推动经济发展的一环，资本哪有道德可言？资本喜欢投1块拿到100块的回报，哪怕投的是炼金术。对于现代社会系统，科学大师是不折不扣的奢侈品，是一种不存在似乎也不必要的想象物种。科研人员能维持学者的存疑都算轻奢，更常见的是精英专家式的价值判断与错误归因，只是不知道有些问题是不是已经严重到让系统崩溃，因为现代化里全局观都是抽象的逻辑的泛泛而谈，而细节疏漏才是系统崩的起点。&lt;/p&gt;
&lt;p&gt;说回遗传漂变，其实这是中性进化的重要组成部分，或者说中性演化更合适。这是对进化论很有益的补充，中性演化体现了遗传现象中的高容错度而并非强调外界生存压力或适应性问题。而且中性进化其实强调的是分子或基因组层面的变化而不是表型层面的变化，毕竟表型层面基本就跟生存斗争很贴近了，且从基因到表型之间能被生存环境调控的地方有很多。不过，虽然该理论得到认可比较多，但不意味着这就是真相，想想前面那个流星的例子就知道了，逻辑是个利器，但也诅咒了使用者，让其盲目自信。&lt;/p&gt;
&lt;p&gt;与漂变接近的现象叫做路径依赖，很多选择例如键盘排列啥的其实都是在起点上的选择导致的，这个选择的理由可能当时很充分，但后来就没道理了。你们有没有关注过小键盘区的数字排布，第一行是123还是最后一行是123？手机拨号键盘上为啥反着？只要你去观察生活，会发现各种不讲道理。这很正常，我体会变老的过程就是理性主义被经验主义按地上暴打的过程，人类只有在1-20年这个尺度上的决策行为比较理性，短期里面全是冲动而更长期看就是随机行走，然后过个20年又是一代人入坑。你可以尝试去拿自己的世界观去解释，然后会发现各种没法解释但过得好好的案例，这种嘲讽不是让你放弃理性，而是学会对事实谦卑。&lt;/p&gt;
&lt;p&gt;我觉得这种不唯一性挺好的，如果你分析我写过的文本，会发现我在助词使用上的一些“指纹”，我没有刻意形成但其就是存在。这种“不刻意”的规律在科研中给了我们新视角，也是所谓数据挖掘所想获取的东西，然而一旦你公之于众，附带上价值判断，这类“不刻意”的规律就会被玩坏，所谓圈子里流行的都是这种“不刻意”的刻意，另外整个搜索引擎优化产业就是“不刻意”跟“刻意”的一次次对战。然而，最麻烦的是没有公之于众而一直使用的规律，类似0day的漏洞，润物无声。&lt;/p&gt;
&lt;p&gt;这个时代最焦虑的是新闻媒体，他们的跟风几乎可以重现一些时代感。大概2010年后，媒体铺天盖地报道小学校车不规范的现象，有没有那么巧所有的事都2010年后发生？其实一点都不巧，就是中国人口在2010年的10年前也就是新世纪左右达到了一个低谷，而之前的人口高峰期新建了大量的小学，当人口不够时基层小学进行了合并，原来需要就近上学变成了集中上学，这才有了校车的需求，初期的不规范自然会出现大量事故。到了两三年前，幼儿园虐童又成了时代焦虑，而恰好其实是我所在的人口高峰的下一代进入幼儿园的阶段，事故的集中爆发背后是资源的时代不均分布导致的概率性高发。生活在时代中的人是很难跳出来去看这些事的而仅仅就是迎面茫然面对，正如不理解随机性，人们也不理解时代中的中性进化，很多事确实是平白无故的，但也有很多是前期事件累积后的必然，而这个1-20年的尺度其实现在是可以理性判断与预防的，起码最近20年我们的数据几乎是完全开放的。&lt;/p&gt;
&lt;p&gt;时代的润物无声其实是最需要关注的，我们回顾更长期的历史一套套的但却总是对过去的1-20年缺少回顾，这里面写满了盲目与愚蠢而多数人根本意识不到时代对自己的影响而单纯认为一切都是合情合理发生的。历史会重演因为时代感就是个随机行走，但个体可以不随机，哪怕这也是虚幻。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>疾病模型</title>
      <link>https://yufree.cn/cn/2020/02/28/d-model/</link>
      <pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/02/28/d-model/</guid>
      <description>&lt;p&gt;我经常跟别人吹用&lt;code&gt;caret&lt;/code&gt;包可以做到几百个模型的验证，做疾病模型很轻松，但实际没实操过。最近实际做了一批样品发现想跟做还真不是一回事，这里记录一下。&lt;/p&gt;
&lt;p&gt;这里我们遇到的问题是测了血样里的几千个代谢物峰，当然我也不知道具体是哪些物质。因为把无关变量加到模型里会提高模型整体方差，所以第一步我做了个自下而上的筛选。也就是说，不同于将疾病作为响应，把代谢物作为预测变量，我首先做的是把代谢物作为响应，把疾病状态作为预测响应的一个变量，同时对那些可能造成代谢物响应的协变量进行控制。也就是如下模型：&lt;/p&gt;
&lt;p&gt;代谢物响应 = f(疾病状态, BMI, 年龄, 家族病史)&lt;/p&gt;
&lt;p&gt;这一步是找出跟疾病状态有关系的代谢物，就是说对几千个物质逐一构建模型并进行错误发现率控制，结果发现一共也就十几个代谢物跟疾病相关。需要注意的是这里我默认预测或解释疾病只用这些代谢物就够了，但真实情况却可能是有些代谢物之间会有相互作用而在单一代谢物水平的建模是忽略了这种相互作用的。不过我这么操作主要是为了把不相关的代谢物去掉，由于我样本量有限，而过多代谢物几乎一定会在模型训练阶段过拟合，这一步操作是为了保证后面疾病模型的统计功效。&lt;/p&gt;
&lt;p&gt;得到十几个代谢物就去解释疾病对于一个暴露组学研究所来说属于严重失误，所以我从合作方那边拿到了被试的问卷调查数据，寻找并筛查了不超过十个与疾病相关的暴露变量。也就是说，目前我手里的变量都是在各自水平上与疾病有关系的，那么很大可能这些变量间也会有相关，例如有些营养指标会与代谢物相关，此时就可以用非监督学习方法对这些变量进行聚类来构建代谢物与暴露指标的关系。不过，我的数据里似乎代谢物跟暴露指标没啥关系，距离都挺远。那我们就可以走下一步来讨论疾病的影响因素了，这个自上而下的模型如下：&lt;/p&gt;
&lt;p&gt;疾病状态 = f(代谢物响应,暴露指标)&lt;/p&gt;
&lt;p&gt;这里我想需要知道代谢物与暴露指标那个对疾病状态影响更大，这就是个比较经典的机器学习问题了。由于前面自下而上的单变量筛选，虽然我的样品不到100个，但预测变量不到20个，勉强跳过了组学的高维诅咒。不过选啥模型就是另一个问题了，随机森林是生物新手的首选，支持向量机似乎有点过时，深度学习有点类似大炮打蚊子，要不要正则化…其实这里我的问题就是要有个衡量变量重要程度的模型，而且这个模型的预测效能要好。&lt;/p&gt;
&lt;p&gt;其实虽然我大概了解每个模型的假设与需要优化的参数，但我不认为存在一个完美模型，每一种模型都是从一个角度来审视数据中的信息。如果这个假设靠谱，那么对我而言最简单的探索方法就是尽可能多选择原理不同的模型进行训练，然后把训练好的单一模型组装为一个宏模型再次进行训练，得到不同模型的预测权重，然后在验证集上检验这个宏模型的组合预测。&lt;/p&gt;
&lt;p&gt;这里用了 &lt;code&gt;caretEnsemble&lt;/code&gt;包，我同时尝试了六种模型，从预测结果上看大概都在70-80%的预测准确率，然而当我组装出宏模型后，预测准确率就会稳定在80%左右，验证集上准确率甚至更高。这其实是一种非技术驱动的性能提升方法，我并没有去依赖某一个模型的精细打磨，而是暴力组合后训练出不同模型权重来进行非技术性性能提升，这实际就是一个神经元为不同统计模型的人工神经网络。虽然从预测结果上并不完美但组合后性能确实提升了，但当我检查这非常六加一的变量重要性时，我发现有一种代谢物的重要性总是排第一。很遗憾，这个代谢物数据库里没有，属于未知物，但无论如何，整个流程走通了。&lt;/p&gt;
&lt;p&gt;总结一下，要对疾病进行解释，可以先在单一分子水平上去除掉无关变量，然后耦合不同组学及流行病学的相关变量并用无监督学习来探索这些疾病相关变量间的关系，最后用多个原理不同的模型组合出一个预测效能好的模型，然后检查变量重要性来区别不同组学或流行病学变量的相对重要程度。这个流程最大的优势在于不依赖单一模型优化而是利用宏模型来整合结果，这对于疾病研究应该已经足够了，因为疾病就想知道两个问题的答案：那些因素可以导致疾病？这些因素间的关系是怎样的？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>关于模型的模型</title>
      <link>https://yufree.cn/cn/2020/01/20/modeling-models/</link>
      <pubDate>Mon, 20 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2020/01/20/modeling-models/</guid>
      <description>&lt;p&gt;模型是认识论的基础，所有的模型都是在抽象描述一些事物或事物的历史，也就是说物理上至少四个维度：三维空间与时间。但我们之所以可以称为事物，是因为其区别于其他事物或真空，那么指称事物就要求其可被描述或相对稳定，不能今天是鸭子明天成了玉米，这个事物要在空间内稳定存在而事物概念本身就是依赖语义模型搭建的，不同语言各有侧重，概念不清导致的扯皮就像是鸡同鸭讲，很多人拒绝形而上的讨论，很大程度是因为有些问题定义本身就不止一个。所谓稳定存在，指的是描述上要可重复指代，这个事物可以是固定不变的，可以是周期运动的，可以是随机化的，也可以是复杂的。后面两种的区别在于随机化的事物可以整体上统计描述而很难具体描述，复杂事物则存在规律性或模式。这四种形态可以用细胞自动机这种离散模型来生成，但真实世界事物比这个复杂很多。&lt;/p&gt;
&lt;p&gt;事物本身的规律是物理学家研究的内容，从亚原子到全宇宙。物理规律的存在让世界变得可被认识与预测。物理学中关于分子转化的那部分独立出来就是化学，化学里关注的分子中跟生命过程相关的部分就是生物。从物理到生物，规律的普适性在缩小与精准，越是普适的规律越像有用的废话，例如电磁作用力非常重要，但在描述蛋白质折叠上就不如氢键这种作用力模型来的容易懂。学科在细化过程中会针对物理世界存在事物的特性去构筑新概念，但本意应是为了方便交流描述而不是构建学科壁垒。其实，描述事物的物理模型可认为是缩小了的数理逻辑或加了限制条件的数理逻辑模型，例如数学上负数没有止境而物理上你写个零下一千摄氏度那就闹笑话了。同样的，虽然逻辑模型条理清晰易于梳理，但存在那种完全不合逻辑的事实，这个时候你改不了事实，最好考虑下是不是逻辑上漏了什么重要问题。从这个意义上看，虽然因果分析对于机理研究是非常好的工具，但如果事实收集有偏或关系错综复杂，那可能就是不能过分简化描述一件事。很多文章看似条理清晰有逻辑但事实却完全可能走另一条路，所以任何模型都不应该脱离现实世界。&lt;/p&gt;
&lt;p&gt;现实世界的模型描述根源上都是物理模型。物理模型可以描述一个物体，也可以描述两个及以上物体间的关系。在这个基础上提出的模型可以是描述事物稳定状态下的热力学模型，也可以描述事物在时间尺度上的动力学模型。然而，物理模型的研究因为历史原因到今天都偏爱自下而上用分析后组合的描述思路，结果就是经常无法反应现实。偏综合启发性的系统论则更侧重从描述事物间的关系出发来提出模型或框架，而很多时候我们也能观察到不同事物发展规律的相似性，例如幂律分布等。不论如何，模型可视作对事物认知的一个简化思考过程，如果为了用模型而生搬硬套，那就是本末倒置让简单事变复杂了。同时，模型的简化是很主观的说法，好在现代智人都有个共同的非洲祖宗，大家都认可的主观经常有客观的现实地位，但换个文明物种故事可能会很不一样。&lt;/p&gt;
&lt;p&gt;我们为什么用模型，很可能是因为模型减少了思考消耗，从现实的花花世界里提取出了共性与规律，这对生存非常重要。否则，我们就需要一个记忆力超好的大脑来对所有个人历史进行记录与反查。打个比方，一棵树结满了果子，如果我们大脑不能直接给出这是颗苹果树的认知，我们就得记住树枝啥样，每个树枝上挂的果子啥样，即使每个果子都长得差不多。这里苹果树的概念就是个很简单的认知模型，将我们从细节与噪音中拯救出来。因此，模型一定是抽象了概念并损失了细节信息的。知道前面有苹果树并不能告诉你哪个叶子上有虫子，而客观事物上却含有这部分信息，只不过我们这颗进化出来的大脑默默把这部分抛弃了。真实世界、模型与人的认知的关系是一层层递进的：&lt;/p&gt;
&lt;p&gt;$$真实世界 = 认知模型+模型未捕获信息 = 人的认知+人对认知模型的理解偏差+模型未捕获信息$$&lt;/p&gt;
&lt;p&gt;人起码都是要通过神经系统组成的生理模型来进行认识的，进一步讲则是语言模型，语言模型描述不准就因此产生偏差，配合模型本身对现实的抽象，人能认识到的世界都包含了模型的偏见与自己的偏见。自己的偏见可以通过学习或引入数学描述等方法来降低，但模型的偏见就不太好降低了。举个例子，地域歧视就是一种简化的认知模型，通过对家乡的询问来直接给出好坏判断，这个模型也许不反映现实但依旧流行，当然流行不代表就是合理。同时，模型本身也存在稳健度问题，简单的模型稳健度高但会因为对事实不敏感而描述单一，精细的模型会捕捉事实的细微变动但又因为过于敏感而描述变动很大。其实这个类似的描述在统计学里称为偏差-方差权衡，单一模型的优化实际上就是在过拟合现实与欠拟合现实中找个平衡点，然后提取出参数。当我们通过单一模型认识世界时，同样存在拟合度问题，地域歧视就是欠拟合而经验主义则常常过拟合。&lt;/p&gt;
&lt;p&gt;如何降低模型偏见？最简单的方法就是掌握多个独立模型，也就是说，单一模型的偏见/未捕获信息会被多个模型各自独立的部分抵消/覆盖掉，实现更全面立体的认识。在历史研究中，用某某主义单一解释历史事件通常会发现伪规律，好比拿锤子找钉子类事实去论证，但螺母这类需要扳手的史实就完全忽略了，多种历史观同时使用可能更有助于还原历史事实。不论哪一种都是对事实的偏离，简单模型符合奥卡姆剃刀原则而更容易被接受，然而整体看一个完美模型应该是构建在多个独立模型的结果加权整合上的，此时模型最反映现实，但有时候人们需要看的可能不是现实而恰恰是模型过滤后的结果。不过真正原理独立的模型可能并不多，很多模型直接本就相关或者存在更本质的一致性，这类模型整合后并不会发现更新的东西。如果两个模型是互相承接的，那么其组合模型的效果应该是独立模型的乘积而非加和。同样的，如果两个模型独立描述，其整体效果相当于单一模型效果的加权，只是权重是依赖实际问题的。&lt;/p&gt;
&lt;p&gt;$$完美模型 = 独立模型1 + 独立模型2 + &amp;hellip; +独立模型n$$&lt;/p&gt;
&lt;p&gt;模型永远处于接近完美而不能真正完美，因为总会有未知信息或视角我们还没发现。不过，现在人工智能的发展会导致我们可能做出一个描述超越人认知水平的模型出来，我们也许永远都无法理解其是如何运行但其预测性能却出奇的好。从工程角度看这并不问题，只是伦理上估计还得照顾下现代智人的情绪。更多的模型可以让最优点系统向以前认为的噪音部分移动，当然更多的事实或数据也会起到类似效果，现在感觉大家对更多模型的整合关注度还不够。&lt;/p&gt;
&lt;p&gt;总之，这就是关于模型的一个认知模型。对个人而言，更多的见识与开拓眼界会有助于发现世界的复杂与累积更多的经验，而更多视角的开放态度则可以让你发现更贴合事实的综合模型。诚然，很多模型虽然独立但跟你想关注的事无关就没必要整合，说不定还带了更多方差进来，很多事就是简单规则就最实际好用，不过在认知的探索阶段，多模型有助于实现整体超越个人的效果。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>可重复性研究的框架</title>
      <link>https://yufree.cn/cn/2019/11/14/reproducible-research/</link>
      <pubDate>Thu, 14 Nov 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/11/14/reproducible-research/</guid>
      <description>&lt;p&gt;实验结果的可重复性研究不是个新鲜概念，上个世纪就开始有讨论了，最早是心理学，现在已经蔓延到多个学科。但可重复性研究的流程其实比想象的要复杂，完整的可重复性研究包含多个步骤，例如人群可重复性、科学问题是否一致、假设是否一致、实验设计是否一致、实验人员是否一致、数据分析流程是否一致、代码是否可公开、推断的合理性与结论是否一致。新闻里常说的可重复性不好主要是最后一项结论的差异，但整体流程的任何一个环节都可能出问题。而且，原始报道者也常常用实验设计不一致、科学问题不一致等理由来解释两组实验结果的差异，那么有没有一个更好的评价框架？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/sciguide/sciguide_files/figure-html/unnamed-chunk-1-1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;有，当前在可重复性研究中目前比较可行的是自数据收集以下的可重复性，也就是可重复计算的部分。如果这部分有问题，那么前面也就不用看了，而且前面就用的原始作者的设计，也不会出现来自原始作者的质疑。这部分验证的成本相比全流程实验验证要低很多，对原始实验的报告者的要求也比较低，就是数据与代码公开，在我看来这会是一个切实可行的趋势。那么是不是作者公布了原始代码与数据就够了呢？&lt;/p&gt;
&lt;p&gt;也有问题。如果一组实验重复了二十次才看到一次阳性结果，那么只报道这一次阳性结果而隐藏十九次的探索过程是有问题的，从p值角度看甚至就是随机事件。实验学科的很多研究生经常或主动或被迫尝试一些新想法，此时几次不出结果就该考虑这想法是不是靠谱了，起码机械重复出的阳性结果在多次探索下已经不再可靠。但当前学术界的一些评价体制导致研究人员可能选择性报道自己探索出的成果，也就是发表歧视，其实对于读者而言，有价值的信息往往不是你怎么成功，而是你踩过哪些坑，没有坑的信息一方面你的结果不好重复验证损失影响力，另一方面我们丢失了太多探索细节与新发现的机会。因此，在实验可重复性计算的部分，我们需要研究者同样报道自己探索性实验记录，或者起码是可以电子化随时实名查阅的。然而，大量选择性报道可能出现一个副作用，论文的讨论很多是依赖引文，如果引文结果不靠谱，那么后续研究只有同样采用了选择性报道才能继续跟进发表，最后形成一种确认偏误，这情况比想象的要常见。甚至在系统综述过程中，对确认偏误的忽略可能通过结论影响决策者，那就成了一种自我实现。那么有了探索性实验记录是不是就够了呢？&lt;/p&gt;
&lt;p&gt;还是不够。当前科研属于“定语”科研，由于各学科基础理论已经相对完善，很多新发现都是建立在一些特殊控制条件下的。然而，当你进行条件控制时，其实又掉到了高维诅咒的坑里。打比方我做了一组实验，最后发现某种药在A条件B参数面对C人群中D年龄分组里是有效的。那么问题来了，假设ABCD全是互斥的二元变量，那么我这个结果实际上是做了16次对比得到了一次显著性结果。然而，如果我们采用p值，那么16次随机假设检验里出现一次p值小于0.05的概率是0.56，也就是说这个结果在完全随机状态下也有一半可能发生。其实可靠性跟p值没关系，最终是跟样本量挂钩，如果你的满足条件的目标样本很大，那这个结果很可能就是对的。相反，如果这个结果是来自于小样本，虽然根据多元模型是显著的，但具体到这个条件下其实就几个样本，此时结果就不能算靠谱。探索性数据分析通常会面对这个无穷假设困境，当你不断引入协变量后，维度的增加导致样本实际是稀疏欠拟合的，最后看到现象可能就是假象。因此对于此类“定语”科研，我们会要求定语条件下的样本量必须够多，否则就需要其他证据来说明现象。那么符合了样本量要求是否够了呢？&lt;/p&gt;
&lt;p&gt;依然不够。不同的统计模型会产生不同的假设检验结果，研究人员通常只会报道那些有阳性结果的统计模型。这个非常难识别，因为统计模型通常比较复杂且研究人员有可能是先上船后买票，也就是先发现这个模型结果有利然后根据模型组织文章。这里面会牵扯到探索性数据分析与论证的差异，如果研究人员把新模型当成了文章亮点，那读者是完全看不出来这里面的不恰当行为的。此时还是需要把探索性数据分析的流程也进行公开，如果大家都能下载到数据，标准化后然后同时跑多个模型，只有共存结果才有可能可靠。不过，这里面的问题在于多个模型的假设是不一样的，只有符合数据本身统计特征的模型才能被加入到评价体系里。在这里有个要求就是分析流程脚本化，这也是我长期以来一直反对使用图形界面数据分析软件的原因，如果你的图形探索流程可以脚本化也没什么，但仅仅说我用了某某软件是完全不够的。那么公开数据探索脚本对研究可重复性是不是够了呢？&lt;/p&gt;
&lt;p&gt;当然还不够。科学本身是构建在错误校正过程上的，但科学家评价却是人性化的，良好的评价很多时候成了科学家追求的标的。不论是对影响因子的追求还是学术明星的打造，非科学的评价与评优其实影响到了科研结果的报道。科学家正在作为一个团体来维护自己的利益与社会地位，其副作用就是对失败的低容忍度，年龄限制与成果限制使得探索必须要符合效率原则，很多年轻人在年富力强的时候做了大量排列组合而非探索性的工作来确保个人的生存无虞，这样造成的损失目前我们无法衡量。随之伴生的学术不规范、不端与造假则是层出不穷，很多人开始利用一些规则上的漏洞来实现非科研目的，例如审稿流程与评优。科学家的形象要由团体的文化来体现，阳光底下没有新鲜事，除了开放获取的研究成果，研究整体流程也应该实现透明化，这样可以很大程度防止暗箱操作。&lt;/p&gt;
&lt;p&gt;所以应对可重复性的问题，我们需要透明化科研流程，从基金申请到修改到进度报告到结题报告到文章的投稿接受与后续跟进研究及评优都要有公开的记录可以查询，文书都要经过版本控制方便返溯，所有研究人员都要实名负责对应的项目。学术团体接受公众舆论监督与同行监督，日常学术交流也要有公开的记录与反馈机制，所有的记录不直接对外公开但接受实名查询并留存查询记录。这样透明化的流程可以保证学术团体除了发表论文之外还有其他的结果展示途径，进而避免实验结果的选择性汇报与资源的过度集中。打破自我包装与人脉对科研的束缚，让结果更直白地展示给所有人。此外，关于可重复性，nature就近年来的科研可重复性危机采访了五组科学家，分别从认知、NHST、FDR、数据共享与范式转化的角度进行了&lt;a href=&#34;https://www.nature.com/articles/d41586-017-07522-z&#34;&gt;论述&lt;/a&gt;，值得一读。在医疗领域也有了一些有意思的讨论，例如认为基于人群的归纳式诊断会被个性化精准医疗所替代，此时可重复性里内含的平均律就会被彻底颠覆，分子水平的因果逻辑可能成为未来的主要知识探索方向。预印本、开放获取与审稿、科研社交媒体及数据共享等新&lt;a href=&#34;https://theoreticalecology.wordpress.com/2019/01/22/tree-species-richness-and-its-effects-on-productivity-neither-global-nor-consistent/&#34;&gt;趋势&lt;/a&gt;也孕育着新的问题解决方法。其实结果不可重复或者错误对于科学探索而言是可接受的，不然就不会有新知识的出现，但因非学术目的掩盖错误与选择报道实验结果就属于学术不端了。&lt;/p&gt;
&lt;p&gt;可重复性研究的明天是建立在今天的基础之上的，在流程透明的明天，谁在裸泳一目了然。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>暴露研究的范式</title>
      <link>https://yufree.cn/cn/2019/09/03/exposure-paradigm/</link>
      <pubDate>Tue, 03 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/09/03/exposure-paradigm/</guid>
      <description>&lt;p&gt;我博士阶段侧重污染物环境过程研究，在博后阶段逐渐过渡到暴露组学，研究思路其实有了明显变化，形象点说就是从一对一到多对一，一对多然后到多对多，这里总结一下，反正以后也会忘。&lt;/p&gt;
&lt;h2 id=&#34;一对一&#34;&gt;一对一&lt;/h2&gt;
&lt;p&gt;一种污染物对应一种健康风险或毒性终点，这是环境化学与环境毒理学研究的基本问题。环境化学的起点之一就是重金属污染，《爱丽丝梦游仙境》中疯帽子的原型就是当年做皮帽所遭受的慢性汞中毒症状的工匠，在这里一种单一的污染物对应一种病症，但这种一一对应的污染物-毒性终点并不常见。这里我们看下遗传病例如镰刀型细胞贫血，一个点突变就能造成病症，但更多的毒性终点或疾病并不是一个点突变就可以引发的。同理，对于环境毒理学研究而言，单一污染物引发独立疾病的情况也不常见，所以一对一研究在逻辑上虽然最清晰，但预测性很有限。一对一的研究范式目前还是主流，不论是构建毒理动物模型还是污染物迁移转化模型，这类研究很容易培养出某一污染物的专家，但这类专家视野会很有限。&lt;/p&gt;
&lt;p&gt;一对一的环境化学研究范式基本就是针对某一污染物进行三间分布研究，也就是污染物的空间分布、时间分布与人群分布。如果深入一些会加入该污染物的结构类似物或代谢产物，但这类研究更多是调查性质的，结合物化性质研究其环境行为。如果有环境毒理学配合，就可以对污染物风险进行评估，例如QSPR预测、离体实验（例如肝微粒体模型、植物瘀伤组织、斑马鱼胚胎）、活体实验（例如小鼠与植物模型），主要研究剂量效应关系、组织分布及代谢还有毒理效应。如果没毒性那么其实环境化学的调查就会非常尴尬，这倒是生态毒理学的一个来源，总能找到污染物影响。&lt;/p&gt;
&lt;h2 id=&#34;多对一与一对多&#34;&gt;多对一与一对多&lt;/h2&gt;
&lt;p&gt;单一污染物的毒性很容易做到死胡同，此时就要拓展污染物，从一种污染物扩展到一类或一组污染物，但健康终点还是一个，例如多溴联苯醚与多氯联苯还有双酚类污染物。此时就非常需要毒理学模型与环境调查的结果来缩小污染物清单，缩到那些确实有毒且环境介质中可以检测到的单体。在这里环境介质测到是相对容易的，但有没有毒就不容易说了，一方面是因为毒性终点实在多的没法数，以人体为例，肝毒性、肾毒性、皮肤毒性等等靶器官可能不同，同样的靶器官里组织、细胞形态还有分子毒理都可能不一样；另一方面则是毒性还有个剂量与暴露途径问题，很多人喜欢用癌细胞来做污染物毒性，但很多污染物压根就过不了皮肤，没有暴露途径空谈毒性对实际问题的讨论没有太大意义。&lt;/p&gt;
&lt;p&gt;多对一的研究伴随环境分析化学的发展而快速发展，现在同时测定多种污染物非常简单。然而，多对一的瓶颈在于多种污染物是否适合放在一个框架下讨论，因为理论上你随意找100种污染物去测毒性，总能找到一些有毒的，这不是说明他们真的有毒，而仅仅是随机性导致的。很遗憾，环境化学背景的研究人员对统计学的理解往往很肤浅，所以很多时候他们并不能正确解释实验数据，而是摘樱桃式报道那些有毒的单体，有的则简单套用QSPR预测结果来做并声明发现新兴污染物，采样地点也很讨巧地关注工厂附近或污水处理厂这类几乎一定会有检出率的地方。这样的研究可看作暴露研究但对风险的讨论往往比较有限，但配合后续的毒理研究则可以给出更多实际意义，不过坦白说没有流病研究支持的毒理学与环境调查如果遇到经费消减将会第一顺位被拿掉。&lt;/p&gt;
&lt;p&gt;多对一的一通常需要一个很综合的毒理指标，例如致死率、ROS之类，多对一的高端技术就是在线效应引导分析，样品经过分离后切割，一部分用质谱进行定性定量，另一部分走96孔板做一些通用的毒性终点，这对仪器平台及自动化水平要求都很高，作坊式的小课题组通常采用离线技术，配合半制备色谱来分离富集疑似高毒污染物进行鉴定。效应引导分析一般都是环境浓度，所以省了很多后期实际意义的讨论，但也正是因为环境浓度，经常你什么结果都看不到。套用基因组学概念多对一就是基因芯片与表型关系研究，人体也就两万多基因，表型固定为一个，看哪个基因在搞事情。在暴露研究中可把基因替换为污染物，当然一种表型可以是某种疾病也可以是某种毒理学指标。我们经常看到某类疾病即可能是基因相关也可能是污染物相关，这里面就牵扯到先天后天问题了，我个人认为表型或风险是基因、环境与随机性共同作用的结果，比例不好说，我并不相信单一污染物会是某种表型或风险的银色子弹，逻辑性很强的东西一般现实中都不太好使。&lt;/p&gt;
&lt;p&gt;一对多则是一对一在环境毒理学的延拓，此时毒性终点并不单一，而是用动植物活体模型或细胞模型仔细研究污染物的致毒机制。另一层意义上的一对多则是环境流行病学里生态学调查的研究领域，可以看某种污染物对人群中多种疾病的影响，这里面倒不能说多种毒性终点了，而是看你怎么对人群分类了，这类一对多对实验设计或调查问卷设计比较高，对统计模型要求也很高。一对多的经典案例是吸烟，除了肺癌，吸烟对喉癌、口腔癌、食道癌、膀胱癌、胰腺癌、肾癌及血癌的患病风险都有影响，所以现代流行病学里默认会把吸烟与否当成暴露研究的协变量，与之待遇类似的还有年龄、性别、BMI等。一对多在基因组学里有但不常见，不过一些经典通路的激活几乎是很多毒性终点的必经之路。&lt;/p&gt;
&lt;h2 id=&#34;多对多&#34;&gt;多对多&lt;/h2&gt;
&lt;p&gt;多对多是目前暴露研究的终极目标，复杂性极高，逻辑性很差，通常找不到单一理论来概括。多对多的第一个多是非目的分析，旨在找出样品中所有内源代谢物、标志物与外源污染物；第二个多则是暴露风险的多样性，这里也没有预设。这样的研究看起来就像是科学问题都不清楚就拿到了一大把数据做分析，很多传统分析的人很不喜欢这类研究，认为是瞎做。但传统分析的还原思路却可能事实上低估了复杂性。目前比较折衷的研究领域一个是代谢组学，关注内源代谢物在不同生命过程中的变化，实际上还是多对一。另一个研究领域就是暴露组学或环境非目的分析，关注外源污染物的健康风险，这一块接近多对多，因为健康风险可以有很多。&lt;/p&gt;
&lt;p&gt;多对多研究也是个神坑，能把第一个多搞清楚就已经凤毛麟角了，第二个多则必然需要与医院或公共卫生部门合作才能有数据。研究者需要对样品从采样到前处理到仪器分析有很深刻地全流程理解，这只是个起点，拿到数据后的分析才是坑中之坑，就算你好不容易对未知物进行了鉴定，下一步与健康对接则需要对生物化学、流行病学及病理学有着透彻的了解，然后你还要有足够的统计学背景与编程背景来应对你遇到数据的特殊性。全流程都能做通的人几乎不存在，所以多对多的研究一般需要依赖样品库、仪器平台、合成制备平台、医院与数据库等多领域人的合作，强强联合。&lt;/p&gt;
&lt;p&gt;在这个过程中，千万不要轻信商业软件，商业软件设计者为了商业化做了很多愚蠢的事，很多研究人员其实被软件给卡了研究思路而自己又写不了软件。同时，商业软件经常过于保守，NIST的谱库可以把一个物质在20种碰撞能下做二级，同时做三五种母离子，看起来很全面，但环境样品的基质效应会出现完全不同的母离子，此时谱库比对就成了垃圾。卖谱库的用标品来做没问题，但只要你处理过实际样品就会知道很多基质效应前处理根本就除不掉，同时很多中间产物根本就没有标品。如果你是个做科研的，就不要把复杂性甩包给软件，探索性研究尤其如此，用商用软件你很难发现新东西而仅仅是做验证。&lt;/p&gt;
&lt;p&gt;另一个坑就是要对统计方法足够警惕。不要别人用什么自己就跟着学什么，统计方法都有其历史背景与应用场景。如果你感觉实际问题很复杂，建议多使用仿真模拟重采样的方式来探索数据内在结构，模型使用上不要一味深度学习这类看似高大上的东西，谁不知道就是几行代码的事，其实线性模型与层级模型理解透了可以自由构建统计量来精准描述你关心的问题。模型的可解释性要更多从专业知识出发而不是单纯讨论模型本身，这个活很艺术。要时刻警惕p值的滥用与随机数的使用，保证结果的可重现性。&lt;/p&gt;
&lt;p&gt;最后要提的是多对多的科学问题，做科研不是为了炫技，不能创造不存在的问题。这个趋势在分析化学中很明显，有些技术所需的条件实际样品根本就不符合。而在风险这边则更有意思，20种污染物1个风险会出现1个假阳性，那20个风险会怎样呢？说不好听的，只要你数据属性够大，污染物够多，多对多研究你总能找到一些指标来指示差异，但这个结果真的可靠吗？有没有额外验证？应该说这是个很费脑子与体力的过程，可重复性尤其重要，不但你的数据支持，最好还要有开放数据集的支持。&lt;/p&gt;
&lt;p&gt;总之，在我看来，一对一的研究时代已经要过去了，当前多对一与一对多正在快速发展，而多对多眼下能做的地方并不多且问题一大堆。不过，这样才有趣。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科学算命</title>
      <link>https://yufree.cn/cn/2019/08/25/sci-future-telling/</link>
      <pubDate>Sun, 25 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/08/25/sci-future-telling/</guid>
      <description>&lt;p&gt;前一阵做了个23andme的基因芯片测试，想了解下自己这一坨里有多少历史遗留问题。我目前的观点是遗传、环境与运气三三分，也就是说如果我做了一件事，三分之一是遗传决定的，三分之一是出生后的学习与环境决定的，还有三分之一完全掷骰子。这类似个人认知的贝叶斯的主观先验概率，会根据后续知识与事实来调整。现实情况比这个复杂多了，有些病就是遗传病而另一些就是环境主导，还有些我觉得就是运气主导而那些弱信号经不起检验。基因测试，特别是现在消费级基因测试，基本是芯片测试，也就是测定的基因点位是固定的，属于目的性分析。当然现在也有公司做测序的，这两者区别在于测序是把DNA信息全都提取了，而芯片只是对两万个已知基因位点中一部分给测定了。鉴于目前消费级测序应该搞不了组蛋白甲基化这类东西，所以基本你现在测了跟10年后测差异不大，属于一次性消费。也是因为这个问题，这个行业是个存量行业，测的人越多，未来测的人就越少，趁行业还没消失可以尝试一把。不过这个行业还是有很多可持续商业模式的，例如以后做体内微生物宏基因组或表观遗传啥的，会有聪明人想解决方法的。&lt;/p&gt;
&lt;p&gt;一般测基因比较有意思的结果是祖源分析，这个基本都能倒退回非洲，我自己的祖源里84%的汉族，另外的非汗血统一半来自蒙古，另一半是韩国，还有约1%搞不清楚。不过这个结果跟数据库关系很大，我把芯片数据传到了国内一个平台上，结果85%的汉族跟15%的日本血统，不过基本上来说汉族还是靠谱的，只是不知道那八分之一东北亚血统是哪一代的故事，不过看意思至少是四代以上差不多是清末时候的事。我的尼安德特人血统比较弱，有217个变异，少于94%的23andme用户。&lt;/p&gt;
&lt;p&gt;至于说其他遗传病问题，23andme啥也没查出来，就有个乳糖不耐受还有个老年白内障，不过似乎我喝牛奶也没啥大问题，估计喝多了不行。至于说眼睛问题，眼下也没啥可说的，近视都十几年了。不过国内平台上倒是给出了不少风险提示，最严重的是一个原发性胆汁型肝硬化，比正常人高近10倍的风险，看了下男女发病率1:10，40-60岁发病，最严重时需要肝移植，免疫性疾病不可治愈。其余的风险都不超过三倍，考虑到发病率都比较低，即使是胃癌喉癌这类挺吓人的病也基本可以无视。有意思的是我抑郁症风险竟然是正常人1.4倍，但我要说自己容易抑郁估计认识的朋友都不相信。&lt;/p&gt;
&lt;p&gt;不过这也就是一种算命，披着科学外衣的算命，不是说这些公司迷信，而是解读的人很难理解概率而更多进行是非判断。只要比正常人高了就会担心，但其实人只要活着就有风险，喝水还能呛死人，坐公交还能出车祸。人本能是寻求确定性的，你告诉他今天下雨就会带伞，哪怕概率只是40%也是高风险。在这个本能下，很多人的决策模型都是决定论的或想尽办法去压缩随机性。但这个社会如果要稳定就需要随机性来调节，很多组织结构是金字塔的就是没办法让所有人都登顶，那种总想做些什么来改变自己概率的行为很多时候是徒劳的。例如只要去考试就要用专用橡皮或外套之类的，这些迷信行为跟结果关系不大，但却是本能里就有的，这事斯金纳做迷信鸽子实验的时候就发现了，这是我们的内生动物性。&lt;/p&gt;
&lt;p&gt;对于很多人而言，幸福就是拒绝一切不确定性，上重点小学、重点中学然后爬个藤，贷款学个医或律师，每天定时上下班，下班后举铁半小时，周末去近郊露营或星级酒店度假，每天跟邻居打招呼，买车买房买安全感，然后让自己的孩子也走这条虽然比较苦，但只要努力十拿九稳不会有风险的人生规划，很多人恨平凡恨到了骨头里却又向往稳定优渥的生活。那么别人呢？自然是无所谓了，挤上公交车的人会担心挤不上车的人上班迟到吗？鄙视链是必须存在的，不然他们会觉得生活失去了目标与动力，天天咒骂社会的动物性却也在加剧动物性。他们会删除自己成长过程中的不完美记录，让自己在别人眼中善良可靠正确无误，然而混淆了目的与手段，正是不完美的生活促进了成长，而完美的记录只会让你停滞到自己的安全区，但读文学作品时却妄图体会作者描绘的生活艰辛。前些日子看到个文章说安全区没什么不好，外面豺狼虎豹死无全尸，说到底看你想什么样的生活了，不同价值观的人就没必要互相喷了，浪费对方时间。&lt;/p&gt;
&lt;p&gt;勇气可嘉，但我觉得勇气需要敢于面对不确定性，任尔东西南北风。不是所有不确定性都可以压缩，很多时候人们做的事跟结果别说因果了，相关性都没有，但本能还是会驱使你去这么做。我中学阶段有强迫症，家里沙发绝对不敢坐右侧，走路一定两个方格完整跨过去，遇到台阶一定是一次两级的走，最后三级一步跨过去，这事持续到了高中，很多规则非常可笑，我都不知道怎么搞出来的。我并不知道这样做有什么好处，只是感觉不这样做就会出现很严重的坏事，对未来的恐惧让我意识到自己变得很不正常。这事除了我其实别人应该都没意识到，我隐藏地不错，但心理压力非常大，我意识到如果这样持续下去，最终会疯掉且没有人能帮到我。然后我选了那一周之后某天的晚上七点作为最后期限，过了这个期限就一定要打破我给自己设的禁忌。到了那一天晚上，我紧张地不行，呼吸声与心跳听的一清二楚，然而时钟过了七点，我强制自己做到了沙发右侧，眼睛一闭一睁，什么也没发生。然后我逐一打破了所有之前给自己设的莫名其妙的规则，还是什么都没发生，然后到今天我再也没出现过强迫症症状，相当于用强迫自己的方式治愈了自己的强迫症，然而，基因测试里我强迫症这项确实比正常人风险要高。我不敢说战胜了基因，或许这种强迫症并不重，但对十几年前的我而言，那种压力非常致命，有一种自己锁死自己的窒息感。不过当你走出来那种状态之后，一切都云淡风轻了，但这需要自己想通，别人开导没有用，甚至我怀疑绝大多数强迫症的人都相对内向，根本就不敢说或寻求开导，因为我当年就是这样。很多时候，外力是解决不了问题的，你需要对自己挥起手术刀斩断心魔形成的病灶。&lt;/p&gt;
&lt;p&gt;迷信有助于生存，但不能帮助你成长。高考那段时间，我所在的班上很多人都在服用脑白金啥的营养补剂，但我觉得没用，然后一模成绩很差，我的同桌都在吃且成绩都不错，所以似乎我成了个不吃药成绩差的典型。不过我当时没构建出吃药与成绩的因果关系，所以也就没管，最后成绩正常发挥。反而是吃药的同学中有发挥不佳的，我猜测是补药已经成了他力量的一个来源，但并不真实起作用，所以他可能因为补药而减弱了努力，最后自然会弱。借助外界力量来帮助其实并不能改变客观存在的不确定性，但一旦失去就会变弱。花钱买安全感是个好商业模式，但阻止了个人的成长，掩盖了不确定性的真相。&lt;/p&gt;
&lt;p&gt;同理，如果你遇到一个人在不知道某些技巧的情况下展示了与使用技巧后类似的能力，那这个人是很强的。然而，如果一个人强调形式与技巧，那么他的强大是暂时的，会需要体制来维护自己的软弱，甚至要通过偶像膜拜来维持形象。面对不确定性，你要有不做什么的勇气，这是对抗本能中求稳的倾向，营销这个行当非常善于创造不需要的需求，然后让你觉得买了一个商品就能获得掌控感，也有研究说掌控感可以让敬老院的老人恢复活力，不过额外的商品只是消费主义的陷阱，过了新鲜劲你还得买才能获得稳定感。&lt;/p&gt;
&lt;p&gt;面对迷信，很多人的观点是结果好就信，不好就是伪的，这不解决问题，最多是心理安慰。好比我做的这个测试，有些项目其实就是看着玩的，但真把这结果看着玩并不容易。你的本能会让你在看到结果后对风险项额外关注，寻求一些结论与对策，但其实很多结论与对策可能根本没用，连结果都可能是假阳性，三三分的模型可能更适合你。我觉得每个人都有个“解释性”大脑，把所有经验事实进行抽象推理给结论，在某种程度是理性的，但理性不代表真相。如果真相就是一个概率化的，无论如何都不能把概率降为零，那么理性推导会很难接受现实结果，但我隐约感觉这个世界就是概率的，信噪比的，真相与我们认为的真相间是存在压缩不了的不确定性的。现在很多人热衷于用传感器记录自己尽可能多的生理指标，但指标本身的不确定性与噪音可能就阻止了真相探索的精度。不过，真相可能并不带来那种稳定性的幸福，但每个人的幸福都可以自己决定，走到哪一步，你说了算，别被各种规则潜规则与人情世故搞得压力山大，这本质上也是一种强迫症，如果你不按经验套路或“最优路径”来，也许会发现一个自由新世界。&lt;/p&gt;
&lt;p&gt;迷信造成的心理问题，除了自己没有人能帮到你。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研圈的IP分级</title>
      <link>https://yufree.cn/cn/2019/03/09/reserch-ip/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/03/09/reserch-ip/</guid>
      <description>&lt;p&gt;现在科研细分领域实在太多太细，训练出的科研人员往往搞不清科研领域的整体状况，在研究背景或导论里胡扯的情况简直不要太多。大家都要吃饭，强调自己研究的重要性无可厚非，但是面对公众或其他领域科研人员单方面强调自己的研究其实是某种程度的欺诈。对一个学科在科研总体中的量化是很有必要的，在这里分享下自己的经验。&lt;/p&gt;
&lt;p&gt;虽然很多人批评文章数量不代表学科热度，但我觉得起码每篇论文都在解决一个科学问题，所以这里的比较就统一用文章数量。为了进一步简化评价，我们这里就用 pubmed 数据库作为例子，也就是说探索的是生物医药领域内不同研究领域的发展状况。方法也极为简单，就是关键词搜索。下面这个过程大家可以自行验证，其实用 web of science 更合理，但考虑到需要有对应权限我就不展示了，可自行探索。&lt;/p&gt;
&lt;p&gt;首先先分析下具体的人。我自己追踪的学科内紧密相关研究一年发文量不超过100，也就是一个周一两篇的样子。这个知识更新频率应该是比较符合科研人员个体信息处理能力的。如果你关注的领域非常热，发文量很高，那么大概率你也会自主把文献查新的量通过关键词叠加来缩小到一周一两篇，一季度甚至一年出现一小领域综述的状态。而且这个量我觉得对大多数科研人员还是超载了，很多研究人员的课题非常精细，一年内同行发文量个位数，全世界也就几个课题组在做，那么此时应适当眼界放宽些，否则你的研究会被视野限制住。&lt;/p&gt;
&lt;p&gt;当一个关键词年同行发文数量超过一百时，围绕这个关键词的全国性年会就会召开，也可能会拥有自己的专业期刊与学会，小型国际会议也可以组建了，例如纳米毒理学或持久性有机污染物。这个状态下的学科要么快速发展，要么快速衰退，全球相关课题组数量不会超过三位数，这类学科一年内如果频繁登上CNS，那么很可能进入指数增长期，但如果一年内一篇都没有，那消退也很快。如果低于这个量，那么关键词对应研究组可能还从属于某个大学科，属于大课题下的边缘课题，绝大多数退学的博士生都是挂在这类几乎看不到发展希望的项目上了。顺带一提，国内的杰青级评选的候选人至少要在国内是这个量级领域下的数一数二的人物，这样的领域整体看大概1000个左右。&lt;/p&gt;
&lt;p&gt;当年同行发文量超过两千时，千人级国际性会议就能开，开的不错，行业内会出现多份期刊来吸纳不同层次的论文。而且我观察超过一千后的研究领域很少有萎缩的，但这是第一个停滞点，很多领域的规模上限就是两千。从人才角度看，国内在这个量级上数一数二的人物都是院士级的。这样的关键词例如纳米银、生物医药里的深度学习，这个量级如果能保持增长，那绝对会是学科热点，估计对应从业人员超过一万了，这类学科基本都有产业化的课题做支撑了。&lt;/p&gt;
&lt;p&gt;年同行发文量在两千到一万的学科是非常多的，这是通常意义上的的科研 IP 例如代谢组学、精准医疗。这类研究你应该能从公众报道到听到了，全球有四位数的课题组，基本每所综合类大学都有至少一个人在从事相关研究。国家重点实验室基本都是在这个量级上构建的，企业也会有研发团队，且这个量级的实际需求已经有行业级支撑。&lt;/p&gt;
&lt;p&gt;超过一万的关键词都可以称得上前沿或热点学科并且已经有能力渗透到其他学科了，例如纳米颗粒、基因组学、分析化学、睡眠、衰老等。每天科技新闻都会有相关报道，是CNS的常客。相关创业公司会受到科技类风投的重点关注。然而这里会遇到第二个停滞点，实际上这个量级的研究已经是此消彼长的发文量了，相互之间会有学科级资源分配问题，在国家层面会出政策来扶植这个量级学科的成长，当然如果财政有限，拿来支持的资源必然是其他学科抽的。这个级别是可能萎缩的，例如同位素研究在上世纪六七十年代曾经超过一万，但现在稳定在四五千的体量，这就是撞了停滞点了。&lt;/p&gt;
&lt;p&gt;然而，还有一些顶级 IP 。生物医药科研里的顶级 IP 是细胞，最近三年年发文量稳定在不到27万的样子。然后是癌症，这个关键词最近三年基本稳定在17万。研究血液的在15年达到顶峰，发文量14万。脑类相关研究在17年见顶，不到8万的发文量。另一种热点疾病的是心脑血管疾病，在16年达到顶峰，大概不到7万的年发文量。有两点体会：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顶级IP一般要发文量超过5万，但似乎不会超过30万&lt;/li&gt;
&lt;li&gt;很多顶级IP在14年之后停止了增长，或者稳定，或者干脆下降&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些顶级 IP 而且几乎每一个都有一堆下属子学科，子学科的国际会议都能达到几千人级别。这些关键词几乎都配备国家实验室或研究所，数量每个国家也就十几个。这类学科已经不是渗透其他学科发展了，更多是引导性发展，这个领域出现的方法学进步会直接超越其他领域，也能吸引到很多超精英，带动整体进步。诺奖应该就是这个量级关键词上的进步的后果。&lt;/p&gt;
&lt;p&gt;不过顶级 IP 在14年后的相对停滞是个值得关注的现象，我怀疑单一关键词存在一个体系上的发文上限，可能是经费、可能是人口、可能是整体教育水平、可能是技术限制、可能是资源相对竞争、也可能是难度。总之，数据就在那里，值得思考的东西很多。&lt;/p&gt;
&lt;p&gt;这里我简单分个级（按幽游白书的分级方法）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;S级 年同行发文量超过5万的关键词领域，疑似有停滞点&lt;/li&gt;
&lt;li&gt;A级 年同行发文量1万到5万的关键词领域，有停滞点&lt;/li&gt;
&lt;li&gt;B级 年同行发文量2千到1万的关键词领域，有停滞点&lt;/li&gt;
&lt;li&gt;C级 年同行发文量100到2千的关键词领域&lt;/li&gt;
&lt;li&gt;D级及以下 年同行发文量100以下的关键词领域&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个应该就是科研人员的天梯系统了，研究在D级，关注到C级的研究动态，参与B级领域的会议，蹭A级的热点，然后远远看下S级开心就好。通过这种简单但可能不靠谱的分析，科研人员应该可以实现一个对自己的清楚定位，然后合理规划自己的视野，防止见树木不见森林，也防止迷失在过大的森林里。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>全栈科学家自测题</title>
      <link>https://yufree.cn/cn/2019/01/29/full-stack-scientist-quiz/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/01/29/full-stack-scientist-quiz/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;定性定量分子量100-100万的物质需要用到哪些仪器？优缺点是什么&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;多重比较与多重检验的区别与联系是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;傅立叶变换在光谱分析与质谱分析中的应用场景有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简述21世纪学术圈出现的“可重复性危机”主要指什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ssh远程登录启用图形界面需要加什么参数？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;野外采样的就餐原则是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何快速将牛腩煮烂？这个方法与提取亚细胞结构的内在联系是什么&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;伪码写一下梯度下降算法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简述文献管理的原则与你的方案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;审稿意见该怎么写？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;观察实验与控制实验的模型选择有什么区别与联系？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两组样品同时测定了100个指标，简述可视化与统计分析两组样品差异与共性的思路&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;冷干法不适于测定生物样品的哪类指标？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;t检验、方差分析、线性模型的共性是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;超净台日常使用的注意事项及与通风橱的区别&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;15分钟学术报告需要多少张幻灯片？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简述引用文献的不规范行为有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;给你的研究写一份新闻稿&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验室如何进行项目管理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;什么是编译？为什么有些软件需要编译？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;三间分布在调查类研究中的常用统计方法有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;组学数据的功效分析怎么做？谈下思路&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;完全萃取与不完全萃取的定量原理有什么区别？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简述二代测序的原理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;NCBI的常用数据库有哪些？能查到什么信息？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;石墨、石墨烯、石墨炔、碳纳米管的区别联系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从头计算、DFT及分子动力学模拟常用来解释什么问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;主成分分析与偏最小二乘回归的区别与联系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用正则表达式提取日期&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;分析化学的灵敏度与统计学的灵敏度概念有何异同？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;agent based model 可以用来做什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;请列出3D打印实验仪器所需要的硬件与软件平台&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;统计模型与仿真模型的区别与联系&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;生物学实验数据log转化的物理学基础是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;细胞培养防污染需要哪些措施？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;与非门与异或门是什么？电路标记画一下&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简述下样品命名的原则&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;随机数如何重现？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;有限元分析的应用场景有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课题组需要一个网站来发布信息，请简述搭建过程及前端设计&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验用品供应商如何联系与筛选？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;利用网络开放数据可以做什么样的研究，请举例&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何鉴定采样得到的植物种属？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验室数据安全需要注意些什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验室人员流动时交接程序有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验室垃圾分类该怎么做？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;简单说下你对团队协作软件的看法&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;学术伦理主要涉及哪些方面？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;野外采样期间突发事件如何处理？例如生病、交通延误、地方黑恶势力等&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何甄别实验室数据造假？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;技术重复与生物重复的区别是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;电镜照片计算平均粒径的方法是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;探索性数据分析的常见方法有哪些？应用场景是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正交试验结果如何解释？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自制层析柱有哪些指示物可以用来标示洗脱进度？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同材质手套的使用场景&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;反应釜的温控手段有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常用样品脱水材料或手段有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何从论文图片中提取数据？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何鉴定培养基污染菌种？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如何计算数据处理所需内存？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;并行计算在CPU与GPU平台上有哪些流行的框架？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哪类问题可以进行集群计算？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;贝叶斯统计的可信区间与置信区间有什么区别？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;相关不代表因果，那么能代表什么？有哪些其他解释？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;时间序列最大的特点是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;常用物质数据库有哪些？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;谱图比对匹配的算法原理是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;动态规划算法用来解决什么问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;EM算法用来解决什么问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直接质谱分析与表面增强拉曼光谱各自优缺点是什么？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;解释下内标法定量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;无监督聚类有哪些方法？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用决策树算法配合重采样技术估计变量重要性如何实现？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;线性混合模型用来解决什么问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模型验证方法有哪些？解释下ROC&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>研究生教育的灰犀牛</title>
      <link>https://yufree.cn/cn/2019/01/12/graduate-rhinoceros/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/01/12/graduate-rhinoceros/</guid>
      <description>&lt;p&gt;今年国内研究生入学考试报名人数刷了新高，达到200多万，而这里面应届占一半多一些，报录比在缓慢降低。有一个很有意思的现象，报考研究生的人数并不是一直上升的，事实上，2007年、2013年都出现过报考高峰然后下一年回落的情况。2007年高峰是2007年经济形势一片大好，工作比学位来钱快。而2013年的高峰则值得玩味，14年15年的持续下降很可能跟当时经济形势上行有关，最近三年的重新上升则又体现了毕业生对就业的担忧。而且往届生与应届生报录人数同时增长，说明毕业生普遍认为学位比工作更有价值，或者说本科就业形势不佳。&lt;/p&gt;
&lt;p&gt;我们再看看高考，中国高考报名人数在07-09这三年都突破了千万，此后人数稳定在九百四五十万的样子，录取则是在2016年达到巅峰的705万。对比高考录取人数与研究生录取人数就会发现高校中本科生规模已经见顶，但研究生规模持续增长，录取难度整体下降可能也是吸引考生报名的重要因素。&lt;/p&gt;
&lt;p&gt;可以预计未来三五年如果研究生持续扩招（推测20年见顶），搞考研培训、出国培训、期刊校稿还有高校教职将出现最后的快速发展窗口，之后将进入稳定期。然而，这三五年我们将会看到更多关于研究生团体的讨论与新闻调查，我们的研究生教育发展可能还跟不上研究生团体扩大的速度，中间的差距是一头典型灰犀牛。&lt;/p&gt;
&lt;p&gt;从学生角度看，眼下的研究生热潮跟经济压力有关而跟科研兴趣没啥关系，所以很有可能出现学生自认打工仔的情况而在混日子等就业的情况，高校或研究所的心理辅导如果跟不上会出不少极端问题。从导师角度看，上个10年的高校扩张吸收了大量新导师，而持续增加的劳动力所需要的管理经验基本都比较欠缺，毕竟他们读研时周围没那么多学生，研究生无指导或指导过激情况会不断出现。我们会在近几年看到一系列因为研究生极端事件而采取的改进，但能否做到预防，就看高校研究所的领导团队是否有意识了。&lt;/p&gt;
&lt;p&gt;研究生身份更像是一个容器，容器里面的是22-30岁的年轻人，都有着明确的导师学生关系，这个容器越大，微弱的声音就更可能汇聚成大的声响。这个群体的心理健康连同与之紧密相关的导师的心理健康都非常重要，这里面研究生群体是弱势群体，很多研究生对情绪调整可以说毫无头绪，这是成长的烦恼，但高校的象牙塔属性与导师制并不保证健康成长。社会里公司可以靠成熟持久的制度职场教做人，导师学生关系却永远只会是二到八年的临时身份，显然后者出问题概率更高。导师靠自觉来解决问题也并不容易，可以借鉴的经验基本就是个人成长经历，这玩意多半是个邻居孩子的故事，励志还行，并不能捕捉体会到当下研究生的真实感受。资源、机会、奖惩、社会整体就业压力都面临公平效率间的平衡管理，偏巧这玩意课堂里是不教的。师生交流不畅会成为今后研究生教育问题重要来源。&lt;/p&gt;
&lt;p&gt;读研的是人口少数，多数人的问题例如扶贫环保才更重要，但我想说的是网络话语权。显而易见，未来几年我们社会里最有时间在网上发言的大学生研究生群体会持续走高，我们应该会看到更多对这个群体的讨论与新闻。事实上，千禧一代在制造话题上从来都是行家，他们伴随互联网技术崛起而成长，他们普遍教育程度的走高对整个社会，特别是舆论引导会产生巨大影响。如果你去回顾下这些年社会新闻的焦点，基本都能找到千禧一代的身影。他们在中国人口基数中比例很高，裹挟了上一个婴儿潮作为父母，可以说对很多经济形态例如网红经济、知识付费、新零售、消费升级、租房市场等提供了消费需求。他们的消费与网络话语权决定了新兴市场会听取他们的态度而不是大多数人的态度，而新闻媒体从来都是求新的。现代社会本质上就是知识精英的社会，因为现代社会的大厦只能通过各类专门知识来管理，单纯资本或人口不解决问题。&lt;/p&gt;
&lt;p&gt;这是一个浪潮，浪潮的下一端是人口结构的变化，千禧一代可能是世界范围内最后的婴儿潮。眼下发生在非洲东南亚的那一拨可能有人口红利，但没有互联网同步发展的技术红利，如果不出现类似互联网的普惠技术，很多发展中国家事实上或者说政治上不存在多大的发展空间。所有问题都可能是时代问题，这几年有，下几年就没了，但身处时代之中的人往往是最容易看不到问题的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>全栈科学家</title>
      <link>https://yufree.cn/cn/2019/01/08/full-stack-scientist/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2019/01/08/full-stack-scientist/</guid>
      <description>&lt;p&gt;本来是打算写别的，但今天下午的例会彻底把我搞怒了，我现在越来越明确地感到分工促进效率这句话在科研中是多么扯淡的事了。我在去年总结中提到不喜欢进取心强的人，其实有点一棒子打翻一船人了，也不用猜了，说白了就是西奈山这边的两个AP，一个P开头纽约城市大学毕业的，一个A开头哥大毕业的，我说的是名字。这二位有个共同点，都是所谓搞数据的统计学家。坦白说，从这二位的报告上我看不到任何闪光点，接触几次后更是再也不想打交道了。问题有两个，一个是目中无人，一个是外强中干。没有第二个其实我能接受第一个。&lt;/p&gt;
&lt;p&gt;这些所谓统计背景出身的人每次例会一出现就是一副高高在上的样子，经常性习惯性打断别人说话，然而我不能接受的是满嘴“bull shit”去否定别人的研究且理由根本站不住脚。我统计学是纯外行，但我从来都是鼓励更多实验学科出来的坑主学一些统计学的概念与思想来解决实际问题，不过窃以为统计学纯理论的发展已经脱离实际了。不，确切说是实际问题的复杂性已经不能考虑理论上的精巧了。这二位显然是没受过实验室训练还装自己受过训练，拿块芯片去讲批次效应自己还只是个合作者，二代测序都预备过气了。另一位满嘴模拟数据，我自己收集过两位数的不同数据集去看分布，基本是一个实验一个样，你那个从理论分布里跑出的模拟跟垃圾没啥区别，也别去怪做实验的不懂，懂得才不会用。&lt;/p&gt;
&lt;p&gt;前几年对数据的追捧让很多受过统计教育的人在学术界迎来了春天，我也觉得一个现代实验室需要配备统计学家。不过现在我不这样想了，我觉得需要配备的是统计思维与意识，真正解决问题绝对不能靠统计学家，特别是那些完全搞不清状况上来就胡说八道的主。跟他们提新概念一脸懵比，可重复性的理解只停留在代码脚本层上，讲起东西来倒是挺颐指气使的，讲火山图就讲火山图，找张火山照片问哪里拍的？鬼知道你哪里拍的，知道了对你讲火山图也没用啊，这种半吊子演讲技巧大概也是哥大特产吧。解决实际问题的人往往更关心问题的复杂，而沉溺于自己那一点点专长而到处挑刺的统计学家我觉得任何团队都不需要。解决问题需要工具箱，不是一个锤子就能走天下的。统计学家确实有开其他学科后门的钥匙，但也得对其他学科的问题有理解再喷啊，很多建议做过实验的一听就知道是“何不食肉糜”。&lt;/p&gt;
&lt;p&gt;就代谢组学或非目的分析而言，实际问题从实验设计到数据处理到处都是坑，单纯纠结数据采集不完美或新手乱用软件包不解决问题。更让我感到搞笑的是当我说可以用rmarkdown来进行工作流的标准化时竟然来一句rmarkdown是 worst 中的worst，因为让很多人认为不了解算法单纯填空就能解决问题。好吧，其实我是同意使用者要对算法有了解的，但怪到rmarkdown上是几个意思。要是没有这个，学习使用R的精力成本是非常高的，重复别人的计算工作更是成了天方夜谭，sweave里LaTeX有多少坑，那是个不能说的秘密。更简单的工具的确降低了学习的门槛，能让更多人不用去面对大量的调参，但并不是说调参就是研究的全部。统计模型也好，仿真模型也好，说到底都是真实问题的抽象，用模型用错了与等待完美答案中前者更反映科学试错的本质而能被审稿人或同行纠正，后者则更像是逻辑爱好者的游戏。&lt;/p&gt;
&lt;p&gt;分工促进效率在面对可分解为具体步骤的行业或学科是好使的，但面对真实问题例如疾病，实验者与数据处理者是不能脱节的。但指望两拨人放下成见平等交谈是很不现实的，因为占据理论高度的数据处理者或者说统计学家总会觉得做实验的是啥都不懂的。不过你不可能不湿鞋就过河，不了解实验具体操作就在那边对实验设计指指点点只会让实验者与统计学家的隔阂越来越大。所以我觉得解决实际问题需要培养全栈科学家，就是那种从采样到样品分析再到数据分析都有概念的科学家，即使以后实验可以外包也必须要进行所谓脏活的训练，数据科学家需要洗数据，全栈科学家可能连样品都要亲自采集，纸上谈兵绝对不行，养出一堆赵括天天跟你扯术语用的对不对完全就是浪费资源，全部开掉完全不影响进度，他们只是想通过凸显自己的专业性来找面子，根本就不打算解决问题。&lt;/p&gt;
&lt;p&gt;很多时候模型是否精巧，参数是否最优确实会产生影响，但模型或软件的设计需要考虑用户体验。xcms 3 就很不人性的去掉了子文件夹识别为分组的功能，逻辑上没错，但你让一个做一天实验的研究生处理数据时写正则表达式找分组就任性了。我一直提倡的是默认值要能解决80%的问题，因为搞明白默认值里所有参数的含义基本相当于重写一遍这个模型，这个对使用者要求就有点过了。理解算法思想与核心参数然后调用函数解决问题应该是软件设计者对使用者的预设，不是说要让使用者用软件时重新走一遍设计流程，这是抬杠。这也是我说要标准化工作流的重要性，每个研究都有独特性不假，但有个基础工作流可以保证大多数工作不是在做无用功。要知道，工作流存在的意义就是哪怕一个新手去操作也不会犯低级错误，你管这个新手懂不懂干吗？不懂不还有同行评议来检验吗？标准化工作流就相当于软件默认值，有默认值我们回过头来讨论问题是很容易溯源的，连这个都反对，你是觉得大家都搞独门秘籍无法互相验证更好吗？科学的发展是建立在共识上的，各搞各的是打算开餐馆吗？&lt;/p&gt;
&lt;p&gt;专业的人喜欢谈差异与术语，解决问题的人更关注问题背后的共性。统计学家不要拿起实验设计不够随机与混杂因素工具变量啥的一堆术语去居高临下教育别人，这些问题要是都解决了一个t检验不就天下太平了，还需要统计学家做什么。扎根实际问题然后抽象出可测量的统计量，然后在模型中进行控制或考察，让结果具有可比性与重复性才是更重要的。我觉得统计学家不能固步自封，新技术一直在出现，新理念也一直在出现，自己不懂就去打击是很幼稚的行为，没听说过 reproducible research 还没听过重复性危机吗？隔壁哥大 Gelman 大人天天那么努力写博客都不看吗？我觉得有些AP转正只能靠数据科学的风口了，骄傲而无知能撞到一个人身上也不容易。&lt;/p&gt;
&lt;p&gt;吐槽半天说的还是美国，但毕竟人家都意识到统计学对其他学科的重要性了，国内的路更长，因为搞实验的还停在民工培养模式上。现在教学与技术手段已经足够发达了，培养一个全栈科学家可能并不比培养一个赵括更困难。上世纪科研界花费了大量精力去构建术语体系与专业学科的墙，这个世纪我们该尝试打破这些意义不大的墙去解决一些复杂而现实的问题了。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>暴露组学的黎明</title>
      <link>https://yufree.cn/cn/2018/11/07/exposome/</link>
      <pubDate>Wed, 07 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/11/07/exposome/</guid>
      <description>&lt;p&gt;最近参加了西奈山医学院举办的第二届暴露组学会议，其实我并没注册，只是实验室有位老师身体不适不想去了我去顶的包。暴露组学从名词提出了到现在大概10年有余，大约从去年开始进入高速发展阶段，判断标准就是论文数量，应该说今天的暴露组学大致处于20年前基因组学的发展阶段，方法还未成熟，标准尚未确定，不过都快成形了。&lt;/p&gt;
&lt;p&gt;美国这边最早开始提暴露组的是NIH，加州伯克利、埃默里大学都是暴露组学起步比较早的地方，西奈山医学院 2017 年成立了美国第一家暴露组学研究所，借助美国医学院间的网络来推动暴露组学研究。从参会情况看也是很多其他高校附属医学院过来的同行，相信在接下来的10年研究经费与成果可能出现井喷，现在都是天使轮。&lt;/p&gt;
&lt;p&gt;暴露组学研究什么呢？这里的基本问题跟基因组学差不多，是关于健康的。一个人健康与否基因组学认为更多依赖基因，而且伴随测序技术的进步，针对个人的测序已经是可负担的了。但暴露组学认为人的健康状态除了基因外还要考虑表观遗传、蛋白组、代谢组与日常暴露，甚至还要考虑诸如地理位置、社会经济地位、肠道微生物组等的作用。总体来看，健康是目标，预测变量却非常多，很明显不是一个单因素模型。&lt;/p&gt;
&lt;p&gt;暴露组学属于面向问题的高度综合性学科，基础包括但不限于统计学、生命科学、数据科学、社会科学、环境科学、分析化学、毒理学、公共卫生、医学、遥感、传感、自动化、信息科学等诸多学科，我们目前并不知道哪个学科更重要，但很明显任何一个学科都可能成为回答终极问题的短板，而且就我个人观点而言，几乎每一个学科都有短板且学科间交流壁垒不是一般的高。&lt;/p&gt;
&lt;p&gt;这里从环境分析化学与数据科学这两个学科来说下目前的问题。首先，当前如果要评价暴露水平，首先你得知道有什么，也就是目的性分析。但很遗憾，就暴露组学而言，我们并无法事先知道样品里有什么，所以更多研究是借鉴代谢组学的方法利用高分辨质谱来对未知物进行信息采集。信息采集的终点是色谱质谱峰，然而高分辨质谱全扫描的结果往往混杂大量源内反应形成的加合物、碎片或物质本身的同位素峰，这导致虽然我们可以同时收集上万峰，但形成这些峰的化合物可能只有峰数的十分之一且这些峰会共相关，如果你想讨论物质间的相关性而使用了峰数据，那么估计会有偏。同时，峰识别的算法也通常对全扫数据很不友好，你会看到大量不应该被当作峰的数据被选成了峰，积分效果也是一塌糊涂，这一点从分析化学角度是不可接受的。&lt;/p&gt;
&lt;p&gt;另一个问题是对未知峰的标注，现在流行的方法是先跑全扫筛出差异峰，然后把那些峰去打二级质谱，有的则直接对差异峰去标注。这里我们暂时不讨论气相色谱质谱联用的数据，因为一般硬电离模式下碎片的特异性还算好，甚至可以用来定性。然而，就液相色谱而言，如果我们不考虑APPI这种非主流电离源，一般来说液谱往往使用ESI或APCI源，这两种都算软电离技术，一级质谱几乎看不到太多有价值的定性信息，此时使用一级质谱定性是风险很高的，下游的通路分析会因此不靠谱。而且就算找到一级质谱的匹配，你也无法确认是否是同分异构体，而同分异构体的生物活性千差万别，更不用说当前主流数据库各搞各的，覆盖范围有局限性，唯一的标注也并不意味定性。二级质谱定性当前有很多软件可以做，但基本都是欠拟合状态，训练用的数据基本依赖可获取标准或社区用户共享，想做未知物十分困难。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.cn/images/htfdrd.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这是当前主流物质数据库的覆盖情况，其实最大的三个物质库（PubChem/Chemspider/CAS）我没列，因为数据搞不到或搞得到但处理起来太费劲，最大的应该是CAS，有1.4亿种物质，当然我们能接触到的应该只是其中很小一部分。代谢组学里用的最多的应该是 HMDB ，不过暴露组学看来这都属于生物内源物质，外源有生物活性物质也有诸如 DrugBank 或 ChEBI 或 T3DB 的库，工业品也有 HPV 库等等，但这些还算是有信息可查的，有些物质最多能生成个 InChIKey ，别的啥资料也没有。目前能汇总整理这些信息的地方并不多，而且我在处理有些库的数据时发现他们的数据整理问题很大，格式不标准，如果不是专业人士光是数据提取就得懵圈。&lt;/p&gt;
&lt;p&gt;另外，分析通量也是一个容易被忽略的问题。假如你的样品有100个，每个样品30分钟，加上质控样品后一个序列大概能到150，这就是3-4天的连续分析，色谱柱会老化，甚至质量轴都会漂，当然你可以不断去校准。但最后的结果就是即便不是分批测样，同一批内部都会存在明显的批次效应。我常看到文章里说都控制好了，实际这个过程其实很难控制，随机化序列在一定程度上可以缓解但很难消除分析通量带来的定量不准。&lt;/p&gt;
&lt;p&gt;即使分析上的问题都解决了，下面的问题就是统计分析了。用什么模型，为什么用这种模型眼下都没法检验，你也说不上哪个好哪个坏，其实都不怎么样。我看到过买几千个标来检验的，但问题是你设计非目的检测是想测未知的，也就是标根本可能覆盖不过来。而且统计模型的复杂性可高可低，一般说高了过拟合而低了欠拟合，不是说不能一次性尝试几百种统计模型或机器学习模型，关键如何解释？线性模型与层级模型是两种最有解释力的模型，但预测性能谁用谁知道，直接上神经网络不是不行，就是不好解释。精巧的统计模型面对错综复杂的数据，难怪临床上喜欢多元线性回归。&lt;/p&gt;
&lt;p&gt;另一个相关问题是QSPR，代谢物或暴露物有差异一般都要反推回结构，通常临床研究是有明确终点的，但环境研究可能没有分组或者说分组后并无法进行效应预测。这个角度看是可以用效应诱导分析来做的，但效应终点还是相对固定。此时可以借助QSPR来同时预测多个毒性终点，不过如何把荷质比转成结构，前面说了，一团乱麻。其实多个毒性终点也意味着不同的健康模型，那么问题来了，有没有基于多个健康模型的宏模型呢？回答这个问题只能依赖合作研究了，单一领域其实都没搞特别清楚。&lt;/p&gt;
&lt;p&gt;跟健康相关研究还有个问题就是无穷混杂因素，有的你知道例如年龄、性别、种族等，有的在建模时是忽略的，甚至根本意识不到可能是混杂因素。传统研究喜欢点对点做相关，组学研究是点对多做相关，健康研究的真相是多对多互相影响，控制实验当然是必要的，但如果数据是来自观测研究，那这问题就几乎无解，受研究共同体的视野限制。如果我们只关心那些强信号，可能忽略了那些弱信号，但这里的强弱是仪器决定的，不是生物学意义决定的。或许很多人的研究可以讲一个故事，但很难回答一个真实的问题。&lt;/p&gt;
&lt;p&gt;前面说的问题只是现存问题的很小一部分，每一点的进展都可能对上下游研究产生颠覆式影响，对研究方法论的标准化、可重复化及与对基础研究进展的快速整合是必要的。或许十年后回看今天的暴露组学，很多人可能惊叹于为什么大量的资源被浪费在了毫无意义的研究上，不过这就是科研的现状，我们无法预知今天的愚蠢，但更重要的则是要意识到当前的问题。&lt;/p&gt;
&lt;p&gt;处在新研究的黎明期即幸运也不幸，幸运的是大家起跑点都差不多，不幸的是只要你跑，摔跟头几乎是必然的。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>参考文献那些事</title>
      <link>https://yufree.cn/cn/2018/10/22/reference/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/10/22/reference/</guid>
      <description>&lt;p&gt;你能分清BibTeX、Natbib、BiblateX、biber、Better Bib(La)TeX、bst、bbl、bib、ris、csl、sty、cls…吗？如果能，这篇不用看了。最近要把文件迁移到工作电脑里，不得不去整理Zotero。因为我之前用的时候都是想到哪就去尝试，所以不迁移还好，一换新环境就要重新配置插件。这里面我最不愿折腾的就是bib文件，生怕配置错了key一换，后面的编译都出问题。不过我知道有类似体会的肯定不止我一个，那就来考考古，说下参考文献那些事。&lt;/p&gt;
&lt;p&gt;参考文献系统是一种论证体系，两个人辩论都会来点名人名言歇后语，写书的话自然更要旁征博引，有时候是为了给读者参考的线索，有时候则是证明自己不是第一个胡说八道的。其实参考文献的证据强度并没变，张三引用李四引用王五的话，说到底还是有源头，如果源头不靠谱，后面就都成了空中楼阁。这个简单的道理常常被畅销书作家忽视，眼下我已经看到很多书在引用《思考，快与慢》里关于启动效应的研究，但那篇研究因为样本量不大，其实被很多人批评过无数次了，只是这并未妨碍一伙知识二道贩子拿来出书论证。其实我认为可以参考的事要么是纯现象论证观点，要么是前人有局限的观点进行理性批判，但最好不要拿观点来论证观点甚至构建理论体系，特别是事实基础不牢靠的观点。当然这又跑题了，技术上看参考文献就是文章中某个点进行标注，然后文末列出参考源。&lt;/p&gt;
&lt;p&gt;这样看，当我们处理参考文献时，至少要涉及引用文献的地方与列举文献的地方。当年高德纳想出本书，结果对出版社的排版系统非常不满，所以自己动手开发了TeX，说这个是软件还不如说是一套编程控制语言，这个故事很长，但简单又不负责任地说，老高在写作中混入了排版控制语句，用 &lt;code&gt;\&lt;/code&gt; 来声明开头，然后当排版软件读取混入控制语句的文本后，文本就按照控制语句设计的方式排版进行输出。所以你要有兴趣去读 tex 文件，会发现满屏的控制语句与文本混在一起，但好处就是纯文本文件，写文本的人是知道自己在干嘛的。后来出现 LaTeX 打包了一些常用的控制语句可以直接让作者调用，此时写作者省事了，但对细节的控制权也逐渐交给预定义的软件。这是一个典型用权限换取效率的过程，伴随不断封装，用户的权限不断降低，上手难度不断降低，可以进行的操作就更依赖其他人的扩展包了。所以我常说至少要学一门编程语言，不为别的，起码要知道自己为了换取使用方便而损失的自由度以及你可以实现的自由发挥空间有多大。&lt;/p&gt;
&lt;p&gt;LaTeX是处理了排版，但参考文献比较特殊，虽然本来也内置了&lt;code&gt;\cite&lt;/code&gt;来标注并定义了一个样式环境来列举文献，但功能非常弱。面对比较复杂的参考文献，BibTeX 是另一套专业的软件，初学 LaTeX ，很多人都对先 latex，然后 bibtex，然后再pdflatex两遍的流程有印象。这背后的逻辑就是第一遍latex找到所有的控制语句锚点生成引文与列举文件地点的 aux 索引（还有交叉引用什么的，暂不讨论），然后 bibtex 根据引文文件键值去读 bib 文件里的文献题录与指定的样式文件 bst 生成 bbl 文献列表，然后再latex一遍把这些内容合并到主文件里，此时 aux 位置会发生变化，引文找不到位置，最后latex一遍根据最新 aux 最终生成需要的输出。需要注意的是 bibtex 只关心列举文献的那一部分，引文那部分需要其他宏包来处理。&lt;/p&gt;
&lt;p&gt;这当然不方便，然后就有了natbib，这是个一站式解决参考文献的方案，同时定义了引文格式与管理bibtex题录，基本上你可以用natbib来愉快的写论文了。在 natbib 里，你可以无缝调用一些期刊提供的 bst 样式，例如:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;\usepackage{natbib}
\bibliographystyle{stylename}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;指定了列举文献的样式，正文中用 &lt;code&gt;\citep&lt;/code&gt; 或 &lt;code&gt;\citet&lt;/code&gt; 可以支持更多样的引用形式。natbib 充当了bibtex的前端宏包，单纯支持bib文献，对应的文献管理软件，也就是生成bib文件与引文中关键词的工具一般为 JabRef。那么是不是这套方案就完美了呢？&lt;/p&gt;
&lt;p&gt;显然不是，如果完美，LaTeX 后面就不会出 XeTeX 了，高大神是说英语的，他并没想到自己这套系统会走向世界，然后就遇到了编码与语言问题。这是两个有联系但其实关系不大的问题，在参考文献的处理上也遇到了类似问题，bib格式本身有限制，这时出现了 biblatex ，刚开始biblatex是为了取代 natbib 设计，后端还用 bibtex 处理目录，在引文设计上引入了万能的 &lt;code&gt;\autocite&lt;/code&gt; 来自动判断引文。但 biblatex 为了国际友谊，重新设计了一个 biber 来处理 bib 文件，而且更进一步支持了 ris、endnote xml 等格式，且引文样式与列举文献样式及后端都可以在导言区一步到位设置好（natbib只能设置列举文献样式但相对自由点）。应该说biblatex是新时代的参考文献排版宏包，无奈很多期刊还在坚守 bibtex 的阵地，但因为biblatex是可以调用bibtex作为后端的，所以建议现在打算入坑 LaTeX 排版的直接投奔biblatex的怀抱。&lt;/p&gt;
&lt;p&gt;但其实我根本就不建议入坑LaTeX，你得知道管文档类型的cls文件与管文本样式的sty文件等的运作原理，不然学起来会很费劲，然而为了管理文献，你还得学一套biblatex，你不晕我写的都晕。当然现在我们有 latexmk 来掩盖运行三遍 latex 的尴尬，也有 tlmgr 这种管理包的方便工具，但还有 pandoc 啊，这货是各种文档格式转换的利器。在处理参考文献上很简单，只不过 pandoc 引入了另一个参考文献样式：csl。&lt;/p&gt;
&lt;p&gt;严格说csl跟pandoc没啥关系，是一套基于xml的引文与列举文献样式的定义，现在主流期刊的定义都能&lt;a href=&#34;https://citationstyles.org/&#34;&gt;查到&lt;/a&gt;，也被 Zotero、 Mendelay 与 papers 这三大文献管理工具所支持。只不过pandoc在处理格式转换时用了csl。当然，需要事先说明的是，pandoc可以进行基于natbib与biblatex的LaTeX相关格式转换的。但很明显csl更简单明了，需要什么期刊就用对应csl编译就可以了，Rmarkdown 就支持这个转换的，在Yaml里写好用什么csl文件就可以了。前面说的文献管理软件也是这样快速转换期刊格式的。当然，肯定有人会去问biblatex的作者能不能也支持csl，不过这就相当于换掉biber的后端重新写一个，而且csl文件对于简单的输入输出是没问题的，比较复杂的情况xml格式本身就会限制住很多复杂情景的实现。&lt;/p&gt;
&lt;p&gt;说了这么多，其实更实际的情况应该是markdown写作，csl排版参考文献，有瑕疵手工修改就完了。不过我知道一定有人还会坚守 bibtex/biblatex 阵营，那就顺其自然吧。但说了半天都是排版的事，文献管理该怎样呢？首先，强烈建议使用bib格式来存储参考文献，基本所有管理软件都兼容。其次，就是键值问题，前面说了，你得告诉排版工具引文在哪里，这个控制语句可以做到，但引文对应到bib文件里哪一条就需要一个键值了，这个键值 Zotero 好像用的是哈希值，那玩意跟乱码也差不了多少，所以有人开发了 Better Bib(La)TeX 作为 zotero 的插件来生成人读得懂的键值（不过这就可能出现重复了）。&lt;/p&gt;
&lt;p&gt;下面我说下实际操作，用 zotero 收集管理文献生成键值，同步bib文件到论文目录，用 markdown 写论文，需要插入参考文献可以用 fastcopy 的方式直接拷贝或拖拽pandoc支持的键值到文档里，生成的md文档用pandoc直接调用目标期刊 csl 样式进行格式转换，至于说是word还是tex还是网页，看心情就好。当然如果你用 RStudio 与 Rmarkdown，直接安装 citr 包，Zotero 装上 Better Bib(La)TeX， 同步好bib文件，用citr的RStudio插件就可以直接搜索插入参考文献了。如果配合上 rticles 包，那么学术论文在 RStudio 里一站式完成毫无压力（最好搞清楚模版里用的排版文献方式是不是csl，如果不是，Zotero可自定义的拖拽方式可能更好）。&lt;/p&gt;
&lt;p&gt;当然，我更看好的还是基于&lt;a href=&#34;https://yufree.cn/cn/2018/01/11/doi/&#34;&gt;年初&lt;/a&gt;说的基于 DOI 跟 crossref 的 API 所进行的快速排版。不过这个只适合重点排版参考文献的情况，例如博客、海报与幻灯片，至于说用这个排版论文，可能差的还比较远。&lt;/p&gt;
&lt;p&gt;总结一下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;参考文献的排版需要考虑引用格式与文末文献排列格式&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;BibLatex 同时支持 bibtex 与 biber 后端，natbib 只支持 bibtex 后端&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;建议使用 biblatex 而不是 bibtex 来排版 tex 文档&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;csl 可以实现参考文献的轻量级排版，可配合 pandoc 使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rstudio + citr + Zotero + rticles 是个不错一站式 Rmarkdown 论文写作方案&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;超轻量级的文献排版可以直接考虑DOI与超链接&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其实，理解参考文献的排版对于更好使用其他软件也是有帮助的，毕竟你能知道高自由度的编程语言如何针对性解决特定问题。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>编程思维</title>
      <link>https://yufree.cn/cn/2018/09/24/programming-think/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/09/24/programming-think/</guid>
      <description>&lt;p&gt;可编程是计算机科学的核心概念，当一件事可编程时，我们就可以设计出相对的硬件与软件来自动化这个过程。对于科研人员，硬件方面一般较少涉及，软件编程却是日趋日常化。因此，我们有必要了解编程语言的一些基本概念与思想。&lt;/p&gt;
&lt;p&gt;程序是编程的结果，一般包含一条或一组执行运算的指令，这里运算并不仅仅指数学运算，也包括所有可通过电子电路完成的运算。要实现一次运算，我们至少需要输入值、运算与输出值。运算至少要能实现数值运算、顺序执行、条件执行与循环。因此，如果你打算进行编程，你就需要通过计算机语言让计算机知道输入输出与运算过程。&lt;/p&gt;
&lt;p&gt;计算机语言不同于日常交流的自然语言（虽然可以处理自然语言），其核心特质在于描述上的准确性。不论操作符、数据类型还是函数定义，不同的计算机语言都有自己的规范来确保人要求的抽象化与机器能听懂人的要求之间达到平衡。底层语言例如汇编语言机器非常容易懂，但人不容易将需求转化为汇编语言。高级语言需要编译成底层语言来执行，不过人相对容易将需求进行编程。这个编译过程会损失效率，所以一般学习的语言越容易，效率与准确性往往会受影响。&lt;/p&gt;
&lt;p&gt;科研里一般用程序来处理数据，所以科研编程的语言选择往往是实现效率、处理方法与编程难度的平衡。一般来说，数据处理方法源于统计学知识，编程难度取决于学科现实问题的抽象模型而实现效率属于纯计算机科学问题，科研人员可根据自己知识背景进行选择。对于非计算机科学专业的科研人员，建议关注学科内主流编程语言，否则后期会有很多交流上的困难，或者一步到位实现程序的应用化，让用户在少量编程知识的背景下就可以应用。&lt;/p&gt;
&lt;p&gt;学习编程语言一般首先要掌握变量类型、赋值、表达式语法、保留词、注释等基本概念，然后就是大量的交互式案例训练来熟悉用法。编程语言一般会自带 REPL (Read–Eval–Print Loop；读取-执行-打印循环) 程序，在这个程序下会识别该编程语言的语法与操作符，互动地输入输出数据与结果。在编写程序代码时，最基础的要求是搞清楚编程语言的优先级，例如括号&amp;gt;指数&amp;gt;乘除法&amp;gt;加减法，一般执行顺序是从左到右。&lt;/p&gt;
&lt;p&gt;另一种使用编程语言的方式是通过独立程序实现特定功能来完成的，运行程序可以直接得到输出，人机互动是在应用层上的。 REPL 方式其实比较符合数据分析的需求，后一种方式则反映了软件工程，涉及了程序的设计、构架与封装。目前科研应用中侧重交互式数据分析而业界则更看重程序编写与功能实现，前者存在试错且探索为主，后者则更侧重目标。这个区别专业程序员或软件工程师经常体会不到，觉得用 REPL 的科研数据分析是初学者，不能算编程。但其实科研数据分析的核心就是计算与需求的互动，REPL 只是其中一种，将需求从REPL过度成程序也是很重要。&lt;/p&gt;
&lt;p&gt;也就是说，交互式与独立程序之间往往还有一个中间态，可以是脚本，也可以是自定义函数。一段代码一般是以输入为始，以输出为终，中间有函数来处理数据。在固定模式的数据处理中，一个函数的输出往往可以是另一个函数的输入，将输入输出代码按顺序、条件、循环排好就可以产生一个新的组合函数。事实上很多高级语言就在逻辑上抽象出一些常用函数来方便程序员直接调用。&lt;/p&gt;
&lt;p&gt;同时，为了实现具体的功能，函数的输入除了数据外还有一些参数，有些是经验值，有些则可能要来自于功能本身定义。在输出上，有些函数的输出可以返回数值，有的可能就是打印到屏幕上就结束了，根据实际需求来。此外，多数语言的函数内部变量是只在内部可生产或可调用的，内部没有就可能从当前环境里找，最好不要设计这样的程序。函数或脚本对数据分析最大的意义在于减少重复工作与理清分析思路，对于软件工程则属于搭建工程部件，无论如何都是件功在当代利在千秋的事。&lt;/p&gt;
&lt;p&gt;如果程序设计有问题，编程语言也会有对应 debug 的过程，大多数情况下是编程者的需求与机器的执行不对应导致，可以从这里入手思考修改代码。常见的错误包括但不限于语法错误、语义错误与例外。&lt;/p&gt;
&lt;p&gt;下面重点讨论下编程思维中一些常见现象与术语，侧重理解并最好通过联系来强化理解。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;条件分支：函数中出现需要对数据子分类进行不同运算时的设计，不同子分类用不同条件语句进行逻辑判断，例如数值求绝对值要先判断正负。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;循环：同样的操作要对不同的可索引或满足特定条件的数据进行运算，这种情况要设计循环结构，例如按数据行/列求值。有些循环循环数是知道的，有些则要对数据运行结果进行判断，满足特定条件时可跳出或继续循环。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;递归：比较特殊的条件与循环结构，当数据不满足某条件时就执行函数本身直到满足条件，例如求解斐波那契数列之和就可以设计递归结构循环执行本身直到数据可计算的起点。递归的效率一般不高，但递归结构有助于简化思考问题的步骤。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;正则表达式：正则表达式是字符串处理时常用的模式识别工具，灵活使用正则表达式与条件分支可以有效处理真实数据中的混杂，强烈推荐&lt;a href=&#34;https://zh.wikipedia.org/zh-hans/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F&#34;&gt;学习&lt;/a&gt;掌握。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据结构：通常不同数据按照实际需求会有不同的格式，不同格式的数据处理方式会不一样，一般函数都会先验证数据结构，如果不能处理则返回错误。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据表：常见的数据处理格式，一般不同行表示不同样品，不同列表示不同样品属性且数据类型一致，数据值可以是数值、字符或逻辑值但不能是数据表。由于数据处理算法大都基于数据表开发，这类格式数据比较容易找到现成的算法函数/库/扩展包来进行处理。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;字典：很多程序语言支持字典，字典是一种对应关系，字典中的元素是键值-数值对，通过键值索引数值，也可以反查。数据表中搜索元素是按照数值索引顺序索引的，字典则可以用哈希表快速索引。字典可以在编程中用来构建基于输入的数据库，方便进一步查询。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;列表：列表属于数据表与字典的泛化，列表元素可以是数据表或列表，因此列表的数据结构不是平行的而是具备层级，有的元素可以进一步展开。列表常用来表示一组关联概念且可以数值索引，例如在回归分析的返回值中，就会包括拟合值、回归系数、残差等数据表或数值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;类型：通常列表可被定义成一种新通用类型，算法可基于这个类型进行开发或泛化，例如当你调用画图程序时，其程序会首先判断你输入数据的类型，如果有对应方法则直接调用，没有则用通用方法或返回错误。有些语言中列表是不能直接操作的，这样设计就是为了防止类型不兼容而强制定义格式。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他一些概念例如并行运算、云计算、单元测试、集成测试、GPU加速、功能模块化、环境容器化、接口调用、功能移植、数据库检索、前端设计、数据加密、移动端兼容等都很有了解的必要，但这是建立在牢靠的基础上的。一个简单的判断标准就是根据你的需求你会觉得存在某种设计，然后一搜索发现果然有这样的领域，从需求出发回到需求中去是编程思维的要诀，不要在屠龙之术上花费太多时间。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>案例法</title>
      <link>https://yufree.cn/cn/2018/08/19/controversial-issue/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/08/19/controversial-issue/</guid>
      <description>&lt;p&gt;月初加东转了下，火车中重读《推理的迷宫》，一时间竟想这火车不要停，待我读完到站最好。有句话说身体跟灵魂要有一个在路上，但两个都在路上时，顿觉时光飞逝。在这本偏科学哲学的书里，庞德斯通指出悖论对于思辨的重要性且认为这应是科学哲学的研究对象。确实，悖论构筑了逻辑推理在极端条件下的矛盾，理解悖论才会发现逻辑推理自身的局限性。另一本类似的书是《GEB》，不过这本属于大部头，心态不静无法读，我现在应该读不了了，不过好在几年前读过了。其实逻辑这东西网上网下很多人都在提倡，不过同样的道理人人都懂，但真到该用的时候却只有少数人能看出问题的同构性，这里面最大的差距我现在来看只有一个，就是案例。&lt;/p&gt;
&lt;p&gt;大一上高数时，还是讲师的贾广岩老师说过两句我印象很深的话，一句是数学是工具也是思维体操，不要把知识过于工具化而要体会发现的乐趣；另一句则是数学家与学数学的最大区别就在于数学家脑中装有大量反例，反例多到正和反都无法区分。前一句很好理解，后一句现在逐渐理解了。所谓知识体系，是抽掉了水分的干货，学生学习的核心内容，但每一次知识的抽水都是一种简化，都是一种类似性价比与信噪比的抽取，现在人心浮躁，求知欲旺盛，恨不得把所有干货都吃进来。可问题是，这只是学习，知识不仅仅是用来目的性学习的，而应该是一种体验，这就需要注水。&lt;/p&gt;
&lt;p&gt;所谓注水有两种方式，一种是用学到的知识去改变现状，也就是去经历；另一种就是把经历过的事用新学的视角重新解释。也就是说要补充说明知识的经验，这样的好处就是别人讲理用逻辑，你可以用故事。不要认为叙事不讲逻辑，你学任何新知识大都是通过叙事来进行的，单依靠逻辑推演的知识体系是有边界的。更进一步说，当你解释一件事脑中闪过道理后还能有一堆经验事实来佐证，说服力就会更强，如果只出现道理本身，其实能不能说服自己都很难说。&lt;/p&gt;
&lt;p&gt;仔细想想，如果真遇到紧急事项，逻辑多半不开工全靠本能反应，而过往案例则很好的帮助逻辑在紧急状况下依然有效。在经验没形成理论之前，经验本身就是最实际的问题解决方法。现在人都有职业，但日常生活起作用最多的却还是过往的经验事实，哪怕技术进步再多，你也得拿筷子吃面，这没啥道理可讲，不然就别吃。&lt;/p&gt;
&lt;p&gt;前沿科研有时候就很像遇到紧急事项，有些新兴领域没啥成熟理论，有的就是一个个项目与案例，此时强调基础知识固然没错，但新出现案例的补充其实更为重要。一个事实就是在前沿里错的东西的比例要比日常生活所需知识中有问题的比例要高很多，而案例的存在就是前沿可以发展的重要原因，因为当人报导前沿知识时，多数是因为其与现有认识有矛盾，此时固守之前的认识就很可笑了。&lt;/p&gt;
&lt;p&gt;有本书是《改变心理学的40项研究》，我觉得所有从事科研的人都该看一下，不是去学什么心理学，而是去看看那些经典案例。更重要的是，这本书一直在改版，每一版都会把关于初始研究的最新讨论加进去，关注这些才会发现很多报道的结论或理论其实早就成了历史。但一个残酷的现状就是知名研究的离奇程度更高，而对其进行的补充说明则降低了信息的离奇程度，这个现象虽然简单，但问题是人群间信息传播是离奇程度主导的，因此辟谣永远不会比谣言传的快。谣言相对无知人群总有扩散趋势而辟谣则是看过谣言的人看了之后觉得谣言不可信也就不提这茬了，后果就是辟谣天生传不动而谣言总会死灰复燃，毕竟这世界上从来都不缺无知人群。&lt;/p&gt;
&lt;p&gt;收集与追踪案例可以很好的了解自己知识的边界，而及时总结案例则可以很好的扩展知识边界。当你看的反例足够多，原来所谓正确的理论就有问题，自然需要从经验中归纳新知识。赫拉利的简史系列中如果分解一下就会发现其实是之前很多发表过书与报纸观点的大整合，新东西并不多，但关键在于他能总结出来而别人只能看到孤立的知识。我读过一本英文书，后面有几十页是注释，里面详细记录了前面每一章节论述材料的来源，因为作者是个科学记者，这个来源就非常丰富，除了文献还有新闻、实地访问、录音、网上论坛讨论等等。那本书其实不怎么样，但作者把这些素材展示后我就比较佩服了，因为这表示这个作者对于日常生活有很好的案例化系统，当她有个想法时可以直接从这里面调取整合资源。我见过更多的人则是对干货求知若渴但案例是见一个忘一个，到最后知识永远无法更新，而精力却着实耗费不少，属于知识与经验两个系统永远平行，无法互相补充来指导生活。&lt;/p&gt;
&lt;p&gt;这里一个有意思的悖论就是：喜欢收集案例的人往往懒得总结，喜欢归纳演绎的人往往觉得案例啰嗦。同时喜欢案例与归纳演绎的人往往比较内敛，因为他们比讲道理的人更知道道理有反例其实讲不通，同时比讲故事的人更知道这个故事其实并不意外，出于这个状况，这样的人应该属于笑而不语的那种，就算愿意说，可能也说不出具有传播性的话，因为他所讲的东西最后都会合理化或未知化，也就没什么可说的。后果就是现在天天在台面上讲道理教做人摆事实的主，多半都是有目的的忽悠高手，或者就是还不开窍的主，不晓得太阳底下的新鲜事虽多，但并不是你看到的那个。&lt;/p&gt;
&lt;p&gt;话说这两天连续被人搭讪传教，要不是都有急事，我有六成把握把她们的信仰从根上质疑掉，毕竟我不是一个需要信仰来支撑信念的灵长类。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>短链氯化石蜡的定量方法</title>
      <link>https://yufree.cn/cn/2018/08/06/sccp/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/08/06/sccp/</guid>
      <description>


&lt;p&gt;短链氯化石蜡的定量在环境分析化学中属于难度比较高的，在目的性分析里也算是最非传统的了，不过理解了这类物质的定量对于理解环境分析的复杂性很有帮助，鉴于目前教科书里肯定没有，我就总结在这里。&lt;/p&gt;
&lt;div id=&#34;定量分析&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;定量分析&lt;/h2&gt;
&lt;p&gt;分析化学里的定量模型比较简单，你知道待测物的某个指标，在不同含量下测定标准品中这个指标，找出含量与指标的关系模型。然后当测定样品时，将测得的指标带入关系模型就可以得到含量了。用色谱质谱联用来说明就是首先购买待测物的纯品，然后优化色谱质谱条件来获得待测物特定离子响应色谱峰的最佳灵敏度与分离效果，然后配置不同浓度标准溶液进样，根据浓度与峰面积绘制标准曲线。当然说是标准曲线，多数是用线性关系，有了标线就可以测定位置样品中浓度了。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;短链氯化石蜡&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;短链氯化石蜡&lt;/h2&gt;
&lt;p&gt;针对短链氯化石蜡，上面那个传统套路是走不通的，原因有三个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;短链氯化石蜡并不是一种化合物，而是碳原子数10-13个，氯原子数5-10个的短链烷烃。这是一类化合物，分子式就有24种，而结构式就要上万种了&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;标准品不是纯品，化学定量分析要求标准物纯度要非常高，但市售短链氯化石蜡的标准品大都不是单体，甚至同一种分子式都做不到，能买到的都是用氯含量来标定，也就是定量要通过氯含量来换算&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分离困难，因为标准不纯，定量要同时测多种短链氯化石蜡，但不同短链氯化石蜡特征离子几乎一样，且中链氯化石蜡会形成干扰，后果就是质谱提取特征离子时有时包含了两种化合物，这样就存在系统性定量偏高，同样的，色谱分离也做不到基线分离，甚至看不到峰，标准品看到的也只是五指峰&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于上述原因，那些基于特征离子定量且又是低分辨质谱定量的方法几乎可以肯定是不靠谱的，线性关系一塌糊涂不说误差不是一般的高。有意思的是，网上可以搜到很多短链氯化石蜡定量方法专利，基本都是胡说八道，根本就没搞清楚问题的复杂性，要么就是隐藏技术细节，但其实很多文献里都有也不用隐藏，且根本就不该出现这类专利，因为学术期刊早就发表过了。我自己申请过也获得过专利，那帮审专利的人专业水平不是一般的低，很大程度是因为外行评价内行，不过这东西挺唬人的，但其实科技领域越前沿胡说八道就越多，这样才有讨论空间，不必看得太重。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;高分辨质谱定量方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;高分辨质谱定量方法&lt;/h2&gt;
&lt;p&gt;离子源肯定要是负化学源，EI源会把短链烷烃打碎，后果就是根本找不到特征离子，负化学源能保证你起码找得到分子离子峰。不过这么说也不对，因为即使在负化学源下，短链氯化石蜡的基峰也是掉一个氯原子的。而且只要有氯原子就会存在同位素峰，同位素峰之间在低分辨质谱上会互相覆盖，这里我们先不讨论低分辨定量，高分辨质谱是可以在质谱上实现每种分子式的分离的。&lt;/p&gt;
&lt;p&gt;那么色谱用什么呢？首先得是能接质谱的柱子，其次因为短链氯化石蜡沸点不高，我们可以用气相色谱柱来进行分离。当然也有用液相分离的，那个比较复杂就不提了。&lt;/p&gt;
&lt;p&gt;好了，我们来看技术难点，我们手上有的标准只标注了氯含量而不是单体含量，所以首先我们要构建氯含量与单体含量的关系。不同氯含量的标准会有不同质谱响应因子，也就是你进样量相同时，峰面积是不同的。这里文献中一般采用的策略就是假设所有短链氯化石蜡单体响应的不同主要来自于氯含量不同，而氯含量不同是因为组成不同。计算出氯均一化后总体氯化度对应的响应因子与样品峰面积就可以知道含量。&lt;/p&gt;
&lt;p&gt;首先，我们需要固定浓度不同氯化度的sccp标样，然后提取离子计算面积积分，各离子面积要先除以离子同位素丰度得到化合物面积，然后除氯原子个数得到单位氯原子化合物的响应，所有离子响应之和为单位氯原子的总面积，每个离子的氯化度是已知的，用其单位离子响应占总响应的比例乘以氯化度求和可得到样品中的总氯化度，单位氯原子的总面积除以质量得到标准响应因子，这个响应因子在不同氯化度下不一样，用不同氯化度标样分别测定，得到氯化度与响应因子的回归曲线。&lt;/p&gt;
&lt;p&gt;然后，测定样品时只要计算出样品中的总氯化度就可以知道样品响应因子，根据样品中计算出的单位氯原子的响应面积就可以知道其中sccp的总含量。同时也可以反推得到样品中不同单体的浓度组成。不过最好先用标准品作为样品检验下方法是否有系统偏差。&lt;/p&gt;
&lt;p&gt;我在&lt;code&gt;enviGCMS&lt;/code&gt;包里已经做了一个应用，你按照里面说的一步步来是可以实现定量的，不过请一定理解背后的假设，启动应用的代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;#39;enviGCMS&amp;#39;)
enviGCMS::runsccp()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;此时你的浏览器会弹出图形界面，按照指示做就可以了，记得去引 references 选项卡里的文献与这个软件包就可以了，我不是方法的发明人，但软件却是我写的。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;低分辨质谱定量方法&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;低分辨质谱定量方法&lt;/h2&gt;
&lt;p&gt;前面提到，在低分辨质谱上存在同一个离子实际是两种物质的情况，如果两组物质质量数干扰，就选两个共有离子，每个离子响应是来自两个物质响应的线形加和，由于两个离子的丰度比可以事先计算出来，所以可以构建下面的方程：&lt;/p&gt;
&lt;p&gt;物质A、B的两个共有离子峰面积X、Y，两者丰度比例 m、n：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A + B = X\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[A\frac{n}{m}+B\frac{n}{m} = Y\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;联立求解可以得到A与B的真实峰面积。&lt;/p&gt;
&lt;p&gt;如此可以把相互干扰的离子对放到一起去测，然后求解各离子的实际比例。&lt;/p&gt;
&lt;p&gt;这是个穷人的方法，买不起高分辨就要用数据处理来矫正误差，这里我就不写图形界面了，穷要有穷的志气，穷还不愿思考动手，那我也不想帮忙了，线索已经给的很明确了。至于说高分辨为什么写原因也很简单，目前有人要用，而且我知道对方是理解背后原理的，我不希望不理解原理就套用模版套路来进行科研的人（但写作可以用模版方便交流），这样做出的东西意义不大，没有思考的科研也许有用，但丧失了乐趣。&lt;/p&gt;
&lt;p&gt;祝大家短链氯化石蜡定量快乐！&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>现代科研兵刃谱</title>
      <link>https://yufree.cn/cn/2018/07/14/sci-tools/</link>
      <pubDate>Sat, 14 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/07/14/sci-tools/</guid>
      <description>&lt;p&gt;工欲善其事，必先利其器。今天绝大多数知识都是工具生产出来的，也就是想使用知识，肯定要先学工具，而工具又需要知识铺垫，这就成了一个鸡生蛋蛋生鸡的问题。虽然事后总结都有千般道理，但就我人经验而言，工具与知识是相辅相成缺一不可的，过于关注知识会导致脱离实际而沉迷于工具选择则有很高的迁移成本。这里的忠告就是不要想太多，先迈开步子，随便找个工具用起来，用实战来丰富需求，根据需求定向选择最适合自己的工具而不做工具的奴隶，如有必要，自己创造工具。另外，尽量选择那些花费百分之二十的精力可以掌握百分之八十的内容或应用场景的工具。同时系统学习那些使用频率高的工具，其余的只要知道其存在即可，不要捡芝麻丢西瓜。&lt;/p&gt;
&lt;h2 id=&#34;文本编辑&#34;&gt;文本编辑&lt;/h2&gt;
&lt;p&gt;科研用文本编辑工具主要应对排版要求，早期排版系统基本都是通过 TeX 语言来实现的，后来由于个人电脑普及及新兴学科的出现，很多科研人员上手会用的都是可见即可得的文本编辑器。现在期刊投稿一般会支持基于 TeX 的投稿及常见可见即可得文档，这些都是本地编辑。另一个当前流行的可见即可得文本编辑方式是在线协作，例如&lt;a href=&#34;https://docs.google.com/&#34;&gt;谷歌文档&lt;/a&gt;、&lt;a href=&#34;https://shimo.im/&#34;&gt;石墨文档&lt;/a&gt;、&lt;a href=&#34;https://docs.qq.com/&#34;&gt;腾讯文档&lt;/a&gt;等。对于需要协作完成的论文，在线协作文档极大方便了实时交互与版本控制。其实利用基于Git的&lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt;也可以实现在线协作与修订，不过门槛比较高，但有希望成为一些期刊今后的投稿系统原型。&lt;/p&gt;
&lt;p&gt;还有些文本编辑器是基于纯文本的，通过文本中的控制语句来实现排版，TeX就是其中最流行的。&lt;a href=&#34;https://www.overleaf.com/&#34;&gt;Overleaf&lt;/a&gt;支持基于 TeX 的在线文档协作，甚至你可以直接用其向特定期刊投稿，同样的工具还有&lt;a href=&#34;https://www.sharelatex.com/&#34;&gt;sharelatex&lt;/a&gt;。不过，TeX的控制语句实在太丰富，学习起来比较困难。&lt;a href=&#34;https://pandoc.org/&#34;&gt;Pandoc&lt;/a&gt; 的出现方便了其他更简单的标记语言对 Tex 的转换，其中最容易上手的是&lt;a href=&#34;https://daringfireball.net/projects/markdown/&#34;&gt;Markdown&lt;/a&gt;。不过 Markdown 存在很多版本，其中基础版支持的排版功能非常有限，Pandoc 对其进行的&lt;a href=&#34;https://pandoc.org/MANUAL.html#pandocs-markdown&#34;&gt;扩展&lt;/a&gt;则支持了更丰富的功能方便排版。所以理论上你可以使用 Markdown 来写论文，不过这需要你的编辑器支持一些额外的功能。&lt;/p&gt;
&lt;p&gt;总结一下，作为现代科研工具，理想文本编辑器需要至少有以下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持在线协作、评论与修订&lt;/li&gt;
&lt;li&gt;支持版本控制&lt;/li&gt;
&lt;li&gt;支持常见文献管理工具&lt;/li&gt;
&lt;li&gt;支持期刊样式排版&lt;/li&gt;
&lt;li&gt;容易上手&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;文献管理&#34;&gt;文献管理&lt;/h2&gt;
&lt;p&gt;现在的文献管理工具一般都支持常见文本编辑工具，也就是可以很方便的插入参考文献。然而，文献管理工具要同时具有收集、整理与分析的功能为佳。当前主流文献管理工具都已经支持浏览器层次的文献收集，也就是直接通过快捷键、脚本或浏览器扩展一键自动提取文章页面中参考文献信息并存入用户指定的文献库。要实现这个功能，多数需要知道文献数据库网页结构，当前很多文献数据库都推出了自己的文献收集应用，有的直接收购了文献管理软件。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://endnote.com/&#34;&gt;Endnote&lt;/a&gt;是比较老牌的文献管理工具，不同于前面所说的网页采集，其自身就有与常见数据库的搜索接口，国内科研机构图书馆大都提供培训。与之类似的&lt;a href=&#34;http://www.inoteexpress.com/aegean/&#34;&gt;NoteExpress&lt;/a&gt;则属于国产软件，据说对中文期刊格式支持更好，类似的还有&lt;a href=&#34;https://www.mendeley.com/&#34;&gt;Mendeley&lt;/a&gt;、&lt;a href=&#34;http://refer.medlive.cn/&#34;&gt;医学文献王&lt;/a&gt;、服务 TeX 里 BibTex 的 &lt;a href=&#34;http://www.jabref.org/&#34;&gt;JabRef&lt;/a&gt; 与Mac OS 下的&lt;a href=&#34;https://www.readcube.com/papers/mac&#34;&gt;Papers&lt;/a&gt;。这些工具起步较早，从单机时代就有用户，还有些工具诞生于互联网时代，有着更丰富的功能。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zotero.org/&#34;&gt;Zotero&lt;/a&gt; 属于互联网精神的产物，特别是前者本身就是基于火狐浏览器，其支持的文献格式样式都非常多，而且也有着丰富的文本分析扩展应用。&lt;a href=&#34;https://paperpile.com/app&#34;&gt;Paperpile&lt;/a&gt;则属于基于谷歌文档的应用，可以很方便地管理在谷歌文档中使用到的文献。&lt;a href=&#34;https://www.doi.org/&#34;&gt;DOI&lt;/a&gt;与&lt;a href=&#34;https://www.crossref.org/&#34;&gt;crossref&lt;/a&gt;的出现则更方便了文献的搜索定位。可以说基于互联网的团队化文献管理正在成为趋势。&lt;/p&gt;
&lt;p&gt;总结一下，作为现代科研工具，理想文献管理软件需要至少有以下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持常见文本编辑器&lt;/li&gt;
&lt;li&gt;支持在线文献采集&lt;/li&gt;
&lt;li&gt;支持文献库协作与共享&lt;/li&gt;
&lt;li&gt;支持文献信息学探索&lt;/li&gt;
&lt;li&gt;容易上手&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;数据处理与绘图&#34;&gt;数据处理与绘图&lt;/h2&gt;
&lt;p&gt;数据处理方面很多学科只需要电子表格与基本的统计分析就可以了，很多在线服务就可以完成。然而，有些学科需要更丰富的功能例如多元统计分析与假设检验时，电子表格提供的功能可能就不那么明显了，有时需要学习使用电子表格的宏扩展来实现。此时，很多人容易陷入哪个分析一定要用哪个软件做的误区，其实多数数据分析软件的算法都差不多，只不过默认值可能不同，有些功能则藏的比较深，此时请善用搜索引擎。&lt;/p&gt;
&lt;p&gt;所见即所得的数据处理与绘图软件有很多，Excel、&lt;a href=&#34;https://www.originlab.com/&#34;&gt;Origin&lt;/a&gt;、&lt;a href=&#34;https://systatsoftware.com/&#34;&gt;SigmaPlot&lt;/a&gt; 与&lt;a href=&#34;https://www.ibm.com/analytics/spss-statistics-software&#34;&gt;SPSS&lt;/a&gt; 是科研中用的比较多的。这些软件都是图形界面操作且都收费，其内置很多现成的分析模块应对实际科研问题，但这些简化会导致使用者知其然不知其所以然，在分析方法使用上陷入误区。&lt;/p&gt;
&lt;p&gt;编程分析与绘图则属于基础的工具，&lt;a href=&#34;https://www.r-project.org/&#34;&gt;R&lt;/a&gt; 、&lt;a href=&#34;https://www.python.org/&#34;&gt;Python&lt;/a&gt;、&lt;a href=&#34;https://www.mathworks.com/products/matlab.html&#34;&gt;Matlab&lt;/a&gt; 与&lt;a href=&#34;https://www.sas.com/en_us/home.html&#34;&gt;SAS&lt;/a&gt; 都是这类工具的代表，应该说掌握其中任意一个就足够应对科研中需要的数据分析了。不过通常这类工具比较难学，最好是配合数据分析方法的学习同步掌握，而且要通过案例来理解方法，累积经验。如果推荐一个，那么基于 R 的 &lt;a href=&#34;https://ggplot2.tidyverse.org/&#34;&gt;ggplot2&lt;/a&gt; 作图与其背后的 &lt;a href=&#34;https://www.tidyverse.org/&#34;&gt;tidyverse&lt;/a&gt; 数据分析套装则是很好的起点。如果更进一步，可以用&lt;a href=&#34;https://www.rstudio.com/products/shiny/&#34;&gt;shiny&lt;/a&gt; 来制作交互式数据展示界面。&lt;/p&gt;
&lt;p&gt;此外，互联网上也有一些在线应用可以很方便地生成特殊图形例如&lt;a href=&#34;http://naotu.baidu.com/&#34;&gt;百度脑图&lt;/a&gt;可以用来生成流程图或思维导图、&lt;a href=&#34;https://www.autodraw.com/&#34;&gt;Autodraw&lt;/a&gt;可以用来画简笔画、&lt;a href=&#34;https://plot.ly/&#34;&gt;plotly&lt;/a&gt;可以在线完成绘图等。甚至网上还有直接上传数据后自动猜测你需要进行分析与制图的&lt;a href=&#34;https://www.charted.co/&#34;&gt;Charted&lt;/a&gt;。这样的工具只要搜索你所需要的分析然后加上“online”作为关键词就可以找到。&lt;/p&gt;
&lt;p&gt;总结一下，作为现代科研工具，理想数据分析与绘图软件至少有以下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持科研用统计分析&lt;/li&gt;
&lt;li&gt;图片默认输出美观大方支持绘图自定义&lt;/li&gt;
&lt;li&gt;具备可重复性的宏功能或数据处理脚本&lt;/li&gt;
&lt;li&gt;容易上手&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;学术交流&#34;&gt;学术交流&lt;/h2&gt;
&lt;p&gt;学术交流是科研生活中可以说最重要的一环，现代科研体系的分工合作都要通过学术交流来实现。主流趋势包括论文预印本服务器、开放获取与线上学术交流。&lt;/p&gt;
&lt;p&gt;预印本指在通过同行评议发表之前事先将论文手稿托管在公开服务器的研究工作。预印本服务器可以加速新思想的交流，接受预印本发表的期刊可以从维基百科上&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_academic_journals_by_preprint_policy&#34;&gt;查到&lt;/a&gt;。比较知名的预印本服务器包括偏数学物理计算机科学的&lt;a href=&#34;https://arxiv.org/&#34;&gt;arxiv&lt;/a&gt;、偏生命科学的&lt;a href=&#34;https://www.biorxiv.org/&#34;&gt;biorxiv&lt;/a&gt; 与偏化学的&lt;a href=&#34;https://chemrxiv.org/&#34;&gt;chemrxiv&lt;/a&gt;。国内也有中科院的科技论文预发布[&lt;a href=&#34;http://chinaxiv.org/home.htm&#34;&gt;平台&lt;/a&gt;来服务国内科研人员。很多期刊出版方也在推广自己的预印本服务器来吸引高水平研究，所以可酌情选择。&lt;/p&gt;
&lt;p&gt;开放获取是另一个趋势，要求研究工作可以公开让大众阅读。目前很多科研基金都开始有了这方面的要求及预算。但值得注意的是虽然开放获取期刊可能有更好的阅读数与引用表现，但有很多机构的开放获取期刊属于掠夺性期刊，给钱就发表，对学术评价与学科发展非常不利，可以通过一些网络上的&lt;a href=&#34;https://beallslist.weebly.com/&#34;&gt;列表&lt;/a&gt;来鉴别。要实现开放获取或者说透明科研，&lt;a href=&#34;https://f1000research.com/&#34;&gt;f1000research&lt;/a&gt;、&lt;a href=&#34;https://peerj.org/&#34;&gt;PeerJ&lt;/a&gt;还有&lt;a href=&#34;https://www.plos.org/&#34;&gt;Plos&lt;/a&gt;都是还不错的先行者，它们在实践一些新理念，不过显然并不便宜。&lt;/p&gt;
&lt;p&gt;线上学术交流除了期刊外，实际还要包括学术博客、多媒体展示、学术出版与网络身份。制作学术博客的工具可以直接借助平台例如&lt;a href=&#34;http://blog.sciencenet.cn/&#34;&gt;科学网博客&lt;/a&gt;，也可以自己搭建例如使用&lt;a href=&#34;https://zh-cn.wordpress.com/&#34;&gt;Wordpress&lt;/a&gt;、&lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;Blogdown&lt;/a&gt;或者&lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;等工具。幻灯片制作也最好使用网页模式方便交流，&lt;a href=&#34;https://github.com/yihui/xaringan&#34;&gt;xaringan&lt;/a&gt;、&lt;a href=&#34;https://rstudio.github.io/learnr/&#34;&gt;learnr&lt;/a&gt;等其他基于Markdown语言的幻灯片制作工具可以满足要求。学术出版物则可以通过&lt;a href=&#34;https://bookdown.org/&#34;&gt;bookdown&lt;/a&gt;或&lt;a href=&#34;https://github.com/rstudio/rticles&#34;&gt;rticles&lt;/a&gt;等工具来完成。线上的学术身份识别对于存在大量重名现象的中国科研人员也是很有必要的，&lt;a href=&#34;https://orcid.org/&#34;&gt;ORCID&lt;/a&gt;、&lt;a href=&#34;http://www.researcherid.com/&#34;&gt;Researcher ID&lt;/a&gt;、&lt;a href=&#34;https://www.scopus.com/&#34;&gt;Scopus Auther ID&lt;/a&gt;、&lt;a href=&#34;https://scholar.google.com&#34;&gt;谷歌学术个人主页&lt;/a&gt;及国内的&lt;a href=&#34;https://xueshu.baidu.com/&#34;&gt;百度学术个人主页&lt;/a&gt;都是不错的网上学术名片。而在线交流的手段则可通过&lt;a href=&#34;https://www.researchgate.net/&#34;&gt;ResearchGate&lt;/a&gt;、&lt;a href=&#34;https://www.academia.edu/&#34;&gt;Academia&lt;/a&gt;、&lt;a href=&#34;https://www.linkedin.com/&#34;&gt;Linkedin&lt;/a&gt;及&lt;a href=&#34;https://twitter.com/&#34;&gt;twitter&lt;/a&gt;来完成。&lt;/p&gt;
&lt;p&gt;审稿也是很重要的学术交流方式，建议使用 &lt;a href=&#34;https://publons.com/home/&#34;&gt;Publons&lt;/a&gt; 来构建自己的学术审稿记录。当然你可以在博客或微博上评论最新研究，甚至很多网络期刊网站的评论也有很好的思想碰撞，这里最关键的是要搞清楚你所在学科最活跃的网络交流平台，如果没有，自己搭建一个也无妨。&lt;/p&gt;
&lt;h2 id=&#34;数据分享&#34;&gt;数据分享&lt;/h2&gt;
&lt;p&gt;数据分享是一个很重要现代科研特征，越来越多的科研成果正在开放自己的原始数据供社区推动学科进步。其中，&lt;a href=&#34;https://figshare.com/&#34;&gt;figshare&lt;/a&gt;、&lt;a href=&#34;https://osf.io/&#34;&gt;Open Science Framework&lt;/a&gt;、&lt;a href=&#34;https://dataverse.org/&#34;&gt;Dataverse&lt;/a&gt;与&lt;a href=&#34;https://zenodo.org/&#34;&gt;Zenodo&lt;/a&gt;都是这一潮流的引领者。良好的数据分享不仅包含原始数据，还要包括处理后数据、数据收集相关信息与处理代码，另外对于共享数据的使用也要尊重数据生产者。&lt;/p&gt;
&lt;h2 id=&#34;代码管理&#34;&gt;代码管理&lt;/h2&gt;
&lt;p&gt;后续我们会看到所有学科都会不可逆引入编程，所以代码管理工具也非常重要。&lt;a href=&#34;https://github.com/&#34;&gt;Github&lt;/a&gt;与&lt;a href=&#34;https://bitbucket.org/&#34;&gt;Bitbucket&lt;/a&gt;都是非常实用的在线代码管理与版本控制平台。而&lt;a href=&#34;https://rmarkdown.rstudio.com/&#34;&gt;Rmarkdown&lt;/a&gt;与&lt;a href=&#34;https://ipython.org/notebook.html&#34;&gt;Jupyter Notebook&lt;/a&gt;等工具背后提倡的文学化编程也是很重要的代码开发工具。此外应考虑为未来自己做好注释并记录运行环境保证重复性。&lt;a href=&#34;https://docs.docker.com/get-started/&#34;&gt;Docker image&lt;/a&gt;等完整的数据分析环境也可能成为现代科研的主流。代码的编写要能站到巨人肩上：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Good writers borrow from other authors, great authors steal outright&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;r包管理&#34;&gt;R包管理&lt;/h3&gt;
&lt;p&gt;对于R包的管理，建议打印相关Rstudio出品的&lt;a href=&#34;https://www.rstudio.com/resources/cheatsheets/&#34;&gt;小抄&lt;/a&gt;作为参考。同时作为IDE，Rstiduo提供了包开发的模版，可以使用&lt;a href=&#34;https://yihui.name/formatr/&#34;&gt;formatR&lt;/a&gt; 与 &lt;a href=&#34;https://cran.r-project.org/web/packages/Rd2roxygen/index.html&#34;&gt;Rd2roxgen&lt;/a&gt;来重新格式化旧代码。同时使用&lt;a href=&#34;https://cran.r-project.org/web/packages/roxygen2/index.html&#34;&gt;roxygen2&lt;/a&gt;来编写开发文档。为了让包更容易使用，可以用Rmarkdown来写&lt;a href=&#34;http://r-pkgs.had.co.nz/vignettes.html&#34;&gt;小品文&lt;/a&gt;方便读者上手，另外就是使用&lt;a href=&#34;https://github.com/r-lib/testthat&#34;&gt;testthat&lt;/a&gt;来进行代码的单元测试。对于代码的执行效率，可以用&lt;a href=&#34;https://rstudio.github.io/profvis/&#34;&gt;Profvis&lt;/a&gt;进行可视化而集成在线测试则可以通过&lt;a href=&#34;https://travis-ci.org/&#34;&gt;travis-ci&lt;/a&gt;或&lt;a href=&#34;https://www.appveyor.com/&#34;&gt;appveyor&lt;/a&gt;来分别对R包进行Linux与Windows系统下的测试。当然，包完成后可通过 &lt;a href=&#34;https://github.com/r-lib/pkgdown&#34;&gt;pkgdown&lt;/a&gt;来制作网站并通过&lt;a href=&#34;https://rstudio.github.io/learnr/&#34;&gt;learnr&lt;/a&gt; 来制作交互式教程。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>选专业</title>
      <link>https://yufree.cn/cn/2018/06/15/selection-of-major/</link>
      <pubDate>Fri, 15 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/06/15/selection-of-major/</guid>
      <description>&lt;p&gt;2006年夏天，德国世界杯，我刚高考完，跟所有伪球迷一样，装模作样看球赛，然后在应用心理学、法医、医学、机械与环境科学五个专业间搞不清楚选哪个合适。其实我对哪个都不了解，应用心理与法医是因为想当侦探、学医是因为我爷爷是医生、学机械是因为觉得工程师比较酷而环境科学则是有种强烈保护环境的意愿。想来想去觉得好不容易能自己选一把，就来个理想主义吧。我当时如果有现在的知识储备，一定会把脑袋摁倒水里测试下相似相溶原理是不是真的。我这个专业选择倒完全没受到任何家庭干扰，当时还觉得我在同龄人中还是比较有代表性的，选专业跟扔骰子差不多，当然后来我才知道我的那伙重点班同学其实大多数都是家长铺路了，高考前就知道专业是啥了而我高考前想的只有考完了看世界杯争取能真正成为一个球迷。&lt;/p&gt;
&lt;p&gt;这是我那时候考学的特点，从下到大周围的小朋友家里条件差别都不大，邻居父母都是一个单位同事，或者说大也没大到出现数量级区别。虽然很多同学有家里铺路，但问题是那个年代家里的认知水平也差距不大，都是在很有限的见识下拍脑袋。那个时候有互联网，但信息差不像现在这么大，都是比较无知的状态。一个地级市的省重点高中理科重点班的同学父母明显是公务员、教师或医生占多数，大都是最早一批上大学开眼界的人，不过这眼界用我现在的标准卡显然都非常有限，充斥着偏见与自负。贫乏时大家相对平等，而富足后却出现了碾压，这是现代社会公平与效率的永恒辩题，而贫穷与富足是广义上的，包括视野与财富。&lt;/p&gt;
&lt;p&gt;总体上我那代之前的人包括父母观念偏左，所以自私的想法他们从内心就排斥。但21世纪的前十年出现的不仅仅是我这一代人的青春期，更多的是社会迅速右转。很多人会说改革开放在78年就开始了，但从我的观点看，改革开放前二十年产生的贫富差距远没有之后二十年那么大。前二十年只是在打基础，后面二十年不但打好了基础，还出现了低流动性的阶层分化。在这后面的二十年里，房地产逐渐取代制造业成为居民财富的标的物。而90年代初玩官倒的那一部分显然没有21世纪第一个十年里买房的人多，此时眼界所带来的胆量让很多人敢于使用杠杆来买房并迅速致富。同时期崛起的还有人口红利、互联网普及与全球化，见识与财富在过去的二十年对所有年龄段的人都是冲击，其实虽然很多人用XX后来区分不同代际，但我眼中XX后的时代烙印都是二十年前打下的，之后的人能区分代际的只有网龄。也就是说如果一个00后在06年就开始上网，我可以说跟他是一代人；一个90后在16年才接触网络，他的社会见识要落后06年入网人十年。不过这倒不用担心，因为越早进入，越早衰老，后发者永远有优势。&lt;/p&gt;
&lt;p&gt;个人财富的累积一定会造成社会的右转，谁都不愿意别人动自己辛苦积攒的奶酪。但最近的调查数据又显示社会在左转，这背后的动因很简单：贫富差距太大了。这倒也不是一个国家的问题，全球尺度的财富都在超量集中在极少一部分人手里，然后我们就看到了《21世纪的资本论》这本书的出现。同一时期，我们也惊奇的发现宗教又重新开始流行、全球尺度出现了人口平均年龄上移还有就是金融、互联网等行业的指数增长。人类是一种从众生物，从学校各专业分数线上你会发现，如果专业决策事实上是家庭决策，那么有些专业显然出现了从众泡沫，而这些家庭显然都觉得自己的决策水平高出平均水平。理性判断的声音弱于从众判断的声音时，泡沫就会产生，从众是一种线性思维，认为当前好的以后也会好，但现实迟早会打脸。&lt;/p&gt;
&lt;p&gt;现在有人问我选专业的建议，我经常首先问句你自己有没有想法，如果没有听了我说的容易被忽悠，你需要多听几家，不过这话跟废话一样，别人问你决策问题时其实多半就放弃思考了。如果你打算问别人关于自己的决策问题，请找有对立观点的人来咨询，然后列一个正反意见表进行权衡。随大流不是不行，但要对想法进行预判，不要出现事后埋怨，所有选择都存在机会成本，意识到这个会让生活少很多不必要的烦恼。&lt;/p&gt;
&lt;p&gt;下面我就把那些能忽悠人的话放到这里，其实都是套路，信了就输了。&lt;/p&gt;
&lt;h2 id=&#34;职业人士&#34;&gt;职业人士&lt;/h2&gt;
&lt;p&gt;医师、会计师、律师还有教师是很传统的中高收入职业人士，都具备很强的专业性门槛且社会需求是刚性的，选择这些行业的父母一般比较保守求稳。基本上如果家里孩子没有自己的兴趣（这个情况比较普遍），父母给选这几个专业是很常见的。职业人士历史悠久但以后存在被替代的风险，其实你去医院就会发现，所有化验单上都有诊断参考意见，医生一般是进行综合决策的那一个，如果以后出现一个数据库互联的诊断决策系统，那么大概率很多门诊要被取代；外科医生也不会保险，因为现在手术机器人的研发进度很快，手术效果比人要稳，学医没问题，要学会跟技术进步共舞。会计师、律师都存在综合决策场景，所以选这些职业要锻炼综合决策能力，而且要超过自动化算法。可以预见这些行业最后会变成两层，一层是作为社会福利存在的自助算法辅助决策，大部分人通过这个系统可以解决80%的需求，政府可以低价甚至免费提供；另一层则是作为个性需求的专业咨询，社会收入中上的人会考虑配备。如果你选了这些行业，要掂量下自己能不能走到第二层。&lt;/p&gt;
&lt;p&gt;举个例子，发达国家报税软件的免费基础版与收费高级版就分别对应这两层，也许你觉得请个真人会计报更保险，但实际上从我体验来看普通会计比软件多的知识也就是一些免税项，软件开发商只要加几个提示他们就毫无优势（现在是高级版功能），也就是借助语言优势坑一下同胞移民。如果政府愿意，对大多数居民的全自动报税在技术角度上没有任何门槛，不过跟会计共同体的政治斗争可能会持续个几十年。&lt;/p&gt;
&lt;p&gt;教师这个比较特殊，社会地位比较高但收入不一定比前面三个高，而且教育市场属于新需求不断的行业，但如果是义务教育就不好说了。你可以去翻人口结构，如果老师持续供应而学生持续减少，市场会出现类似贫富分化的现象，有钱人会投资私校保障教育资源而其余的则进入公立学校。也就是说，义务教育或k12教育的老师如果没有核心竞争力，长远看面临下岗或转岗。如果是高等教育，你首先得有个博士学位，而且现在的情况是私校义务教育或k12教育的老师都要求博士学位了，这条路我不想多做评价，核心竞争力还是关键。&lt;/p&gt;
&lt;p&gt;但其实最大的教育市场并不要求职业教师，目前的新技术新理念层出不穷，最先进行教授的人往往都没学过教育学。很多新东西目前是以咨询、报告、培训、会员等模式出现在教育市场，这个是有持续前景的，但对教师的专业其实没啥要求。所以如果想让孩子通过教师身份获取经济优势，反倒不应该去选师范专业。师范专业的优势是家长资源，如果驾驭不了就别入坑。&lt;/p&gt;
&lt;h2 id=&#34;理工科非计算机金融&#34;&gt;理工科（非计算机、金融）&lt;/h2&gt;
&lt;p&gt;理工类专业要分开看，理科不太好面向社会就业，工科其实就业一直很好。不过理科是可以系统训练科学思维的，当然这个也看个人悟性，因为普遍高校教师自己都没有这个思维。工科专业就业方向就是工程师，工程师不论哪个专业都比较抢手，但要做好参与职业认证的准备。而且工科是比较容易实现小富即安的，前提是制造业需求不断，制造业需求比服务业需求相对稳定，经济下滑居民首先缩减的一定是服务业需求而不是工业品，毕竟服务业溢价普遍高且多数需求都是伪需求。同样的，新技术也会冲击工科，但因为其实工科本身就创造新技术，所以冲击破坏性不会太大。所以如果孩子本身喜欢工科，那就顺水推舟，因为工科应该是大多数家境普通人通过高等教育后衣食无忧的最理想选择。&lt;/p&gt;
&lt;p&gt;理科的孩子们如果不想沦为科研民工，快三十拿到学位后发现除了学术圈别的都干不了而对学术圈兴趣也不大的话，我建议尽早转工科。另外就是要往宽了学别往窄了学，不要担心半瓶醋，因为理科博士的结局最常见就是纸没发出来，别的啥也不会，会的没人要。那个博士头衔不是对你在某个细微领域发现的奖赏而是综合素质的认可，如果一个职位不限制专业而限制学历，多半这个职位需要跟专业不相关的综合素质，而考察标准就是拿下学位。要想办法把读博吃的苦变成竞争力而不是怨气跟重复劳动，否则怨妇级博士就是现代孔乙己。&lt;/p&gt;
&lt;h2 id=&#34;计算机&#34;&gt;计算机&lt;/h2&gt;
&lt;p&gt;很多人都说闭着眼选计算机肯定没问题，我现在所在的学校计算机科学是比较强的，就业更是好得不得了。但我看过一次他们的毕业设计展就明白了，他们的就业也是综合实力的竞争。所谓计算机科学，编程只是一部分，就业其实考察的是编程与实际需求的对接能力。现实中存在计算机科学专业学生搞不清实际需求然后被公司开除的情况，而这个能力需要不断参与项目实践而不是考试获得，当然考试可能就是项目实践。我看到很多计算机的学生毕设产品直接是可以变成产品满足市场需求的，也就是他们的团队打通了从设计到市场所有环节，这种能力单纯专业课是教不出来的。&lt;/p&gt;
&lt;p&gt;选计算机还有个问题是技术更新，这个行业新概念太多太新，选了这个专业不代表铁饭碗，也不要上来就幻想从技术转管理。技术转管理的基础应该是至少十年的技术优势与管理能力的同步培养，前者很多人是做得到的，后者属于软实力，我不认为所有人都能有意识培养。对自己的评价很重要，不同个性的职业路径是不一样的，幻想随大流过得不错就等着失落吧，技术是可以走很远但公司的层级结构决定了只有少数可以实现，如果想好了走这条路就早做准备。&lt;/p&gt;
&lt;h2 id=&#34;金融&#34;&gt;金融&lt;/h2&gt;
&lt;p&gt;现在另一股风潮就是对金融行业的追捧，个个年薪百万且飞来飞去，生活很光鲜，但我觉得金融行业在未来并不乐观。经济理论认为金融会为实体经济融资来推动经济发展，这是个经验法则，不过就实证的结果看也确实是这样。但如果总是这样，08年就不会出现金融危机。很多人说原因在房地产过分发放了次级贷款，没错，但次级贷款就是个金融创新。类似的创新很多的，例如很多人觉得央行印钞票造成物价飞涨，其实不然，央行没有实际去印钞票，起作用的是债务。债务跟钞票不一样，钞票需要印而债务可以凭空产生，我打你一拳你要1个亿精神损失，如果我认可了就凭空制造1个亿的债务关系，房地产、影视、艺术品收藏、NGO都具备凭空制造债务的能力，周瑜打黄盖，总有韭菜割，也因此是泡沫与洗钱大户行业。&lt;/p&gt;
&lt;p&gt;再举个例子，我存了100块到银行，银行转而把100块贷给公司A，公司A到另一家银行存进去就可以转而贷给公司B。我这100块提供到市场账面上可以同时是两家银行的资产，也就是提供了200块的市场流动性，其实如果央行不要求准备金，100块产生的债务关系可以通过这种链条无穷无尽延续下去。如果准备金率是10%，那么银行吸收存款就只能把其中90%贷款给市场，最终可以向市场提供1000（等比数列求和）块的流动性，那么我要想让市场繁荣，其实不用印太多钞票，降低准备金率就可以释放大量借贷关系出来。但你也看到了，源头就是100块，如果这个链条上的借贷关系有一环断了，一个1000块的链条就都完了。在这里，提供链条债务关系的就是影子银行，他们包装出无数金融产品来转售债务关系并收取佣金或手续费，一个真实交易背后可能有一串金融产品对接，通过金融产品的混搭，理论上抗个体违约风险是降低的。但如果出现集体违约或遇到经济周期下滑就会出现系统性风险，这个时候金融业就会把风险通过打包方式传导到所有行业，链条越长越密集，出现连锁反应就越大。如果配合上杠杆，那么本金100块的小波动就会让整体出现大波动，这个时候金融行业就不是为实体经济融资了，而是灾难信号倍增管。无序发放信贷还不如实打实印钞票或者说直升机撒钱，撒钱到居民账户会促进消费释放需求，但增发信贷就最终几乎全成了金融手续费，无法实质促进社会发展。当然信贷确实是可以促进经济发展的，但分配不能实现普惠，这样的经济发展不可持续。如果你投身到一个不可持续行业，实际上就是在赌运气，90年代下岗潮时工人都懵了，因为当年当工人就是家里能安排的最好职业。&lt;/p&gt;
&lt;p&gt;很不幸，由于金融业集中了太多聪明的脑袋，他们有各种从微小波动中获利的原生冲动，包装出的产品都在绑架实体经济。例如原油与外汇市场的交易量是超过实物几倍甚至几百倍的，这意味着大规模的波动会被金融业放大到其他所有行业或直接毁灭自己的行业。特别还有进行高频交易的，这些人纯粹是在跟市场做零和博弈或对赌，但如果他们通过一些保险或金融产品来对冲风险，那么赚的都是金融业的，赔的可就是所有行业了。因为这伙人普遍聪明，所以金融危机可能对其个人是影响不大的，但我依旧不推荐这个专业，除非你真的特别聪明，喜欢这种火中取栗带来的快感。而且，能进行这种操作的人是少数，多数人可能就是银行职员或大堂经理顶天了，这些人怕是会被人工智能取代一大半，现在你去银行，ATM旁边都有人辅助来分流柜台压力，同时手机银行的流行让柜台更显得不那么重要，也许现在在其位的人还能安然到退休，但因为不需要更多的人入场，以后就业竞争压力肯定不会小。&lt;/p&gt;
&lt;h2 id=&#34;商科&#34;&gt;商科&lt;/h2&gt;
&lt;p&gt;有想法爱交际想混名利场或创业的孩子首选，由于学费普遍贵，所以家境一般的就别掺合了，甚至中上的都很难掺合进去。本质上，学这个其实不是本科阶段的首选，研究生选还差不多，而且别指望从学校学到东西，你更多是从同学身上互通有无，学校就是通过招生跟高学费把这些人遴选出来给个场地，选这个专业的人目的性都非常强，不太有就业问题，更多是创业或继承家业。我接触过商科的人都属于进取心特别强且虚荣心也很强的，学生阶段的比较势利，创业后则都有毫无根据的自信心。选这个行业是要走企业家道路的，这条路对99%的人而言是死路，如果你期许一本波澜壮阔的自传倒是可以考虑，思维模式要经受很大冲击。&lt;/p&gt;
&lt;h2 id=&#34;文科&#34;&gt;文科&lt;/h2&gt;
&lt;p&gt;额，如果兴趣爱好是文科其实没必要把文科当专业的，文科生就业基本就是公务员或转行。文科属于素质教育，但只有素质教育没有专长挺危险的，而且你去学别的专业不代表就没法同时进行素质教育了。而且，社会上对文史哲的要求都是畅销书水准的，也就是说专不专业不重要，你的相关知识可以具现化让别人听懂很重要。当然从政的话文科专业在宣传、秘书、机关行政等部门是不可或缺的，但专业性门槛并不那么高。至于文科中音体美等专业，都是金字塔的职业发展，还是那句话，当成爱好有主业那是锦上添花，当成主业还没爱好那就是现代悲剧了。&lt;/p&gt;
&lt;p&gt;其实我上面这些胡扯相信你肯定都多少听过，而且其实每一条都有反对的观点，我在写上面那部分时刻意隐藏了很多。我的真正观点其实跟我当时选专业时比较接近，选什么都是错的，都可能是趋势泡沫，都会过时，后期自我调整就是了，一劳永逸那种想法在现代社会走不通。很多专业都不断面临新技术冲击，拥抱而不是拒绝改变就可以了，只有面对改变的社会不断改变自己或将改变纳入原有行业，机会才是对你是平等的，好好干就会过得不错。但如果总想铁饭碗，倒是可以考虑下高校，拿到终身教职就可以了，不过道路会比较艰辛。&lt;/p&gt;
&lt;p&gt;如果你还想主动一点，现在就出门到附近最大的商场或超市门口去观察，看看出入的人究竟在讨论什么或买了什么，按照流量排序，一般来说，排名靠前的主题相关需求的专业基本不会失业。或者去股市上看看不同行业板块的行业报告，基本上行情开始起步阶段的行业所需专业在你毕业时刚好会有窗口期。不过你要是自己想到这一点了，那根本就不用看我写的废话，你对未来应该早就了然于心了。&lt;/p&gt;
&lt;p&gt;所有行业都是一个名为“人民（包括你）日益增长的物质与文化需求”的行业，围绕这个主题修炼就可以了。当然，如果你够强，没有需求也可以创造需求出来。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>两种结论错误与研商</title>
      <link>https://yufree.cn/cn/2018/05/17/type-sm/</link>
      <pubDate>Thu, 17 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/05/17/type-sm/</guid>
      <description>&lt;p&gt;读论文结论时其实我们都在跟着作者的事实推理逻辑进行决策，而决策就有对有错，这与事实或规律本身无关，只代表当下的认知水平。正是因为承认这一点，科研才不会纠结于错误，或者说科研就是在错误中前行的。同样的数据是有可能得到完全不同结论的，这是个时间的函数，逼近而不是揭示真相。所以，在这个有决策的过程中错误是可以用概率来描述的，p值的流行很大程度上是因为它给了一个通用版的决策方法与阈值，随之而来的就是两种错误，一种是假阳性，一种是假阴性。&lt;/p&gt;
&lt;p&gt;所谓真假，必有对照，多数假设检验的空假设就是个对照基础，这个基础一般是一个分布或就是随机条件。多数对这种判断诟病的根源也在这里，因为真实实验或观察中基线往往不服从分布或随机，为此统计学家提供了大量手段来平衡掉不随机的部分让随机成为基线，在此基础上进行的差异比对就是一个令人信服的相对正确结论。在结论的修饰语中，相对正确是理想化的，令人信服才是被发表出来的原因，多数人没搞懂这一点去解读文献其实是一种科黑。&lt;/p&gt;
&lt;p&gt;显然，平衡掉不随机的部分需要你事先知道这部分是什么，很遗憾，目前科研特别是基于观察的研究并不能事先知道，有时候就是想发现这些不知道自己不知道的东西。这种情况下基于p值或空假设的假设检验其实是不应该用的，打个比方，你发现观测数据中A基因与甲疾病相关，但究竟是不是A基因引发甲疾病还是需要用控制变量来验证的，很有可能A基因与甲疾病同样被B基因调控，但你根本就没测B基因，所以研究本身就是不完整的。那么通过组学技术知道的不知道的我一起去测不就完整了吗？也不是，当你测量数量增加时，假设检验的个数也增加了，此时你的p值阈值如果是0.05，那么10000个测量变量中会有500个即使随机测定都会出现差异的基因。去年有人建议把p值阈值设到0.005，但这根本不解决问题，只是把需要核实的数量减少了，虽然这也有一定意义。举个例子，10000个基因中有一个是真实的，你测定后按照0.05发现了501个，按照0.005发现了51个，也就是说需要验证的数量减少了。但真实研究中，你会遇到0.05发现了501个但0.005只发现了50个的情况，真实差异由于效应量或造成的差异量不够大而被你的决策方法给漏掉了。甚至也会出现0.05发现了480个而0.005只发现了48个的情况。也就是说，当你观察的问题效应不大时，p值有可能不管怎么调整都无法发现。这个锅不在p值，在于你要研究的效应效应太低而你用了不恰当的研究方法与假设来检验这个现象。这类效应大小问题就是 type M 型错误，只要你假设检验很多，这个问题就很难规避。&lt;/p&gt;
&lt;p&gt;读博期间跟室友卧谈时我曾说过，现在只能相信强结论，也就是说无论你用哪种统计方法去进行检验，这个现象都是客观存在的，不会因为决策方法的变化而出现结论差异。不过这个提法现在看还是太理想了，因为强结论真的很强或显而易见，属于科研里低垂的果实，前人都摘的差不多了。如果一个现象足够强，p值一定会发现，贝叶斯方法也一定会发现，此时不存在效应大小问题。但更多的事实或规律是埋藏在当前认为的随机或噪音之中的，我们的分析水平也就刚刚好能把疑似信号与噪音进行区分，而这个区分是否靠谱则完全成了迷，统计学在这里帮不上忙，技术进步倒成了关键。我看到一些研究寄希望于数据挖掘技术解决学科内现象发现问题，这里我只能说对于显而易见但被忽视的现象是有帮助的，但对于高噪音数据，降低测量噪音对结论的帮助要远大于遴选能发现差异统计方法的努力。数据迷信会让你看到伪规律，而测量技术进步才会真的发现价值规律。我曾经也想把生活完全量化，但后来发现测量与传感方面的误差会让量化数据变成垃圾，大数据很美但也可能很虚。&lt;/p&gt;
&lt;p&gt;另一个则是方向问题，p值经常是双边概率取中间那一部分，所以当你看到一个很小的p值时，你并不知道这个效应的方向是更大还是更小，此时你还是需要去看效应值。在这个情况下，如果报导p值不报道效应，那么就好比我告诉你明天要变天但又不告诉你变成什么一样毫无意义。在多数实验设计中，变化几乎是一定存在的，例如我敲掉了某个基因去验证功能，基因的变化与功能肯定有区别，大都来源于观察实验，更有意义的是影响大小，这个大小更多需要专业判断而不是简单的p值。如果理科学生学了半天最后就知道用p值来判断结论，那么这个学位不给也罢。这类搞不清楚效应方向的问题是 type S 型错误，验证性实验特别需要注意。&lt;/p&gt;
&lt;p&gt;今天特意讲这个是因为我去年年底看了一篇论文，上面测量了很多种污染物的浓度，然后就对着很多健康指标进行了相关分析。这是一种多对多的结果遴选，在组学研究中也很常见，需要承认的是这是很多环境健康研究的惯用套路，然后只报道那些差异显著的结果。我将这篇论文转给了哥伦比亚大学的 Gelman 教授，询问他从数据分析角度有没有什么建议，他告诉我会在半年后在博客上公开回复这个问题（他档期真的很满）。然后这个月我看到了&lt;a href=&#34;http://andrewgelman.com/2018/05/15/reduce-type-m-errors-exploratory-research/&#34;&gt;回复&lt;/a&gt;，总结下就是 Gelman 教授认为1）显著性检验是不靠谱的，2）通过多层模型来减小M型错误影响（这是一种我认为很符合中庸之道的模型）并且3）尽可能多的平衡掉已知效应。更重要的是， Gelman 教授指出这属于探索性分析而非验证性分析，对于结论不应该太过信赖。这个回复是很中肯的，但一线研究人员能否理解并应用就不好说了。如果把对当今科研中的问题理解程度量化为“研商”，我想国内对于研商的培养是缺失非常严重的，从学生到老师职业功利性都远大于
对研究本身的理解，或者说我们缺少一个氛围。如果你去看 Gelman 教授的回复，你会发现博客下面的评论中引发了更多对科研成果报导、开放获取期刊等问题的讨论。而国内的科研博客评论里普遍理性讨论少，简单评价多，这个氛围的形成需要包括你我在内的一代甚至几代人的努力。&lt;/p&gt;
&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;除了假阳性与假阴性错误，科研结论中还存在效应大小错误与方向的掩盖&lt;/li&gt;
&lt;li&gt;p值对于后面两种错误的解决帮助不大，贝叶斯分层模型有助于问题部分解决&lt;/li&gt;
&lt;li&gt;强结论很美好，但同时依赖数据分析与测量技术，后者容易被忽略但更为关键&lt;/li&gt;
&lt;li&gt;研商是区别科学家与科研从业人员的重要指标，国内对此培养欠缺&lt;/li&gt;
&lt;li&gt;在线公开讨论问题对于问题的理解与解决是有帮助的，这是互联网时代的研究红利&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>狐狸还是刺猬</title>
      <link>https://yufree.cn/cn/2018/05/07/fox-or-hedgehog/</link>
      <pubDate>Mon, 07 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/05/07/fox-or-hedgehog/</guid>
      <description>&lt;p&gt;科学有个老梗就是这个词是来自日本，本意有分科的学问之意。其实这个解释倒也贴切，科学很多时候就是在对同质性与异质性进行研究，很多原理被经验事实证明适用范围有限，而不同适用范围出现了不同子学科。同样的道理，当你去思考外国人时他们都是金发碧眼或皮肤黝黑的，等你经历多了后就会发现金发碧眼跟金发碧眼是不一样的，而皮肤黝黑也可能是故意晒的小麦色。把一个群体或概念从内部区分是认识世界的起点，否则刻板印象会跟你一辈子。&lt;/p&gt;
&lt;p&gt;人与人的区别很大，但也能按来源大致进一步分成六类：氏族的(Clan)、惯例的(Institution)、个人的(Personal)、历史的(History)、本质的(Essential)与随机的(Random)，组合在一起就是谜（cipher）。氏族的主要指家庭培养与团体文化，这是最近几年由阶层固化引发的焦点，很多人焦虑地认为如果孩子起跑线落后了一辈子就玩了，因此把家庭社会经济地位纳入考量也是现代研究不同于古代研究的地方，古代研究我们能看到的往往只是少部分人的生活，而团体文化则是非血缘的氏族。惯例的主要指文化传统，是民族或国家尺度的，例如印度人吃饭上手不代表不卫生，这里面有民族意识的影响。个人的则属于个人特性与原则，例如准时或完美主义，虽然能找到同样爱好的人，但这部分特性往往是自己独立发展出来的。历史的则侧重时代形象，共同经历过某个阶段的人会有共同的时代形象。个人的与历史的都是时间函数，当然你也可以说惯例的氏族的也是时间函数，但它们会更稳定些，本质的则指遗传的作用，这在基因组研究人员那边被吹上了天，但显然只是解释区别的一个角度。最后一个随机的则是完全不可控或不可知的部分，也许整体可以用分布描述，但具体到个人完全无法预测。很多人容易特别重视这六部分中的某一个而简单认为其他部分不起作用或都一样，但具体到每种认知差异其实都有下面的解谜（decipher）公式成立：&lt;/p&gt;
&lt;p&gt;$$d = f_1( c ) + f_2(i) + f_3(p) + f_4(h) + f_5(e) + f_6( r )$$&lt;/p&gt;
&lt;p&gt;举个例子，某人得某种疾病可能来源于民族文化的饮食习惯、家庭文化影响的卫生习惯、个人的完美主义原则、整个时代缺乏某项技术、基因不好或仅仅就是运气不好。当然也可能是多个原因交互引发的，用这个解谜原则可以简单判断很多论断是否合理，如果缺少任一方面可能都有问题。例如经常有人说某种现象怪社会或怪个人或怪时代或怪团体或怪基因或怪运气，其实更大的可能是都有影响，单一原因决定的论断需要控制实验来解决，而实验设计的原则更多是平衡掉或随机掉不关心的因素而只留下关心的因素进行考察。同理，听取别人意见时也要注意对方六个方面是否都考虑了，如果没有，那么就当作参考吧。自然科学往往只关心本质部分而社会科学则往往基于公平公正原则不讨论本质差异，两类研究往往都很难脱离时代局限性。&lt;/p&gt;
&lt;p&gt;读书也可以用这个系统去分类：关于人类整体文化的，关于团体文化的，个人传记，历史事件记录，自然科学知识与杂文。读书要读事实类但不要忘记每个事实记录者都有自己的观点隐含其中，而预备预测性的观点可以形成理论，很多观点没有事实支撑时可以用虚构的事件来体现。市面流行的成功学往往是包装过的团体文化与个人传记，很多观点无法验证成为理论只能看官自行分别。我个人读书喜欢看关于人类整体文化的与历史事件记录，团体文化与个人传记除非被自然科学手段验证过否则不看。&lt;/p&gt;
&lt;p&gt;教育可以在除随机与个人经历外的因素上起作用。打个比方很多人关心子女教育其实父母对其影响不见得比学校及时代影响大，时代是固定的，学校被社会文化与团体文化所左右，家庭能做到有多少是不好说的。这里面的矛盾是个体与团体、团体与整体三个层级的，家庭是在团体层次上的，如果要影响孩子本质上是竞争其他团体对孩子的影响或干脆融入其他团体例如宗教。但如果孩子个性足够强，这两方面可能都没啥作用，因材施教是很重要的，如果不能做到就随大溜，虽然绝大多数人最后都走这条路，但没必要一上来就跟团体与社会妥协成为其一部分。&lt;/p&gt;
&lt;p&gt;这个解谜系统看起来不错吧，但其实这只是诸多逻辑自洽系统中的一个，认知模型可以有很多种，每种都有自己可解释的事实。逻辑自洽不代表唯一，更不代表科学，因为可能怎么都解释的通且无法证伪。你可以今天构建一个解谜系统，明天就可以构建另一个压缩系统。但认知系统还是要有的，否则别人一通忽悠就把你拐跑了，导致学了很多道理但连不成体系。不过有本书叫做《狐狸与刺猬》，里面提到两种人，狐狸知道很多事，刺猬只知道一个绝招，我上面提到的解谜系统有可能帮助刺猬找到绝招并减轻认知负担，但对于狐狸来说只是多了一个角度认识外界，世界依旧纷繁复杂。这两种人都可以很成功也可以很失败，收获的生活体验也会不同。&lt;/p&gt;
&lt;p&gt;好了，现在选择权交给你了，狐狸还是刺猬？&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>实验室大扫除</title>
      <link>https://yufree.cn/cn/2018/05/03/clean-lab/</link>
      <pubDate>Thu, 03 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/05/03/clean-lab/</guid>
      <description>&lt;p&gt;任何一个运行超过二十年的实验室都是迷宫，这类实验室如果打算搬家或清理将是一个可怕的工程，我的运气一向不错，这种工程赶上了两个。读博士期间实验室搬家，清理出的东西可以追溯到建国前中央研究所（中国科学院前身之一）化学所时代的药品且因为没有保质期还不能清理，找了个柜子继续封印。同时被封印的还有一批俄文与日文标注的药品，也不知道是哪个时代留存下来的，只能通过分子式来定性。当年对这些药品的登记造册持续了一个月，但一年后想通过药品记录找又不太灵了，原因很简单，并不是每个人都能做到用完了放回原位且更重要的是，为了保证实验结果不出问题，多数人会选择购买新药品而不是去翻上千条记录的电子表格。旧的用不完新的又放进去，实验室二十年流动人口一两百，很快就又出现药品柜不够用的情况了。&lt;/p&gt;
&lt;p&gt;这种事课题组长根本无法控制，因为保证实验结果不出问题也是课题组的底线，就算跟学生说可以考虑用之前的药品进行预实验但到了发表时也必然要用新药品试一遍排除干扰。课题组成员的新老交替虽然会有流程进行转接，但一句话传三遍都会变味，更不用说很多时候的转接就是很简单的一句：那个抽屉跟柜子归你了。几代之后就会发现，一整个柜子里其实只有很小一块可以放东西，其余的地方都是前辈留下的“财宝”。那次搬家我是见识到了很多传说中的仪器，有一些被放到了会议室的小展台里，例如打字机、初代气相色谱等。不过更多的则是退库了，例如长得像炼丹炉的烘箱，便携式pH计等。不过我没想到这种冤无头债无主的事出国后又赶上了。&lt;/p&gt;
&lt;p&gt;上周接到通知说是这周要拿出两天来清理实验室，而这个实验室运行了接近三十年。不得不说教授是真的喜欢保存资料，他两周要找所有人面谈一次，每次都要交打印版报告，这类资料是可以追溯到上世纪90年代的，这次清理了上世纪的。打印出的东西一两年也就是纸发黄，二十多年则是完全不能辨识了，且更重要的是没有人会去查阅，而之所以没有进一步清理是因为这个世纪的研究报告都堆在教授办公室的四五个立柜之中而他现在不在。&lt;/p&gt;
&lt;p&gt;另外就是四五个文件柜的磁盘跟磁带，不要误会，磁带不是放音乐的而是存数据的，而且只有几兆，而磁盘则是我小学用过的貌似自带 Dos 系统的5.25寸与中学用来拷拳皇的3.5寸软盘（当时压缩软件有个很重要的功能就是把压缩包切割成1.44MB的小包装存入软盘）。虽然我们也找到了能读这些古董的软驱，但最后还是一股脑扔了。你不大可能指望现在90年代出生的研究生去操作 Dos 系统或学习 fortran  语言来读取数据，我这把年纪也只是赶了个末班车学了个皮毛且实战经验几乎为零，而且但凡学过的上古时代软件操作的一旦接触图形界面就会光速忘记那些命令，再接触过触屏界面后估计更回不去了，过几年出生的孩子打小就是语音控制，估计他们根本就无法体会打孔机时代的计算机其实也是重大发明。换句话，我们现在生活的轻松实际上都不是显而易见的，都是一步步过来的，无数前辈费劲周章才把计算机变成生活的一部分而不是需要专业人士指导的工具。不过这对应的问题就是那些上古时代的软件与数据怕是过上几十年就再也不会有人能读懂了，只能封存或扔掉，不知道以后会不会有人把这段科研实验数据记录的历史梳理出来，因为我一直相信历史中藏着比逻辑推理更有意思的经验事实。&lt;/p&gt;
&lt;p&gt;另外一个清理大头就是各种自行设计的玻璃仪器与机械组件。实话说这是我认为国内外实验学科研究生最大的区别，国内很少有研究生具备这个层次的动手动脑能力而国外虽然也不是说就有，但学校的相关部门会提供辅助，只要研究生设计的出来，机械工厂就能加工出来。倒也不是说国内研究生设计不出来，而是这部分能力基本是脱离课程的，假设你的教材里压根就没有直接质谱技术，那么你怎么让学生去想象改进这个技术？国外的教材则更新更快，很多是在学校书店里按课程编号卖的讲义，所以就算你可以买下版权做影印本，最新的东西也不会那么轻松看到，更不用说讨论班里对最新文献的研究了。不过实话说，真正能吃透最新教材里内容的学生比例在国内外应该是差不多的，大多数还是看不懂，但只要有剩下的就是非常有竞争力的，但完全不讲就根本连门票都没有（这也是我一定要在公众号环境黑板报里加入文献速递这个板块的原因，忽视学科整体发展就永远落后）。在这次扫除中我看到了不少之前人做的设备原型机，很有想法，不知道什么原因就断线了，传承问题对于流动性比较大或历史比较长的课题组是很难规避的。&lt;/p&gt;
&lt;p&gt;实验室传承是个大问题，这两天的清理发现大量过期药品与未知物，保守估计请专业清理人员要几千刀才能合法处理掉，而这些又的确不好规避。前面说了，后来者是不太可能用前人开封过的耗材的，毕竟研究结果的重复性对于实验性学科特别重要。而几乎每个人都在实验室有自己独立的抽屉与柜子，个人习惯差异很大，几乎不可能统一要求。这就像自己家的厨房与冰箱，哪天心血来潮可以收拾整齐，但因为天天要用，很快就会熵值升高的。小实验室还好，人数超过20，这种混乱是不可避免的，如果延续二十年，几乎一定会造成实验室拥堵与集中清理。这很像进化过程中的一些遗留问题例如阑尾，虽然完成了历史使命但也埋下了历史隐患，进化并不是一直择优，很多时候就是两害相权取其轻，重的那个被自然选择消灭的更快而已。&lt;/p&gt;
&lt;p&gt;定期退库是很必要的，不让问题累积。仪器更新换代要在老仪器还可以正常运行时进行，不要等到最后一刻，因为最后一刻的更新意味着老仪器只能吃灰占地方。而定期更新则保证了有仪器可以作为备份且一直用最新技术。其实现在系里打印机就是租赁合同，两年一更新，不用担心退库问题。其实我建议对租赁维护成本与购买更新成本进行长期核算，如果相差不大，那么租赁其实对商家跟客户的好处更多。现在苹果手机就有类似更新计划，这样其实是核算平摊了很多风险，更适应模块化快节奏的现代生活，租赁或订阅可能会成为未来主流商业模式。&lt;/p&gt;
&lt;p&gt;传承多媒体化，让技术比特化。虽然我现在的教授还是喜欢打印的报告并存档，但其实没有人会去真正查阅这些报告。一个良好的传承用文字是不够的，需要多媒体甚至虚拟现实，进行实验时对步骤与设备用途进行全程数字化记录，一方面可以方便查原因，也方便别人延续工作。我特别不理解为什么很多实验流程网上都有实验视频的情况下还有很多人一定要找人带，技术比特化后可以存到课题组或学校机房里，这样内部传承即使隔代也能继续。&lt;/p&gt;
&lt;p&gt;物联网配合区块链对实验室进出物品进行标记与定位，自动化清理。我相信设计一个小传感芯片来进行10米的被动定位并不困难，而实验室基本就是这个尺度，蓝牙通讯就够了。实验室每进入一个物品，特别是药品都贴上一个小芯片，关联药品信息，如果过期就推送提醒进行清理并可以通过手机应用定位到具体药品架。而厂商可通过区块链来重点追踪药品流向，因为每个商品都可追踪，如果出现问题可以很快配合传感芯片来管控药品。不过历史遗留问题就没办法了，但亡羊补牢也不晚。&lt;/p&gt;
&lt;p&gt;有意思的是我发现上世纪明信片似乎是很重要的学术交流方式，上面会贴上个打印的纸条，指明想看你发表的哪篇文章，然后希望你邮寄、传真或email一个副本过去，那可是化学文摘的时代，这三种途径竟然可以神奇共存。&lt;/p&gt;
&lt;p&gt;最后，今天是某人生日，生日快乐！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研的创业隐喻</title>
      <link>https://yufree.cn/cn/2018/02/22/sci-startup/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/02/22/sci-startup/</guid>
      <description>&lt;p&gt;其实科研，特别是理工科科研，很像是创业过程。互动的理解这个过程有助于青年科研人员知道自己究竟在干什么。&lt;/p&gt;
&lt;h2 id=&#34;产品为科研成果的创业隐喻&#34;&gt;产品为科研成果的创业隐喻&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;投资人：政府或企业&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公司：项目或课题&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;董事长：课题组长（PI）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;经理：小老板或子课题负责人&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;项目经理：博士生／硕士生／本科生&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;员工：无&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;质检员：张全蛋，额，打错了，是审稿人&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品上市：论文发表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品发布平台：学术期刊&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品未通过内部质检：论文拒稿&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品有销量：论文被引用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品成为爆款：论文被大量引用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品被媒体推荐：论文被编辑或综述点评&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品滞销：论文无引用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品原料配料表：论文数据共享&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品生产流程：数据处理&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品被模仿：论文被重复验证&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品补丁：论文修正&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品更新换代：论文跟进发表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品推介会：学术会议&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;产品退市：论文撤稿&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;公司融资：申请基金&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;新三板／创业板：申请青基&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A股：申请面上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;路演：项目申请书&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;估值：学术影响力&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;产品为科学家的创业隐喻&#34;&gt;产品为科学家的创业隐喻&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;产品基础认证：博士学位&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;天使轮投资人：博士导师&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;风投：博后合作导师&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;投行：给教职的学校，一般是招人的系主任&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;上市：常任轨存活&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;财报：论文/学术报告&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;退市：撤稿或学术不端&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;被收购：成为小老板或子课题负责人&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;招募合伙人：跨学科合作申项目&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;股票指数：h指数、引用量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;涨停：被邀请会议报告、书章节、新闻采访、审稿&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;跌停：技术或理论过时&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;综合指数：科学家整体影响力&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;板块：学科共同体&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;蓝海产业板块：新兴学科&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;红海产业板块：传统学科&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;其实类比法是一个非常好用的思维工具，可以把不熟悉的东西转化为熟悉的场景来理解，有时候换个角度，可以发现新思路。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DOI 年代的参考文献</title>
      <link>https://yufree.cn/cn/2018/01/11/doi/</link>
      <pubDate>Thu, 11 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/01/11/doi/</guid>
      <description>


&lt;p&gt;现在的研究人员其实大部分时间都浪费在了研究完全不沾边的事，例如论文排版，而论文排版中的大部分时间其实是花费在了按照期刊要求改格式。我个人有个判断审稿人水平的小诀窍，如果他一直纠结格式不对，那么要么是水平太低看不出论文的缺陷，要么就是故意放水。实际上，现在大多数期刊都有专门的编辑最后去帮助排版校稿，完全没必要在这上面浪费时间，市面上任意一款文献管理工具都能生成那个长长的文献清单。&lt;/p&gt;
&lt;p&gt;等等，文献清单？为什么我们还要文献清单？一个直观的答案是要用文献清单去追溯原始文献。嗯，让我回想一下我是怎么追溯的：复制到搜索框，点击搜索… 且不说这样准确率有时候低，更重要的是我其实根本不关心清单里的内容，既然不关心，为什么不直接把文章中引用参考文献的地方设定一个超链接到其网络全文或文摘数据库？反正如果要查还要搜，直接溯源不就完了。要知道，每一次谷歌搜索会产生约 1kJ 的能量&lt;a href=&#34;https://googleblog.blogspot.ca/2009/01/powering-google-search.html&#34;&gt;消耗&lt;/a&gt;，而如果用出版商的搜索引擎，能耗只会更高，我估计全世界科研人员每年浪费在搜索文献清单上的资源是足够让二氧化碳减排任务减轻一些的。&lt;/p&gt;
&lt;p&gt;实现这个功能需要 DOI ，也就是&lt;a href=&#34;https://zh.wikipedia.org/zh-hans/DOI&#34;&gt;数字对象识别符&lt;/a&gt;，DOI码由前缀和后缀两部分组成，之间用 “/” 分开，并且前缀以 “.” 再分为两部分。前缀当中的 “10” 为DOI目前唯一的特定代码（显然这个格式可以被正则表达式匹配）。其实很多论文校稿也是用 DOI 来确认引用文献是否正确，然后放入数据库，便于引文分析。有了 DOI ，其实我们并不需要文献清单，只要在论文写作时引用 DOI 就可以了，后期只要把 DOI 转为超链接就OK了。&lt;/p&gt;
&lt;p&gt;不过这么做期刊可能不太高兴，因为很多期刊最大的特色就是你要投他的稿，就要接受他的霸王条款：引用格式。如果都用 DOI ，虽然其校稿负担会大大减轻，但论文手稿的迁移度会大大提高，期刊留不住投稿的人，那又臭又长的作者指南谁还当回事，尊严何在？&lt;/p&gt;
&lt;p&gt;其实期刊本来就不应该有什么尊严。从历史渊源上，期刊只算是学术交流的一个时代产物，最早的学术交流是见面或书信，因为点对点，所以很多信息沟通不畅，这样学术共同体例如学会就会定期发行面向同行的手册，这也就是期刊的起源。从源头上说，期刊的终极目的就是方便学术交流，任何与之无关的门槛或障碍都理应清除，目前的期刊运作都太中心化了，各自制定各自的标准，不利于学术交流。&lt;/p&gt;
&lt;p&gt;《脚注趣史》里曾提到最开始别人在进行引用时都是要附带批注来表明自己不是胡说八道的，有理有据，是对逻辑推理的有效补充。发展到现在其实学术论文整篇大都是对前人研究与观点的批注，然后写上自己研究实验的结果与讨论，知识也是这样一点一点累计出来的。从这个视角看，文献清单曾经在历史上帮助学术人员整理学科知识，但或许不久的将来就会退出历史舞台。新的形式是什么样的眼下没出来谁都不知道，但拭目以待吧，肯定是一种让研究人员交流更高效的模式。&lt;/p&gt;
&lt;p&gt;预印本服务器的出现其实很好的解决了交流问题，但当预印本上的论文想要发表，除了同行评议外还得遭受格式修改的难题，关于同行评议的吐槽以后再说，单看格式问题还是少不了文献清单的老路子。我理解很多期刊除了网络版还有印刷版发行，但目前科研人员绝大多数都是看网络版，特别是有超链接的 PDF 版，我本人就参与过美国化学会 iPDF 的测试工作，后来听说这个功能推出后非常受欢迎，只是国内因为众所周知的原因速度总是很慢，后来美国化学会干脆在国内架设了镜像服务器。&lt;/p&gt;
&lt;p&gt;但说归说，如果我现在写论文在引用的地方只写 DOI ，那么最痛苦的事可能就是无法跟实际投稿过程整合，只能各玩各的。想来想去，这个功能其实非常容易实现，跟大象装冰箱一样有三步：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读取文本为字符串&lt;/li&gt;
&lt;li&gt;正则表达式提取出 DOI 并去重&lt;/li&gt;
&lt;li&gt;用 crossref 的 API 把 DOI 按预想格式输出并打印&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;既然都写出步骤了，就用 R 来实现吧：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(&amp;#39;stringr&amp;#39;)
library(&amp;#39;readr&amp;#39;)
library(&amp;#39;rcrossref&amp;#39;)

doiref &amp;lt;- function(path, style = &amp;#39;apa&amp;#39;){
  mystring &amp;lt;- readr::read_file(path)
  doi &amp;lt;- unlist(stringr::str_extract_all(mystring, &amp;quot;\\b10\\.(\\d+\\.*)+[\\/](([^\\s\\.])+\\.*)+\\b&amp;quot;))
  doi &amp;lt;- unique(doi)
  ref &amp;lt;- vector()
  for (i in 1:length(doi)){
        temp &amp;lt;- try(rcrossref::cr_cn(dois = doi[i], format = &amp;quot;text&amp;quot;, style = style), T)
        ref &amp;lt;- c(ref,temp)
  }
  return(ref)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;测试了一下，基本符合预期，这样只用关心样式名称就可以输出任意格式的文献清单了。不过我还是觉得这个功能只是作为一种对当前投稿体制的妥协且很不环境友好，互联网时代如果关心的是目的地，何必要人为给它加个壳，横竖也不会有人去读内容，只会被复制粘贴。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>文献管理的三个阶段</title>
      <link>https://yufree.cn/cn/2018/01/05/literature-phase-3/</link>
      <pubDate>Fri, 05 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2018/01/05/literature-phase-3/</guid>
      <description>


&lt;p&gt;文献管理方面主要包括文献收集、整理、分析与追踪，目的是获取当前研究趋势。用认知过程阶段可以分成三个：从无到有、从有到精与从精到用，从无到有是指刚进入一个新领域时的状态，绝大多数研究生跟转行的科研人员都要通过这个阶段构建自己的文献知识库；从有到精指维护与整理与追踪新文献；从精到用阶段指文献知识库体系直接参与科研过程形成产出的过程。&lt;/p&gt;
&lt;div id=&#34;从无到有&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;从无到有&lt;/h2&gt;
&lt;p&gt;刚开展研究工作的第一步就是背景知识的了解，除非你研究生转行，一般本科阶段的学习应该已经掌握了学科基础，这个是共通的背景知识。基于此你要从教科书上相对确定的知识走向文献资料中相对不那么确定的知识，此时最好的开端是一本英文教材，一方面锻炼英文，另一方面英文教材的更新比国内要快（你大概率可以从图书馆借到，而且多数图书馆都有根据你需求订书的服务，不要浪费）。如果你精力足够，甚至可以联系作者问下是否可以翻译，这样一举多得，不过我没操作过，只是建议。另一个思路是通过 MOOCs 来系统学习，国内外很多高校放到网上的课程授课老师都属于接受新思想比较快的人，讲义也比较前沿，系统性比较高。还有一个不太通用的方法是阅读近些年的博士论文，其文献部分一般都是相关信息，不过能不能找到就不好说了。这个阶段一般要两三个月，不要心急，先把基础打好。前面掉的坑越多，后面跳坑就更有经验。&lt;/p&gt;
&lt;p&gt;一般而言，一项学术成果要先发表，然后被综述评论，然后进入研究生课程讨论班，然后进入本科生课程讲义，最后才进入学科经典教材的更新。所以你可以倒着去走这个流程，越往后可能越不容易懂，但循序渐进总比一下读前沿论文被搞晕要好。有了相对前沿的教材或讲义作为知识框架，你的脑子里此时应该比较清楚导师让你做的东西或自己打算做的东西在学科中的定位，解决的是什么科学或工程问题，此时可以进行基于关键词检索的文献收集了。&lt;/p&gt;
&lt;p&gt;一个良好的搜索返回的结果应该在10篇以内，首先要是综述，然后关键词检索方面建议学点逻辑运算符来过滤掉不相关信息，如果你上一阶段看的书是5年前更新的，那就只去关注最近5年的综述；如果你做的领域实在太新，那就把关键词信息的同义词跟近义词也加到搜索里；如果你能找到一篇写的特别好的综述或者有高人指点的论文，那是最高效的方法，可遇不可求。这10篇论文请按年为单位每1-2年选一篇综述去看，一月内读完，要求是精读，也就是论文里提到的研究都加到你的文献库里并阅读细节，同时可参考综述章节对文献库进行分组。一定要做笔记，而且要进行结构化的笔记或思维导图，这个阶段时间可能比较长也比较累，成果是当你去听系里的报告时，你大概能将报告定位到你的笔记框架里。到此文献库就从无到有了。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;从有到精&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;从有到精&lt;/h2&gt;
&lt;p&gt;有了文献库不代表就不用读了，你要建立一个体系来整理并追踪最新文献，这一阶段希望你早就了解 RSS 是怎么回事并且使用过 RSS 阅读器。如果没有，邮件订阅也不失为一个良方。这里我要提示一下，一般文献库管理工具都提供针对单篇文献的笔记功能，不要用。请自建按研究主题的笔记，把新的有意思的新论文连同你以后可能引用的语句直接摘到相关主题的笔记里，而且要让你的笔记可以反链到数据库或通过 doi 可以直接找到原文（推荐后者）。没别的意思，我希望你的笔记稍加整理就可以作为综述发表，省的你次次重返工。建议文献追新频率每周一次，固定时间，看到好的文章就马上消化掉。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;从精到用&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;从精到用&lt;/h2&gt;
&lt;p&gt;文献信息的收集与整理不是为了写笔记，是为了需要用的时候瞬间能够用到，例如写一个技术报告，给别人审稿，还有最重要的：写科技论文。科技论文不同于其他文体一个最显著的特点就是参考文献体系的支撑：所有的讨论都要起于前人的发现，参考文献事实上经常是考察作者知识面的关键，对前人工作的遗漏会严重降低文章的系统性与创新性，经常会被审稿人一票否决，哪怕其实你做的跟前人是不一样的。另外的使用就是报告幻灯片跟其他学术交流场景，如果你能做到在大脑或笔记中快速定位到一个观点或现象然后几句话说清楚，这个习惯能帮你离开学术界后在其他行业直接展开降维打击。绝大多数离开学术界的人都不会继续保持了解前沿动态的习惯而更多依赖过往经验，一个人的经验如何去抗衡一堆参考文献背后成百上千人的经验？当然有些东西那些成百上千人也许都不知道，特别是工程上的。不过这种“学院派”的研究习惯最大的好处就是让人更谦逊些，知道一山更比一山高，处处重峦叠嶂。那些上来就趾高气昂且沉醉于自己小圈子的人，不管在学术界还是其他行业，九成以上是鼠目寸光之辈，请远离这些人。&lt;/p&gt;
&lt;p&gt;谈文献管理，我希望不要掉到工具选择的坑里，要构建完整的知识管理体系，哪怕是基于便签的只要能实现头脑知识的更新换代就可以了，如果能方便写作投稿，那就更好了。切不可舍本逐末，单纯把文章发表作为目标去优化，毕竟所有的短期目标都要最终整合成你学术生涯的一部分，可以抽时间去想想一些简单的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;我的研究究竟有没有实际意义？&lt;/li&gt;
&lt;li&gt;我的发现是否有助于学科发展或写入教科书？&lt;/li&gt;
&lt;li&gt;我现在纠结的事10年20年后会不会纠结？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以人之渺小，所有的时间都是浪费，但你要为自己浪费的时光赋值。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>假设检验的乌云</title>
      <link>https://yufree.cn/cn/2017/10/28/nhst/</link>
      <pubDate>Sat, 28 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/10/28/nhst/</guid>
      <description>


&lt;p&gt;19世纪的最后一天，开尔文男爵在展望20世纪物理学前景时提出了两朵乌云，后来这两朵乌云分别催生了相对论与量子力学。时至今日，物理学家还在为了统一相对论与量子力学而不懈努力，而由此衍生的圈量子场论跟弦论已经不是几句话说得清楚的了。然而，21世纪的科研天空可就不仅仅是两朵乌云了，简直可以说乌云密布，这其中最大的一块大概就是空假设显著性检验（NHST），以此为基引发了无数次的关于科研成果可重复性、发表歧视、多重检验与p值、因果推断、科学决策等的争论，这些争论有些出现在学术期刊，有些则在科研社交网络蔓延。作为一名科研人员，身处这样一个窘境而不自知是可怕的，这意味着很多在做的工作根基上就有问题，盲从与职业化的科研正在蚕食科研成果的威信。我并无能力提出完美解决方案，但有必要把问题先提出来，疑惑对科研总是有益的。&lt;/p&gt;
&lt;div id=&#34;空假设显著性检验nhst&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;空假设显著性检验（NHST）&lt;/h2&gt;
&lt;p&gt;NHST更常见的形式是p值，也就是在空假设成立的条件下某事件发生的概率。p值有多流行呢？根据 Jeff Leek 的&lt;a href=&#34;https://docs.google.com/presentation/d/1hzdSDaPPSE9xUYZHhOVfQIRPPdwe0A9SdE7QDsK3bOA/edit#slide=id.g255a5ace66_3_796&#34;&gt;估计&lt;/a&gt;，如果把p值当成一篇文献，那么其被引次数已经超过300万次了，当之无愧的史上被引次数之王，甩&lt;a href=&#34;http://www.nature.com/news/the-top-100-papers-1.16224&#34;&gt;第二名&lt;/a&gt;一个数量级。原因其实很简单，p值已经渗透到几乎所有学科的研究中了，特别是实验学科。可想而知，如果产生p值的 NHST 出了问题其影响力有多大。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;院士身份悖论&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;院士身份悖论&lt;/h2&gt;
&lt;p&gt;要了解NHST的问题，我们首先要看下一个基于NHST的悖论。张三研究员是一名中科院非外籍院士，我们对其有两个假设检验，第一个假设检验的空假设是张三是中国人，备择假设就是张三不是中国人，因为我国不承认双重国籍，所以张三身份不存在薛定谔的猫态，要么是，要么不是。第二个假设是张三是中科院非外籍院士，备择假设就是不是，也是互斥的。那么两院院士不到两千人，中国人口14亿，概率大概百万分之二，备择假设的概率是0，这个情况比较特殊，也就是备择假设永远不成立。现在我们不知道张三的国籍，但知道他是中科院非外籍院士，但根据NHST，张三不太可能是中国人因为绝大多数中国人都不是院士，那么拒绝第一个检验的空假设后我们就会发现，张三成了不是中国人的中科院非外籍院士，额，那张三究竟是哪国人？&lt;/p&gt;
&lt;p&gt;也就是说，如果一个假设对另一个假设来说很稀少，NHST会在很低的条件概率下拒绝掉，然后那些稀少的事情在NHST里就成了无法被检验的事情。这个例子最早是 Cohen &lt;a href=&#34;http://ist-socrates.berkeley.edu/~maccoun/PP279_Cohen1.pdf&#34;&gt;提出&lt;/a&gt;用来说明人们在使用NHST时的问题。本质上是多数人在使用p值时搞混了条件概率，拿上面院士身份来说，我们的假设 H0 在面对张三这个数据 D 时给出了拒绝 p(H0|D) = 0，这个决定是构建在假设 H0 成立时出现 D 的概率太低（即p(D|H0)）之上，也就是说NHST下，我们默认下面的概率是成立的：&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
p(D|H_0) = p(H_0|D)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果你修过任何基础的统计学课程都会知道这两个概率之间差了一个贝叶斯大爷。通过使用贝叶斯定理，在新数据出现后原有概率是要被更新而不是直接拒绝掉的。通俗点说就是 NHST 属于革命派，不认可就打倒你；贝叶斯属于改良派，用新的证据更新原有理论。好了，这里我们回顾一下科学史，革命派跟改良派确实都出现过，但当学科基础相对稳定后，更多的科学知识是改良派搞出来的，除了物理学两朵乌云，多数科学研究都是N+1模式，你现在在科学领域搞从零到一基本等同于对好几代科研人员同时开群嘲，结果一般会被认为民科或伪科。这个悖论的本质就是把假设下的事实与事实下的假设搞混导致的，这是NHST的一个致命问题。然而致命问题可不止这一个。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;方法学悖论&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;方法学悖论&lt;/h2&gt;
&lt;p&gt;过去的100年，测量方法的精度是在不断提高的，而精度其实又会影响研究结果，很不幸，也是通过 NHST 来进行的。其实 NHST 在实验物理学里用的还是好好的，例如我去检测一个物理量，只有数据出现在其理论预测下数值四五个标准差以外才会对理论产生实质作用。此时，测量精度越高，由于测量误差导致的对原有理论的冲击就会越少，因为物理学的预测性要比化学生物等学科要好不少且此时 NHST 检测的原有理论是比较真实的。但在其他学科，特别是心理学跟医学的控制实验里，在实验开始前你几乎就可以确定空假设是不成立的，要不然你也没必要分组，此时你去搞 NHST ，几乎一定可以找到差异，此时测量精度如果不断上升，那么你会识别到一系列差异，但这些差异的效果是无法体现在p值里的，p值可能非常小，但效应却属于明显但很微弱，这样的结果也许可以发表，但对实际问题的解决几乎没有贡献。更极端的情况是如果你加大了样本量来提高统计功效，你总是能发现差异的，也就是你的空假设里原有学科理论为真也是会被方法学进步给推翻的。总结下就是 Meehl 在60年代就提出的&lt;a href=&#34;https://philpapers.org/rec/MEETIP&#34;&gt;悖论&lt;/a&gt;：方法学的进步与增大样本数对于相对硬（理论根基深厚）的学科证伪是正面的，但对相对软（理论比较模糊）的学科则是弱化。方法学悖论的根基其实是应用学科与基础学科的矛盾，基础学科用 NHST 检验观察事实中的理论，但应用学科用 NHST 来检验的是实验设计预测下的事实，此时实验设计的那个假设与 NHST 的空假设并不对应，而 NHST 先天弱化空假设的问题就凸显了。&lt;/p&gt;
&lt;p&gt;事实上，p值正在成为测量投资与努力而不是事实的标准，给定差异，我们总能找到足够的样本来发现这个差异（这也就是常说的功效分析）。也就是说，NHST 有时候功效不足测不到差异，有时候又一定会能测出差异，但科学事实并不会因为你使用了 NHST 而发生变化，特别是有意义的变化。而作为标准的p值其实在被样本数决定同时又综合了测定效果强度与不确定性，这样的一个标准其实有点多余，你完全可以用描述性统计与置信区间来分别表示效果强度与不确定性。p值也并不能增加新知识，考虑一个多元线性模型，我们只能在多元模型里得到参数，也就是有限检验，不能发现未知参数，但科学就是寻找未知；变量间的关系在数值改变后如何考察，正负关系如何预测，预测性也就无法实现。那么此时，还有必要使用 NHST 吗？&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;低垂的果实&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;低垂的果实&lt;/h2&gt;
&lt;p&gt;20世纪的技术有了意义深远的进步，但更现实的问题是，科研里低垂果实已经没有了，学科从分立走向交叉，开始不断服务社会，所有的科研都像是应用科研。服务社会职能的出现要求科学家回答的不再是科学问题而是现实问题，或者说，科学地回答现实问题。但现实问题非常复杂，科学家要想排除影响，大都采用控制实验来验证观察研究中的事实。注意，这里的事实不再是理论假设，而是一个现象，如果本来就观察到了差异，用 NHST 根本就不会让我们知道更多的事实，我们可以用无数独立手段证明这个事实的存在然后整合进学科知识体系，但并不能产生更多的思考，理论的预测效能在 NHST 里实际是体现不出来的。&lt;/p&gt;
&lt;p&gt;抛开这个问题，另一个更现实的问题是很多一线科研人员甚至还没搞懂 NHST ，说不好听一点，就是只会模仿别人论文，这样连错的都一块模仿了。这里面深层次的原因是科研人员的教育仅仅停留在了知识与逻辑层面，没有系统的科学思想训练与科学史背景。后面那两个对发文章不但没用，反而会让你怀疑科生，但没有后面这两个，你只会看到一个各干各的一团和气的研究氛围，没有评论与争执的岁月静好只会让整体科研水平永远停留在二流追随的状态。你去看各学科顶级期刊里的评论与回复，你会体会到哪里在发生的事，举个不恰当的例子，你到 Github 上去看，那些常用的软件都会在不断的更新与协作，而学术论文的更新与协作却少得多，一个重要的因素就是很多所谓科研成果永远都不会有人重复与验证，最大的作用就是放在简历里谋求职业生存，很多人自以为掌握了高端的果实但其实那些果子对学科发展并无意义，如同 NHST 一样，用之无味，弃之生存空间都没了。如果你把科研当职业，起码也要有点 Github 的分享与协作的职业素养。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;路在何方&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;路在何方&lt;/h2&gt;
&lt;p&gt;关于 NHST 其实还有很多问题例如多重比较跟p值发表歧视，但系统去看，p值也有着自己的生命力，我想更多人关心的是如果我不用 NHST ，拿什么证明我的结果可靠？如果没得选，这剂毒药还是得吃啊。答案其实上面都大概提到了，你如果坚持使用p值，那么就也请同时报告参数估计与置信区间，虽然这个方法也被人喷过。如果你打算完全开一条新路，那就去学贝叶斯统计，贝叶斯统计有自己成套的处理体系，简单说就是先假设参数分布，然后用数据更新分布，后验分布计算出来就同时有点估计跟方差估计，同时多重比较问题也不存在，但随机错误无法避免，此时参数估计方差大也能体现，后续研究可以使用这次的后验数据作为下次先验数据，这样你可以实现完全的 N + 1 模式科研，其验证与预测性也很大程度依赖采样与模拟技术，之前贝叶斯方法不能流行很重要的一个原因就在于计算比较贵，现在就便宜很多了。但我想说的是，这类知识因为提出时间不长除了几个数的过来的名校开设了课程外几乎完全需要自学，不过你要是真对科研感兴趣，这都不算什么。&lt;/p&gt;
&lt;p&gt;有人说我写过的几篇文章是在劝退，我还真没那个意思，看清现状后的理性选择对人对己都是负责的，如果你根本不适应这个现状还又觉得没了退路，那你肯定是被什么毒鸡汤绑架了，这世界上本来就没路。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>幻化残生中的研究生</title>
      <link>https://yufree.cn/cn/2017/09/24/ecmb/</link>
      <pubDate>Sun, 24 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/09/24/ecmb/</guid>
      <description>


&lt;p&gt;幻化残生，也就是环境、化学、材料跟生物这四大学科的近似谐音，属于各类研究生中实验比例最高的专业。然而，其生存现状并不乐观：&lt;/p&gt;
&lt;p&gt;首先，这四个学科属于建立在脑力劳动之上的体力劳动。例如前处理、过柱、表征、养细胞、涂板子、野外采样等等，流程性非常强，到时间点上不论节假日还是凌晨饭点都得待命，但有时又会发现找个本科生带上两天也能做出来。一个尴尬的事实是实验学科一个重要研究方向就是取代人工操作实现流程自动化与便携化，当实验简单到轻轻一按时，研究生训练得到的技能瞬间贬值，更尴尬的是实现这个过程需要的背景知识是物理、机械跟电子工程而不是幻化残生，会某项实验技能短期可以取得不错的成果，但长期看几乎一定会过时。&lt;/p&gt;
&lt;p&gt;其次，特别拼先进仪器技术，进而导致平台建设重于人才培养。今年这个技术能发顶刊，明年就可能被取代了，有些特殊资源例如光源没有背景想约个机时难得要命，如果不进行一些高开支实验可能编辑就直接拒稿，而先进仪器装备的价格奇高，所以从经济角度，这四个学科都属于很烧钱的。那么这里的尴尬就是你的才能受限于仪器平台，从研究机构角度看，投资仪器显然比投资人才培养在初期更有效果，而人才培养初期其实也就是仪器操作。这个没啥办法，现在很多科学问题的回答其实早就脱离了理论导向阶段，而是我有一个问题想回答，但目前技术回答不了，也就是假设早就有了，就等着新技术检验。你去看这些年诺奖，很多是技术获奖而不是理论获奖。也就是说，实验学科比起人才更需要仪器平台资源。&lt;/p&gt;
&lt;p&gt;再次，这几个学科产业转化基本停留在前言里，毕业后除了年龄比同专业本科生大了不少，在满足业界要求上本质区别并不大，这进一步导致本应分流到业界服务社会的博士硕士继续留在学术界造纸，而想从学术界熬出头你看前人经验借鉴意义不大，很多人没考虑时代造就的红利窗口期而大谈特谈自己的奋斗，但要知道此一时彼一时，目前学术界的门槛比10年前高了很多，同样的奋斗强度10年前进高校很容易，现在可能博后都没人要。如果本科转行也就算了，但到了博士转行就真的是在奉献青春了，当然这可能是无法避免的。&lt;/p&gt;
&lt;p&gt;这些现状经常搞得研究生自身怀疑人生，看着转行金融、咨询、IT的同学心有不甘，用学术理想充值的生活把自己隔离在实验室内，但走出实验室的柴米油盐变量太多，控制不来。同时，你又会很惊奇地发现，这些年报道的学术界年轻有为的青千、优青与各路人生赢家基本都是这四个学科的；而且从经费分配跟论文影响力上看，这四个学科也是超级大户；再从经济学角度去看，你会发现围绕这四个学科的仪器、耗材甚至样品测定跟论文润色服务都已经形成了成熟产业链，行业利润十分惊人。注意，这些产业是对科研进行支撑的而不是业界，如果只是这些行业高速发展而产业界没有起色，那事实上是在用纳税人的经费吹肥皂泡，不会长久。&lt;/p&gt;
&lt;p&gt;这并不奇怪，实验学科的知识与技术更迭速度是非常快的，从走进实验室那一刻，你就会发现师兄师姐用的技术学校里根本就没教过或仅仅做了个展望，系统的学习基本上都被传帮带模式替换。如果你自己不去问为什么，大概率你师兄走的弯路你还得走一遍，你师姐画不出的图你也画不出来。更尴尬的是，有时候你会发现，如果你的想法是属于排列组合出来的，那么其实仪器公司完全可以替你做，他们不做并不是不会，而是等着收服务费，你发你的纸，我赚我的钱，各取所需。在这个场景下如果还没意识到自己的民工本质，那大概率是要做一辈子民工的。&lt;/p&gt;
&lt;p&gt;曾经有人提过学术界存在生态位，大家各做各的相安无事，但这个想法现在看比较天真，因为现在竞争者基本都不是来自学科内，而是其他学科的入侵，如果这个问题你自己学科的人搞不定，别的学科就会过来。例如发现一种新材料，如果你觉得意义不大不掺合短期没啥问题，但做材料的表征完了得找应用出口啊，环境、生物、化学都有，你是无法限制某种研究只关注自己学科问题的，技术有自己的生命力，总有人会转过去，事实上这可能是目前科学进步的一个范式：个别学科突破，带动其他学科发展。&lt;/p&gt;
&lt;p&gt;基础学科对新技术的接受度要快于应用学科，一个常见的模式就是某个数学模型首先应用在物理，然后化学，然后生物，然后是边缘综合学科例如环境、医学，然后就是社会科学。当然也存在某些从应用角度出发的模型后来被应用到其他领域，金融与生命科学中经常出现这样的案例。但你应该发现一个问题，要想解决现在的问题，通常老路是不通的，要么回归基础学科，要么从别的学科借鉴，不论哪一种都需要你持续学习新知识，特别是外学科知识。有一个最简单的办法就是你去看看那些最聪明的人在用什么，然后想想能不能用到自己的学科框架里。&lt;/p&gt;
&lt;p&gt;实验学科的发展有时候是很残酷的，初期势必牺牲掉一批掌握过时技术的研究生，这个国内外都很常见，但国外业界会吸收一部分，国内则是学术界大面积收留，这个问题的后果就是现在很多教授对于学生无力指导，看到概念就回来让研究生试，研究生自然苦不堪言，毕业后就业方向非常窄。但同样是实验学科，高能物理、生物统计的毕业生转行就相对容易些，因为可以去做码农，至少生活水平对得上学位。而很多实验学科的研究生对此并不感兴趣，甚至完全不懂，思想上停留在努力实验发论文拿教职的简单规划上，不喜欢接触社会就只接触仪器。这其实是最大的偷懒，科研是需要脑力持续投入的，如果是实验学科还要加上体力。不但要持续学习，还必须要主动学习，关心前沿，而这又是研究生的普遍弱点。&lt;/p&gt;
&lt;p&gt;学科前沿是一个很模糊的东西，对幻化残生而言，教科书上的实验技术是一定落后于科研的，此时对学术前沿的感知要么来自文献，要么来自会议或培训，坦白说，这两个方法都具有很强的主观性，夹杂很多人的小算盘。好比你想在微信里打开淘宝链接，不是不行，就是要通过复制过程恶心你一把，但其实这种经验过程你也没啥办法。另一个方法是各种文献信息学指标，例如H指数，被引率等等，但这些指标属于后验指标，你得至少等文章发表过去两三年才能开始评价，但这两三年中也会有一大把新趋势出现。还有个方法就是自己当期刊编辑或审稿人，其实这个是很多教授的独门秘笈，因为你会比其他人早好几个月知道新研究的动向，但研究生拿到的审稿机会本来就少，高水平期刊更是不会找研究生审稿。所以其实对于很多研究生而言，想了解前沿跟他人的研究动向几乎不可能，而根据我的观察，如果同行坐到一起聊天你对新动向一无所知，那么对方也就不会在你身上浪费时间了。有些出版方跟研究机构也会发布一些热点文章，但多数基于编辑经验，并不一定准确。&lt;/p&gt;
&lt;p&gt;我之前曾写过用文本分析来探索前沿，但我估计很多人也就是看个热闹，并不真的会用。也罢，这个坑我挖的我填，我做了一个在线app来探索最近三年学科趋势：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://yufreecas.shinyapps.io/journaltone/&#34; class=&#34;uri&#34;&gt;https://yufreecas.shinyapps.io/journaltone/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之所以选三年，是因为我感觉三年以上用引用指标更靠谱。这个应用保留了最大的自由度，你可以简单修改期刊或关键词用默认代码绘制相关趋势，或者直接尝试修改成看五年甚至十年的趋势。但我需要声明的是这个app我放到一个免费在线平台上，每个月流量有限，超了就没法用了，所以我建议你本地安装运行。源码&lt;a href=&#34;https://github.com/yufree/journaltone&#34;&gt;在此&lt;/a&gt;，此外，本地运行时多数包cran上有，但有一个方便抓pubmed数据的包是我自己写的，你需要从github上下载安装：&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;devtools::install_github(&amp;#39;yufree/scifetch&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其实，对于幻化残生的研究生而言，主动了解科研趋势只是一方面，了解你自己才是更重要的。当你觉得不好时，不要总是怪罪时代跟环境，也想想自己身上的问题；当你一帆风顺时，不要总觉得这是自己勤奋与努力的结晶而忘记了科研浪潮的背后推手。随波逐流不会过的太差，但放弃思考是绝难在学术界生存下来的，不要真的幻化残生了。&lt;/p&gt;
&lt;p&gt;师兄只能帮你到这了，剩下的，我也没想明白。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>科研博客圈的书剑恩仇</title>
      <link>https://yufree.cn/cn/2017/09/04/sci-blog-discussion/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/09/04/sci-blog-discussion/</guid>
      <description>


&lt;p&gt;有人的地方就有江湖。&lt;/p&gt;
&lt;p&gt;推动科学进步的是学术争论，大家围坐一席以数据与逻辑为工具互相质疑，寻求共识。但事实上这个过程中并不缺乏个人或群体情感的介入，这一方面是现代科研职业化所导致的拿钱吃饭，另一方面则是科研人员自身的主观好恶。这一点在科学家的博客上展示的淋漓尽致，虽然在学术期刊里发评论比较正式，但在预印本、数据共享与可重复性研究的大趋势下，越来越多的科学家选择时效性更高的非同行评议的博客来对科学进展进行评论。借助这些社交媒体，我们也可以一窥他们对学术观点的爱恨情仇，也许有人不屑于这些主观性比较强的评论，但从学术交流的角度出发，如果我们仅仅通过学术期刊与会议交流学术观点，由于存在审稿与运作周期，很多共识会消耗大量的传播成本来达成，这不仅与信息时代脱节，也会造成资源浪费。下面我们看些案例感受下国外学术界在博客这一媒介上的观点交锋：&lt;/p&gt;
&lt;p&gt;案例一：“主观”的贝叶斯方法&lt;/p&gt;
&lt;p&gt;哥伦比亚大学的 Andrew Gelman 的博客可以算得上是个火药桶了，他本身主张贝叶斯学派，而赶巧贝叶斯学派跟频率学派可以算得上科研数据分析里哲学思想差异最大的两派，起码按我的粗浅认识是根本无法调和的，所以即便实用上甚至算法上都差异不大，想对这两种思想和稀泥基本都会被 Gelman 教授无情嘲讽，如果你还打算说贝叶斯不好，基本上会被博文讨伐。当然，也不是所有人都有这个待遇，同舟子的做法类似， Gelman 教授基本也是逮着大鱼去坑。需要提醒的是他可不是舟子那种十几年不做科研的学术圈外人士，其本人是哥伦比亚大学应用统计中心的主任，其团队的研究领域十分广阔，大家可以感受一下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;why it is rational to vote; why campaign polls are so variable when elections are so predictable; why redistricting is good for democracy; reversals of death sentences; police stops in New York City, the statistical challenges of estimating small effects; the probability that your vote will be decisive; seats and votes in Congress; social network structure; arsenic in Bangladesh; radon in your basement; toxicology; medical imaging; and methods in surveys, experimental design, statistical inference, computation, and graphics.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;顺带一提，著名贝叶斯统计软件 stan 就出自这个团队。&lt;/p&gt;
&lt;p&gt;这次事情的起因是卡内基·梅隆大学的 Larry Wasserman 教授（2016年当选美国国家科学院院士）在接受一个博客&lt;a href=&#34;https://errorstatistics.com/2013/12/28/wasserman-on-wasserman-update-december-28-2013/&#34;&gt;采访&lt;/a&gt;时对频率学派与贝叶斯学派下了个定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wish people were clearer about what Bayes is/is not and what frequentist inference is/is not. Bayes is the analysis of subjective beliefs but provides no frequency guarantees. Frequentist inference is about making procedures that have frequency guarantees but makes no pretense of representing anyone’s beliefs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Gelman 教授对其频率学派的观点没啥意见，但那个 “subjective” 直接引爆了火药桶。而按照 Gelman 的定义，贝叶斯方法应该是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using inference from the posterior distribution, p(theta|y)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;特别的，他还认为：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Science is always full of subjective human choices, and it’s always about studying larger questions that have an objective reality.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;坦白说这个看法是比较符合科学史的，虽然当今科学理论体系逻辑上相对完备（先排除下哥德尔跟量子力学），但其发展确实很曲折，在实验数据跟统计决策成为主流之前，很多理论在发现或提出时主流科学家并不接受，有的是逻辑上不接受（很多新理论完全不容于旧理论），有的则属于威权集团打压，可以说相当主观。&lt;/p&gt;
&lt;p&gt;但在后面的论述中，Gelman 教授就开始开嘲讽技能了，Larry 认为在高维数据处理中贝叶斯方法没意义无法解释，Gelman 教授则反驳说他觉得除了贝叶斯方法别的方法也都是解释不通的，并且他认为 Larry 自己不懂贝叶斯还瞎定义是十分不妥的。不得不说这段论述很没营养，跟小学生吵架差不多。紧接着 Gelman 教授又提到主观确实是贝叶斯方法的一部分但不是全部，那频率学派是不是可以说成“简单随机采样的技术”，科学研究范围在拓展，各种方法也在发展，贝叶斯方法可以研究客观问题。这个说法也比较中肯，接下来 Gelman 教授又开启了挖坟模式，他把 Larry 08年到13年关于贝叶斯方法中随机性看法的转变给列了出来，紧接着又说我也有这个转变过程。但文章最后他又翻了 Larry 对经济学家的旧账，认为他存在个人偏见。&lt;/p&gt;
&lt;p&gt;看起来这个文章似乎比较正常，但这篇博文真正有趣的是评论，基本上集中了当今统计学中各路高手，下面是个不完全名单：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Nick Cox 杜伦大学 Stata 元老级开发者&lt;/li&gt;
&lt;li&gt;Larry Wasserman 卡内基·梅隆大学教授 当事人&lt;/li&gt;
&lt;li&gt;Deborah G. Mayo 宾夕法尼亚大学教授 采访 Larry 的人 errorstatistics.com 博主&lt;/li&gt;
&lt;li&gt;Kevin Dick 斯坦福毕业 创业者 possibleinsight.com 博主&lt;/li&gt;
&lt;li&gt;Judea Pearl UCLA 教授 &lt;a href=&#34;http://causality.cs.ucla.edu/blog/&#34; class=&#34;uri&#34;&gt;http://causality.cs.ucla.edu/blog/&lt;/a&gt; 博主&lt;/li&gt;
&lt;li&gt;Christian Hennig 伦敦大学学院教授&lt;/li&gt;
&lt;li&gt;Norm Matloff UC Davis 教授&lt;/li&gt;
&lt;li&gt;Brendan K O’Rourke 都柏林理工教授 &lt;a href=&#34;http://www.brendankorourke.com/&#34; class=&#34;uri&#34;&gt;http://www.brendankorourke.com/&lt;/a&gt; 博主&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们可以看出这么几件事：首先，这些领域内专家会互相关注对方的个人网站并通过这种方式互动；其次，看他们的讨论很有启发，必看书本上的干货更有意思；再次，很多讨论虽然对问题是没营养的，但有助于我们了解一些学术界的风格或流派。在前沿领域由于知识不全，多数情况是无法达成共识的，但通过了解其流派风格会帮助你更全面的看问题。&lt;/p&gt;
&lt;p&gt;案例二：两个软件会产生一个结果吗？&lt;/p&gt;
&lt;p&gt;巴拉巴西是一位呼声很高的诺奖候选人，其畅销书《链接》可以说把不少科研人员吸引到了网络科学的研究领域，现实中的无尺度网络的幂律分布所具有的奇特性质在很多并不相关的领域都有展示。但这个故事主角不是他，提到他只是想提前表示下同情，因为他在加州理工教授 Lior Pachter 的博客里躺枪了。事实上，2014年 Lior Pachter 在博客上开了个三部曲，本意就是对 MIT 教授 Manolis Kellis 的个人恩怨，但为了把故事讲的通透点，这位老兄追根溯源并展示了自己强大的数理功底，先后对两篇发表文章的创新性进行质疑，从图表到算法，其中一篇就是巴拉巴西的，另一篇则是 Manolis Kellis 教授的。这个故事科学网薛宇老师曾经翻译评论过，我这里不细讲。但 Lior Pachter 教授在后续的博文中又对号称H指数100多的巴拉巴西来了次二次扒皮，严格说被炮轰的其实不算冤枉，但被人挂的如此直白也只有 Lior Pachter 教授能做得出来。而我今天要讲的是他最近又跟纽约大学石溪分校&amp;amp;哈佛&amp;amp;卡内基·梅隆大学的同行掐架了，上演了进攻-防守-再进攻的三部曲。&lt;/p&gt;
&lt;p&gt;首先 Lior 讲在他们那个 RNA 测序定量的圈子里，软件跟软件差异都是很大的，基本你用不同软件想得到一样的结果非常困难（这也说明这个领域的研究共识没有达成）。然后他话锋一转，说自己组里2016开发的一个软件跟最近发表在 Nature Methods 上的软件处理结果却出奇的一致，皮尔逊相关系数三个九，然后又是一通追根溯源。这里岔开说一句，Lior 之所以可以追根溯源，是因为预印本及版本控制系统的流行，最近 ACS 也对化学领域提供了预印本服务，预计不久就会覆盖绝大多数涉及数据分析的实验学科。从版本上 Lior 发现在他们论文发表后 Rob Patro 的软件也有了一个很大的更新，更新前跟他们组软件差异明显，更新后确几乎一样了，最后他认为 Rob Patro 所发表的文章实际上就是抄了自己组里开发软件的思想，然后加了个矫正。当然 Rob Patro 也很快在 github 上发表了一个回应，大意是他们在文章跟源码中多次引用了 Lior 组的论文并且在有些数据集中这两个软件的结果是不一样的，工作流程也不一样。但 Lior 教授显然并不满意，他又写了一篇博文指出其回复混淆视听，所谓的不一样是下游分析，而在 RNA 定量上这两个差距还是很小，如果你去看这篇回复会发现 Lior 甚至使用了动画来展示两者区别很小，可谓精心准备。我在读这三篇文章时学到很多的论述方法与追踪验证方法，可以说很多方法现在还没出现在教科书中，但可以感到早晚会形成趋势。&lt;/p&gt;
&lt;p&gt;凭心而论， Rob Patro 的文章就算是对 Lior 软件的改进也是值得发表的，因为当前科研基本都是N+1模式，都是在前人基础上做功课。但我也比较理解 Lior 为什么这么火大，首先在他眼里这两个软件本来就是一回事，凭什么发 Nature Methods，他自己那篇都没发这么好，另一方面就是 Rob Patro 文章在他看来有硬伤，速度也不快，效果也没那么好，评价标准还有问题。其实说白了也有点个人恩怨而不是就事论事，但在这些问题上你去要求当事人一碗水端平也很难。如同第一个案例所言，科学研究就是会掺杂各种主观情感，但作为旁观者，我们可以从中去学习他们讨论问题的方法，例如 Lior Pachter 教授的论证过程，虽然不如发表文章里那么逻辑完备，但思考步骤都是比较清晰的，而这个过程你在期刊论文中往往看不到，好比你看到的总是对方站在山顶但怎么爬上去的一般都不会写，但有时候这些看似琐碎的步骤却足够让你永远达不到那个高度。&lt;/p&gt;
&lt;p&gt;顺带一提， Lior Pachter 教授的博客上还友情链接了 Andrew Gelman 教授的博客。我想说的是在国外是真真切切存在着通过博客的学术交流的，参与学者的水平也是相当强悍，而且不同于国内科研向公众号或博客满足于对论文的解读，这些博客上更多出现的是一种批判式讨论，而且夹杂了相当重的个人情绪，如果你打算阅读也是需要辨伪存真的，这本身对于提高科研思维也有帮助，所以我推荐高年级本科生、研究生跟科研一线的学者都可以去寻找自己感兴趣领域大牛的博客，省的每次找推荐审稿人都搞近亲繁殖，如果你能从这些火药桶博客里获得正面评价，那么恭喜你，科研对你并不是个坑。&lt;/p&gt;
&lt;p&gt;其实类似的故事还有很多，你可以从这篇文章里出发用关键词去探索。我在前面的文本分析的文章中曾提到越是高端的论文，发表勘误的比率就越是很高，这说明前沿领域的研究不确定性是很高的，思想碰撞也很激烈。如果把社交媒体上的各类花式吐槽也算进去，你会发现科研领域有很多烧脑的故事，各路参与者也从来都不缺名校光环跟牛文加持，阴谋诡计、解释掩饰、爱恨情仇等可能被小心翼翼地埋藏在数据与图表之中，虽然看懂需要比较高的门槛，但也正是这种门槛屏蔽了围观群众，上演一幕幕精彩绝伦但需要自行判断的书剑恩仇。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>环境化学的组队原则</title>
      <link>https://yufree.cn/cn/2017/04/21/es-team/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/04/21/es-team/</guid>
      <description>


&lt;p&gt;最近同组两个博后都拿到了教职，聊天时就说到了自己建课题组所需要的人员组成。因为当前课题组的研究方向是分析化学，所以一般至少会需要仪器仿真方向、材料合成方向、数据处理方向与特定应用方向的人才。如果是课题组长，这四方面至少要会两到三项，不然很多项目根本做不起来。回过头来想想，环境化学其实也可以考虑下组队问题。&lt;/p&gt;
&lt;div id=&#34;平台&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;平台&lt;/h2&gt;
&lt;p&gt;环境化学目标污染物常规一点的大概就是无机方面的重金属与有机方面的农残、食品添加剂、POPs名单上那一坨、PPCPs还有一些生物毒素。往前沿看基本都是非目的检测或筛选，简单一点的是已知污染物的代谢产物与结构类似物，复杂一点就是效应诱导分析或通过QSPR预测毒性这类。这些主题比较热门，如果是环境调查方向，可以各种污染物排列组合去发，毕竟考虑三间分布的话，时间地点人群不同，迁移转化规律也不一样。同时还有非生物介质、生物介质等等污染物载体的差异，研究视角不同，看到的东西也不一样。&lt;/p&gt;
&lt;p&gt;从分析技术上看，首先得有前处理设备。常规的超声、ASE、SPE、旋蒸、氮吹、离心机等得有，如果是作方法学的，什么SPME、整体柱、分子印迹、微流控、离子液体、纳米颗粒负载修饰等技术得有会的人，特别纳米材料那一块，考虑上磁性容易做出体系，当然实用性另当别论。这些设备与技术能让你萃取净化到目标物，当然你做无机搞微波消解然后赶酸啥的当我没说，你们那不叫前处理。&lt;/p&gt;
&lt;p&gt;处理完了的东西就要检测，环境分析检出限都是ppb级及以下，有机的就别来掺和了。无机检测ICP-MS是一站式解决方案，你要有钱搞得起MC-ICP-MS还可以做无机同位素分析，前提是有钱。有机一般就是质谱了，获取你比较关心核磁红外紫外，但那个出的结果大概率被审稿人鄙视。不过核磁另当别论，关键环境污染物含量太低，一般满足不了核磁要求，如果你能找到做合成的人帮你鉴定未知物那最好不过。质谱里面有条件上obitrap就上，再不济也得有个tof，如果你有FT，那基本可以抛弃前面的色谱了。定量的话qqq跟单杆最好都有，离子阱如果不做便携质谱或是普渡厨子的门生就不要考虑了。电离源也要配齐，气谱EI跟CI，液谱ESI跟APCI，冷门点的双喷雾或DESI也可以搞搞，不然有些污染物你可能根本就测不到。光谱也是一个思路，不过你得往高通量或可视检测去做，发不出文章也可以出点专利产品，这部分一般思路就是做抗体或者化学发光、荧光啥的，主要就是原子分子光谱，不过跟质谱比最大的优势可能就是便宜了。此外，表面共振拉曼光谱也是个快速发文章的渠道，配合一些稀奇古怪的修饰，总能在现场分析上找到突破口。光谱其实也有个大杀器，光源，前提你约的上，高能射线下能对很多过程进行细致分析与成像。此外，元素分析、各类显微镜电镜还有生物方向的特异性分析、测序跟芯片技术在环境领域也有应用，就看你想回答的科学问题是什么了。&lt;/p&gt;
&lt;p&gt;上面扯半天主要就是说得有个仪器平台可以依赖，而且多半你也不会买维修合同，这说明初期得有点当金工、电工甚至木工的手艺，没有也没关系，好的平台一般都标配。我现在组里那几台质谱基本都是老板各种谈判低价搞过来的，不是二手demo机就是根本已经坏了，故障五花八门全是自己修，搞得这边博士生毕业都可以去培训仪器公司工程师了，反正多数上门工程师的顶级秘籍就是换件。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;人才&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;人才&lt;/h2&gt;
&lt;p&gt;仪器只会报数，只有人才能把数据变成论文。在这一点上，一个课题组至少要有一个人有数理统计与编程技术背景，甚至每个组员都要有应用层次的编程技术。这可不是说看到别人用了pca，你也用pca去照猫画虎，你至少要知道这些技术为什么用，什么时候用，怎么用。只有这样写论文时才知道你在干什么而不是只知道套模版怎么做。软件工具python、r或matlab都可以。此外，也要有一个工科背景的员工或博后，懂仿真。统计模型与仿真模型完全是两个概念，一个面对数据归纳，一个面对实物或系统用规律演绎；一个用回归，一个各种偏微分方程；一个做假设检验，一个直接在虚拟空间进行实验。小到模拟一个吸附解吸过程，大到生态系统的物质能量循环，仿真模型与统计模型是要相辅相成的。软件工具comsol、matlab甚至netlogo都可以。这两类人是基础人才，能把数据变成故事。&lt;/p&gt;
&lt;p&gt;但作为独立课题组只有基础人才是不够的，课题组长一般都有一技之长。环境化学最容易耦合的学科是毒理学、污染控制与环境暴露。毒理学上的人才要对污染物致毒的分子机制玩的转，懂得基因修饰去验证被污染物影响的生物学过程，当然偷懒一点搞点QSPR研究下分子蛋白相互作用机制也是可以的，不过你得真的搞得明白从分子动力学到DFT那一系列的坑，你搞不明白没关系，別坑学生。当然，现代毒理学里急性慢性毒性实验、行为学表征还有流式细胞术什么的基本每篇文章都是标配，不是你的长处也别成为短处。更深入的组学技术如果不是基础够强，花钱找公司做，但数据分析要自己来，很多公司的数据处理技术还停在上个世纪。如果你是污染控制方向，污染物的降解热力学动力学自然要了解吧，拿个mopac算算前线轨道能也可以编出个不错的故事。如果你跑去做工艺养污泥颗粒，那目前似乎没点基因芯片也说不清楚降解机理了。如果你是大气环境化学方向，额，你似乎兼顾有点催化背景好一点。如果是土壤，怎么说也淋过土柱玩过同位素标记吧。如果你搞了个环境暴露方向，最好认识医院里那些缺论文升职称的大夫，随便搞点病人与健康人的样品测下污染物浓度就可能有不错的发现。如果你是公卫那边转过来的，搞点暴露组学配合流行病学研究会有不错的故事。如果你气象那边过来的，搞点气候变化对污染物迁移转化规律的影响也会不错。总之课题组长要会找到研究切入点与生态位，跟风怎么也要等你手头有资源再说，早期做出特色更重要。&lt;/p&gt;
&lt;p&gt;说了这么多你会发现现在要想做出点名堂多半是要靠合作的，很多技能不可能同时出现在一个人身上，多数课题组也一般只会关注到一个方向，但如果科学问题的解决需要多角度切入说明，那就拿出诚意去找合作者。环境科学本身就是面向问题出发的，而阐述问题的证据角度越多，结论越靠谱。同时，要不断从基础学科的理论与技术进展中汲取营养，一个学科里聪明人多，那么新思想出的就多，这些思想不仅可以解决这个学科里的问题，也可以解决其他学科的问题。在这一点上，物理、化学与生物的技术进展与计算机科学、统计还有数学的理论思想都值得关注。在那些聪明人比较多的学科里的人也可以搞个跨界，大家共同发展。这里面最明显的就是计算机科学对生物信息学与金融的带动，往往一个学科的进步暗含了其他学科进步的契机。如果你打算做点学术事业，到聪明人最多的学科里去学习，然后回自己的学科里发展。这里面最大的问题就是，一般聪明人多的学科工资要比不那么多的学科高，这时候就得把学术理想当鸡血用了。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;合作&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;合作&lt;/h2&gt;
&lt;p&gt;有两种做事态度，一种是做所有事都是从自己需求的出发，追求个人的功成名就，科研成果是垫脚石；另一种是从解决问题的需求出发，解决问题是唯一目标，个人名利是副产品。据我观察，两种态度都不影响个人成长与学科进步或退步，但后一种生活态度的人想的少一点，幸福指数要高一点。我个人喜欢面向问题解决问题，当然这个态度会让你不断得罪人你自己还意识不到，不过整体大脑负担小，睡得香。如果面向问题，一作可以不强求、首先发现也可以不要但问题要说明白与说清楚，把好的思想传播出去而不是跟宝贝一样藏着掖着，太阳底下没有新鲜事。这个态度另一个好处就是容易促成合作，如果合作可以成功就比各干各的的社会效益或学科贡献更多。&lt;/p&gt;
&lt;p&gt;很多人都知道囚徒困境里一个比较好的策略就是以牙还牙，但其实这个策略只是可以保证整体收益为零，如果想为正，最好的方法就是双方不断合作。以往的思路都是构建在把自己的课题组搞成巨无霸，目前国内主流就是如此，这样内部合作强于外部合作，容易稳定学术界地位，从这个角度看巨无霸课题组是可取的，我读博的中科院主流基本如此，配合良好的顶层设计可以攻坚克难。但目前来看，如果是一个新课题组长，这样搞一是根本就没那么多资源，二是新人初期很难招到理想的同事。所以此时的优势策略不应该依附大课题组，而应该是跟同龄人合作，在平等的基础上共同成长，面向问题解决问题。不要担心自己的技术被别人学走，别人学走正是说明这个技术有价值，没人学才是大问题。另外，早期技术跟别人合作推广了，你还可以开发新技术嘛，我从未见过有课题组靠一项保密技术可以维持30年的，而对于正常科研人员，30年差不多也该给后辈挪窝了。&lt;/p&gt;
&lt;p&gt;合作是没必要在办公室发生的，很多问题或思路有时候就是差一句话。印象中有公司就通过设计让员工的午餐排队时间控制在3～4分钟左右好让排队时员工能多交流，时间长了员工就出去吃，少了讨论不充分。合作甚至不用物理接触，现在实时通讯工具一大把，随时都可以交流。不过，搞成微信群那样就太花哨，也容易被朋友圈跟红包分散精力，用邮件列表功能又太单一，目前我组内用slack。一方面可以实时交流，另一方面通过区分频道可以针对主题或项目进行讨论协作，此外也可以作为个人项目管理与点对点交流工具。&lt;/p&gt;
&lt;p&gt;我猜的不错的话多数人看到这里也就停了，因为周围可能没有人用，不过万事都有个开头，我已经建立了一个slack主页：yufree.slack.com，欢迎大家给我发邮件slack at yufree.cn拿邀请尝试，不建议留邮箱，原因你懂的。可以当作一个即时交流组队平台的实验品，相互学习，共同进步。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>二十年博士延期之怪现状</title>
      <link>https://yufree.cn/cn/2017/02/19/phd-extend/</link>
      <pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/02/19/phd-extend/</guid>
      <description>&lt;p&gt;坊间有句话叫做“没有延期毕业的硕士，没有按期毕业的博士”，最近放长周末假，就抓了点数据探索了一下这个问题。（来自教育部网站公开数据http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/）&lt;/p&gt;
&lt;h2 id=&#34;研究生教育现状&#34;&gt;研究生教育现状&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/admitted.png&#34; alt=&#34;&#34;&gt;
这是最近20年研究生招生情况，可以看出硕士的扩招力度是远高于博士的，但两者都在扩，20年前一共6万多，现在仅博士每年录取就有7万多，硕士则扩张了10倍有余。
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/graduates.png&#34; alt=&#34;&#34;&gt;
这个则是研究生毕业状况，伴随扩招，每年招生人数与毕业人数有相当的差距，但比较吊诡的是博士招生在增长而毕业人数却趋稳了，这基本暗示延期的常态化。
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/enrolment.png&#34; alt=&#34;&#34;&gt;
通过在读人数我们也会发现，研究生这个临时身份群体在不断扩大，除了扩招影响，另一个自然就是前面提到的延期问题。&lt;/p&gt;
&lt;h2 id=&#34;延期现状&#34;&gt;延期现状&lt;/h2&gt;
&lt;p&gt;自从2003年起，教育部增加了下年预期毕业人数的数据，这样根据真实毕业人数，我们可以计算出当年延期的状况：
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/extend.png&#34; alt=&#34;&#34;&gt;
图上我们可以看出，基本上博士延期概率超过50%，硕士延期概率是个位数，也就是说“没有延期毕业的硕士，没有按期毕业的博士”这句话没毛病，而且延期超过50%的时间已经超过10年了。同时另一个现象也值得关注，那就是女性研究生的延期概率是普遍低于平均水平的，那么对应的男性研究生延期概率会更加惨不忍睹。&lt;/p&gt;
&lt;h2 id=&#34;延期会延多少年&#34;&gt;延期会延多少年？&lt;/h2&gt;
&lt;p&gt;上个问题我们可以看到延期情况是客观存在的，那么延多久就是另一个问题了。如果我们用在校生去除当年毕业生，会得到下面的恐怖结果：
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/meangrad.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;也就是说，博士需要6年多毕业而硕士也需要3年多毕业，硕士那个考虑到延期概率不高还可以接受，博士那个就有点反人类了，而且从近几年情况看这个毕业年限还在增加。其实答案很简单，就是扩招导致的人口在高校或研究机构的滞留，那么如何去除这个影响呢？考虑到博士硕士其实应该是2-4年内毕业，我们只要用当年录取的人数去对比2-4年后毕业的人数就可以了。结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/year2.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/year3.png&#34; alt=&#34;&#34;&gt;
&lt;img src=&#34;https://yufree.github.io/blogcn/figure/year4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;考虑到博士毕业率应该低于硕士且硕士毕业率不应该超过100%，应该是3年毕业的数据比较可信，但同时我们会注意到3年毕业率要远高于延期概率，这又是怎么回事？&lt;/p&gt;
&lt;p&gt;这里就没数据支持了，但我想大多数研究生都听过硕博连读这个概念，其实如果三年毕业为真，那么硕博加起来应该是6年，而硕博连读应该是5年，如果博士延期是常态化的，那么我想这里面很大一部分比例是硕博连读。估计再过几年，考博的比率可能会更低而硕博6年将成为默认的学习年限。有打算硕士毕业出国读博的可以考虑下了，年限上其实吃亏不多而且国外会有老板没钱了逼着早点毕业的情况。&lt;/p&gt;
&lt;h2 id=&#34;国内教职状况&#34;&gt;国内教职状况&lt;/h2&gt;
&lt;p&gt;刚才说了研究生毕业的供给端，下面看看需求端也就是教职的变化。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionall.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;国内教职因为99年开始的扩招导致在21世纪的第一个5年大量的扩展教职，这样的后果就是有一个5年的教职年龄高峰，这个高峰占据了大量的教职。从图上看，目前这个高峰年龄段在51-55岁，都算是当打之年，如果退休年龄没有明显推迟的话，那么在10-15年后应该可以看到一个因为退休高峰导致的教职空缺期。那么10到15年后谁博士毕业呢？大概是现在读中学的孩子，反正我老人家是赶不上了。其实考虑硕博6年加本科4年，每个高校都有义务在学生刚接触高等教育或研究时给他们领先当前技术10年的教材与方法，否则学生10年前选了小灵通网络优化专业，博士毕业基本就只有转行了。&lt;/p&gt;
&lt;p&gt;那么女性教职呢？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionallf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我只能说似乎女性教职前期扩张的要更厉害，平均年龄也更低，大概要20年左右才能迎来退休高峰的教职空缺，如果校方固定当前男女比，那么其实对有更低概率延期的女性并没有什么优势。此外，我们来看下教职中教授的年龄分布状况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionprof.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看出教授平均年龄会大一点，当前教授主流是51-55岁，反推下基本是刚改革开放后上的大学，经历应该挺丰富的。我们再看下副教授的情况：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionprofa.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以看出副教授整体要比教授年轻10岁，大概90年前后上大学，46-50岁这个年龄段人数基本稳定，说明升教授基本就是前一个年龄段，从年龄分布上看35-45岁人多，不同代际间竞争会激烈些。&lt;/p&gt;
&lt;h2 id=&#34;年教职数变化趋势&#34;&gt;年教职数变化趋势&lt;/h2&gt;
&lt;p&gt;前面着重强调年龄分布可能带来的教职空缺，另一种空缺就是所谓扩张期或窗口期，我们看下这个趋势，当然这个数没考虑退休，但从年龄分布上看这一部分的人数似乎比较稳定。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positiontrend.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;从教职数上我们可以看到，每年的教职数一直在提高，而是似乎斜率比较稳定。但是女性的教职数增长的回归斜率只有总数的1/3，也就是说每增长3个教职才会有一个是女性的，这说明教职市场存在一定的歧视。但这个问题不好直接下结论，因为辛普森悖论也是同样的语境。同时，教授与副教授教职增长的斜率低于总体，暗示了教职里存在的层级结构。&lt;/p&gt;
&lt;p&gt;总之，目前还算是一个稳定的窗口期，教职数不断增长，属于利好；但成长空间不算大，别忘了博士毕业生可是年年增长，所以以后熬年限是肯定不行的，31-35岁的副教授人数逐年下降，不是升迁（概率低）就是收紧了要求转而直接从海外引进人才，诸君努力吧。&lt;/p&gt;
&lt;h2 id=&#34;教职与博士毕业生供求&#34;&gt;教职与博士毕业生供求&lt;/h2&gt;
&lt;p&gt;首先，我们都知道研究生学历在贬值，那么究竟贬到什么状况了呢？我计算了同年毕业的博士与硕士人数比例，结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/phdvalue.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;很明显，硕士的贬值效果更强，博士相比之下反而在升值，女博士升值更高。当然，大前提是五十步笑百步，你懂的。基本的情况就是1个博士大概对应10个硕士，显然硕士作为一个学位扩的有点太猛了。后面的分析就不考虑硕士找教职了，基本没戏。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionphd.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;通过这个图（我赌一瓶胡椒博士教育部2000年的数据绝对有问题）我们可以看到新增教职数这些年基本稳定在2万这个水平，博士毕业生大概超过5万，也就是说教职市场在今后可预期的时间里撑死也就能解决一半博士的就业，另外有一半肯定会转行。考虑到博士学位对硕士学位是升值的，估计非教职市场上应该挺容易就业的，当然看你干不干了。&lt;/p&gt;
&lt;p&gt;我们进一步看一下女性教职，如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/positionphdf.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;很遗憾新教职里女性比例是低于人口比例的，但这二十年却一直在增长，同样在增长的则是博士毕业生中女性的比例，伴随这个趋势，教职里对女性的歧视似乎是要好于社会其他行业的。&lt;/p&gt;
&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;没有延期毕业的硕士，没有按期毕业的博士&lt;/li&gt;
&lt;li&gt;从上大学到博士毕业大概要准备10年人生最好的时光&lt;/li&gt;
&lt;li&gt;然后就进入了发展空间可预期的教职市场（掌握通过年龄分布推测的技巧）&lt;/li&gt;
&lt;li&gt;或者转行到业界，学历贬值速度低于硕士&lt;/li&gt;
&lt;li&gt;女性在博士延期可能性上低于男性，但在教职市场上存在歧视&lt;/li&gt;
&lt;li&gt;没有分专业讨论，我大体看了下数据，理工科延期概率显著高于其他专业，约70%-80%的延期率，医学最低（但他们本来年限就长）&lt;/li&gt;
&lt;li&gt;教育部应该给api的，网页数据格式乱七八糟，洗数据洗的我上火&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>读博士是否一定要做学术？</title>
      <link>https://yufree.cn/cn/2017/02/04/fermi-estimate/</link>
      <pubDate>Sat, 04 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/02/04/fermi-estimate/</guid>
      <description>&lt;p&gt;2015年全国博士毕业生5.4万人，而去年大概到了6万人，按照很多人的说法，读到博士就应该去做学术，但我对这个问题做了一个费米估计，结果比较有意思，列出来供各位打算做学术的博士参考。&lt;/p&gt;
&lt;p&gt;如果成为院士（中国科学院／中国工程院）算学术巅峰的话，那么院士的选拔可以看作到达顶峰的路径。选拔方法是什么呢？两年一次，一次总共大概150人，工程科学对半分，平均一年75人。&lt;/p&gt;
&lt;p&gt;我们假定若干年后每年还是75人，因为两院院士总规模这么些年并未有很大规模的变化，就算加上文科一级教授也就是100这个数量级。&lt;/p&gt;
&lt;p&gt;那么若干年后竞争这个数的人选平均看大概都是同年级的博士同学。目前每年全国土鳖博士毕业生6万多人，算上海归，同一年龄组大概7万人应该比较合理。&lt;/p&gt;
&lt;p&gt;那么你看到了，你需要在同年级博士毕业生里成为千分之一左右的精英才算有希望成为院士级别的学者。这个似乎有点丧气，可能院士这个比较难搞，那么准院士的杰青呢？全国每年选拔200人为杰青，那么成功概率乐观估计是千分之三，杰青其实也很难了，我们再放宽到优青。全国每年选拔400人为优青，那么乐观估计成功几率大概是千分之五。即使我们大胆认为博士有一半不从事科研工作，几率翻倍成为优青也要是百里挑一。&lt;/p&gt;
&lt;p&gt;也许你会说优青杰青比较遥远，那么教授或者正高不算遥远了吧，毕竟每个博士背后都有一个博导。那么全国博导能有多少呢，乐观估计6万，年龄分布从35岁到65岁，如果是均匀分布的话且保证65岁退休，那么每年能产生出2千正高岗位，除以当年大约7万的博士人数，这个比例不到百分之三。就算我把那些做学术但不培养博士的岗位算上，这个比例也不会超过5%。硕士毕业生15年大概50万，说明副高大概最多也就这个数，每年也就1-2万岗位，也就是说大概20%的博士最终能走到副高，其实这个比例也不算高，不过可以作为大多数人可以预想的目标。&lt;/p&gt;
&lt;p&gt;你可能会说做学术要有一定理想，不能这么功利，说这话的有相当比例站着说话不腰疼。如果你已经走到教授研究员这个档次自然可以跟人谈理想，但坦白说现在的博导平均拿到学位都是20年前的事了，那个时候博士一年毕业7千多人，而现在博士毕业生数目翻了10倍，换句话在目前的晋升条件下你成为教授的概率大概是50%，如果有一半不做学术，几乎可以肯定就是教授了。10年前一年博士毕业人数大概是现在的一半多，这意味着其晋升教授可能性也有十分之一，尚算合理。但10年后如果博士年毕业生达到10万，那么其成为教授将跟现在成为优青差不多难度，代际不平衡是十分严重的。不了解基础状况就把人往坑里带的后果挺严重的，自上而下，金字塔顶端人数就那么多，一味扩大底端几乎意味着大量博士要陷入无尽的博后循环之中去拉伸等级。&lt;/p&gt;
&lt;p&gt;所以其实我挺理解很多劝博士毕业转行的看法的，那怕你手握博士学位，目前在国内想走到教授也是个p&amp;lt;0.05的事，大概20个人里有一个。考虑到一般博士同学同院系大概也就是20个人，如果学术水平不在前面，基本可以重新考虑下人生规划了，因为此时你选择科研就真的需要兴趣激发了，不然身边的落差会折磨你几十年。而且上面的估计有个严重的问题，那就是大量使用了均匀分布，但真实的情况却是极不均匀分布，你的师承关系跟毕业院校都会把这个分布搞得更加极端，而且后发者优势在科研里面非常常见，但前面的坑都满了你怎么让后发者上？&lt;/p&gt;
&lt;p&gt;同时要注意，国内博士毕业生人数还在不断上升，一方面说明教职还是有空间的，另一方面则暗示了今后博士毕业生生存环境将会更加恶劣，竞争会更加激烈。同时，目前教职数目会逐渐趋稳，如果你没赶上新学科新方向的窗口期大爆发，基本就是始终要接纳这个竞争强度了，只会更强不会更弱。而且有些研究方向必然因为学科发展走向没落，没必要跟一伙老气横秋的人抱团取暖，该转方向就转，反正大家都没基础。&lt;/p&gt;
&lt;p&gt;读博转行可能也是个好事，早点把青春奉献到知识洼地去才更能实现自己的价值，相比学术界科研，业界科研可能是一个很好的选择，毕竟能磕下博士学位，搞点别的也应该没啥问题。&lt;/p&gt;
&lt;p&gt;同时，如果选择了科研道路也要知道上面的概率，当不成分子也可以先做分母，心态上说服自己静下心来做科研就OK了，乐在其中则何乐不为？切不可惶惶不可终日，空费时光。&lt;/p&gt;
&lt;p&gt;数据参考：http://www.moe.edu.cn/s78/A03/moe_560/jytjsj_2015/&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>现代科研人员的日常</title>
      <link>https://yufree.cn/cn/2017/01/27/modern-scientist-weapon/</link>
      <pubDate>Fri, 27 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/01/27/modern-scientist-weapon/</guid>
      <description>&lt;p&gt;8:00AM-9:00AM&lt;/p&gt;
&lt;p&gt;起床，吃早饭并准备午饭离开寓所。在公交上打开手机上rss阅读器，扫一眼生活文件夹看看有什么新闻或关注的博客，资讯一扫而过，长文发送到pocket里晚上处理。那个标注文献的文件夹是每周五下午组会后才需要清空已读的，虽然未读数字已经跳到100+了。一般而言，scinece、nature跟pnas上很少有本专业的论文，有的话也可以从别的渠道看到，rss会追踪本学科内top3的期刊跟自己研究方向的关键词，100%的论文会看题目与图形摘要，20-50%的论文会读摘要，5-10%的论文会读里面的图片，1-3%的论文读全文。&lt;/p&gt;
&lt;p&gt;9:00AM-9:30AM&lt;/p&gt;
&lt;p&gt;到达实验室，跟博后博士生硕士生打个招呼，然后打开内部交流用的slack，看到教授昨晚又分配了一个任务，分享了5篇刚发表的论文，三篇hashtag是ideas，两篇hashtag是experimental design，另外今天要跟一个博士生讨论课题A的进展，还要给另一个新进组的硕士生做内部培训，好在之前的资料都在课题组dropbox的共享文件夹里放着，先发给她吧，反正她也不会看。找到自己的channel，查了下今天要完成一个审稿，还要按照上次跟教授单独讨论（两周一次）的内容改下一篇初稿，另外下午要去准备后天实验的一些标准品。&lt;/p&gt;
&lt;p&gt;9:30AM-11:00AM&lt;/p&gt;
&lt;p&gt;审稿，老实说这篇论文新意不错，但数据处理上很诡异，画的曲线也没有解释，不知道拿什么拟合的，另外这电镜图太模糊了，补充下实验也好。作者用figshare分享了原始数据，写了个脚本跑了下，发现结果跟文章中一致，这点倒不错。平均审稿时间大概是6小时，1.5小时读明白，3小时检查细节，1.5小时写审稿意见，当然一般会分散到5天里去完成，所有意见都标注到了一个对应的google docs上防止忘记。审稿要么就快，要么就不审，将心比心。需要注意的是审稿记录一定要用Publons保存好，因为这也是积累学术声誉的一个重要途径。最近比较流行的Pubmed Commons也可以关注下，发表后审稿或评论将会是学术交流的新趋势。&lt;/p&gt;
&lt;p&gt;11:00AM-12:00PM&lt;/p&gt;
&lt;p&gt;对硕士生进行内部培训，内容包括介绍实验室内部交流软件slack的使用方法与资源获取、对外报告统一的演讲风格与logo、数据分析的模型使用偏好与原因、财务流程……因为之前有积累的培训资料，要求学生一周内掌握好“实验室语言”并会在下次组会安排一个自己背景介绍的报告作为验收。现在的实验室人员流动性大，重复培训有时会消耗大量精力，要逐渐收集留档之前培训或workshop的内容作为自学资料并设置验收，都是成年人了，没必要求着学，自学更新去吧。新人的培训是很重要的，但学校研究所都一直会有面上的培训邮件，实时转发就可以了，如果他不是打算混学位应该知道该怎么做。&lt;/p&gt;
&lt;p&gt;此外，新手科研人员要重视个人在线学术档案的管理，可以在researchgate或academia上注册并更新自己的学术档案并参与社区问答构建在线声誉，谷歌学术或百度学术的档案也要注意维护，因为它们的搜索优先级高。&lt;/p&gt;
&lt;p&gt;12:00PM-1:30PM&lt;/p&gt;
&lt;p&gt;午饭，饭后查阅邮箱，发现有人询问之前发表文章的数据处理细节，找到当时项目的github repo直接发过去，这些都会在发表后公开。另外发现自己researchgate关注的几个课题组也发表了新文章，当然很多跟教授早上发的比较重叠，也有些追踪的项目更新，biorxiv上关注的大牛也出了新的预印本论文。大概看看，在twitter上转发下有意思的论文。此时算作午休，不用研读，只要记录。另外回复邮件时尽量简短，不用太多客套话，要知道邮件正在逐渐被微信等新兴交流方式替代，关注你关注的问题。邮件里提到的待办事项直接记录到在线日历里设置提醒，然后就不要想了。&lt;/p&gt;
&lt;p&gt;1:30PM-2:30PM&lt;/p&gt;
&lt;p&gt;跟博士生讨论下在研课题的结果，总体结果不错，但需要补充几个实验。这个过程不是面对面的，因为这个博士生正在另一所高校访问，交流是通过谷歌环聊（国内可以用微信）与谷歌文档（国内可以用石墨）协作完成的，一边讨论一边修改协作文档里的报告，借助语音输入，讨论完了基本报告也成型了，共享给教授并在slack上项目channel里进行了记录。&lt;/p&gt;
&lt;p&gt;2:30PM-3:30PM&lt;/p&gt;
&lt;p&gt;论文修改，使用rstudio里rmarkdown进行论文写作，通过rticles包里的模版可以直接生成tex文档跟pdf。文献管理使用zotero，毕竟在线收集比较方便。习惯所见即所得的可以用谷歌文档配合paperpile，当然word跟endnote的组合也可以，看个人习惯。文献库要每周更新，按项目分组，这样可以提高效率。论文成稿后可以酌情放到预印本服务器上，这样可以一定程度避免出现审稿过程中的抢发。&lt;/p&gt;
&lt;p&gt;3:30PM-5:30PM&lt;/p&gt;
&lt;p&gt;准备后天实验，这是体力活，也是每天耗时间最多的，因为总有意外。不要把一天分给一件事，要把一小时分给一件事，专注处理一件事。&lt;/p&gt;
&lt;p&gt;5:30PM-6:30PM&lt;/p&gt;
&lt;p&gt;在slack里记录今天完成的事跟明天要做的事，跟人约时间讨论问题，第二次查看邮箱并回复邮件。&lt;/p&gt;
&lt;p&gt;6:30PM-8:00PM&lt;/p&gt;
&lt;p&gt;做饭吃饭，把pocket里存的文章用读文章模式去听。&lt;/p&gt;
&lt;p&gt;8:00PM-10:00PM&lt;/p&gt;
&lt;p&gt;继续公开课学习或读书，twitter上看看学术圈出没出事或者更新下自己博客介绍下刚发表的论文。每天这个时间的内容可以不重样，不论学习还是探索都无所谓。如果你长期保持一个学习探索习惯，你会发现每天能带来新知识的东西其实并不多，大都是各类老调重弹。&lt;/p&gt;
&lt;p&gt;作为一个研究人员，要学会跟互联网打交道，最好有个人网站或课题组网站（可以用blogdown快速搭建）与在线简历，不要总想着构建学术声誉，也可以考虑知识的传播，例如系统总结前沿科学问题，用bookdown做成一本各章节不断更新的书，用xaringan制作网页格式的教案幻灯片公布到网站上，会议报告可以上传到slideshare上。&lt;/p&gt;
&lt;p&gt;其实研究人员首先是人，在遇到问题时用谷歌百度也比较常见，如果经常看到你的东西无形中也形成了你的声誉。同时，虽然现在PI都是40岁以上的，但终究会成为80、90后这一代人的，而这一代人是伴随互联网成长的，其认知过程很依赖网上资源，所以类似quora、stackoverflow、reddit、知乎、果壳、科学网等网站都在实质上累积着科研人员的声誉，我就见过MIT一个课题组定向招博后，招到了还发个课题组新闻说我们欢迎XX领域的guru加入课题组，而那个被招的博后也确实在博士阶段就在在线社区里名声响当当了，而其博士毕业的研究所跟MIT完全不在一个水平上。&lt;/p&gt;
&lt;p&gt;10:00PM-12:00AM&lt;/p&gt;
&lt;p&gt;完全休息娱乐时间，玩局游戏，健个身，看个电影，刷个微博，看看朋友圈点个赞，每天的缓冲时间，然后就可以睡了。&lt;/p&gt;
&lt;p&gt;其实互联网一直在潜移默化地改变着很多行业，自然包括科研，熟练运用这些工具可能会获得效率上的提升并减轻焦虑感。我有时甚至在想，其实有远见的课题组应该可以开个公众号的，一方面传播自己成果，另一方面可以推送领域内新论文，要知道相比看综述，看推送更轻松，而且形成习惯后也能形成学科内大局观甚至引导科研前沿，这可比跑到一两年一次的学科内大会上听报告或做报告效果强得多。其实国外用twitter与hashtag就可以了，甚至有专门网站评价科研人员在社交网络影响力的，这种类型的影响力不容小觑，别忘了给科研人员发钱的人或许会看学术期刊，但一定会刷朋友圈。&lt;/p&gt;
&lt;p&gt;以上纯属胡扯，如有雷同，那就雷同吧。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>现代科研的兴起</title>
      <link>https://yufree.cn/cn/2017/01/22/modern-scientist/</link>
      <pubDate>Sun, 22 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2017/01/22/modern-scientist/</guid>
      <description>&lt;p&gt;今天先讲个论文故事，然后讨论下科研领域正在发生的信息化过程。&lt;/p&gt;
&lt;p&gt;2015年，在《美国国家科学院院刊》（也就是PNAS）上发表了一篇&lt;a href=&#34;http://www.pnas.org/content/112/49/15078.full.pdf&#34;&gt;论文&lt;/a&gt;，题目翻译过来是《提升中的21世纪中年非拉美裔美国白人的患病率与死亡率》。文章对比了1999年到2013年美国非拉美裔白人及拉美裔白人及六个发达国家（包括法国、德国、英国、加拿大、澳大利亚、瑞典）45到54岁人群的死亡率，发现只有非拉美裔美国白人的死亡率是在上升的，在进一步分析了死亡原因后，作者发现毒品、酒精中毒、自杀还有慢性肝硬化可能主导这种上升，同时教育水平越低，上升比例越快。&lt;/p&gt;
&lt;p&gt;这是一篇对左派跟右派都有利的文章，&lt;a href=&#34;https://www.nytimes.com/2015/11/09/opinion/despair-american-style.html&#34;&gt;左派&lt;/a&gt;认为是这些年福利政策减弱与传统宗教价值观的复兴造成的，加上这一段算是共和党小布什的主要执政期，自然锅是右派的。有意思的是，&lt;a href=&#34;https://www.nytimes.com/2015/11/08/opinion/sunday/the-dying-of-the-whites.html&#34;&gt;右派&lt;/a&gt;看到这个研究后也发话称这个锅恰恰是因为白人蓝领对工作、信仰还有家庭观念的缺失，而这个恰恰是传统宗教价值观所倡导的。好了我们不看左右互搏了，解释怎么来都行，但现象总该没问题吧？&lt;/p&gt;
&lt;p&gt;有问题。文章发表不久，知名话痨兼统计学家 Andrew Gelman 教授 在自己博客上对这个研究的数据进行了&lt;a href=&#34;http://andrewgelman.com/2015/11/06/correcting-rising-morbidity-and-mortality-in-midlife-among-white-non-hispanic-americans-in-the-21st-century-to-account-for-bias-in/&#34;&gt;重新分析&lt;/a&gt;，其实说“重新分析”是书面说法，真实的情况是对这一组数据进行了校正。因为 Gelman 教授注意到了一个简单到不能再简单的问题：你这个死亡率没有对年龄分布进行校正。&lt;/p&gt;
&lt;p&gt;原始数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/usnwm1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我来解释下这个校正，举例来说我有100个人年龄段在45到54岁，那么在这个15年的研究时间段里，每一年进入这个年龄段的人数应该是差不多一样的才好跟其他的地方去比。但恰恰这个年龄段包括了二战后的婴儿潮，也就是说，每年这个死亡率的基数在变，该年龄段整体平均年龄被拖大了，按照自然规律，年龄大本来就死亡率高。所以应该对每一年的数据除以其人数，也就是认为这个年龄段的人数应该差不多才合适。&lt;/p&gt;
&lt;p&gt;校正后数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/usnwm2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;额，从这个结果上看那个上升趋势就不明显了。 Gelman 教授进一步分析了其他国家数据，发现其他国家同年龄段死亡率校正后还是一直下跌，那么美国非拉美裔中年白人比较诡异的死亡率确实是存在的，也就是说原文主要结论没啥问题。然后Gelman 教授又想到会不会性别上有差异？然后得到了下面这个图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/usnwm3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;感情白人男性其实没怎么变，女性死亡率倒是一直在提高。然后Gelman 教授又计算了一下相对死亡率，用1999年为基准，看了下不同年龄段的&lt;a href=&#34;http://www.slate.com/blogs/bad_astronomy/2017/01/20/if_you_need_to_find_some_strength_saturn_s_moon_daphnis_may_help.html&#34;&gt;分布&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/usnwm4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;结果发现不仅仅45-54岁女性非拉美裔白人死亡率在上升，35-44岁这个年龄段也在上升。那么问题来了，为什么当初不去说这个年龄段呢？会不会原文属于一种发表歧视呢？也就是说对比了半天终于发现了一个显著的，而其实如果在处理数据时男女分开，这篇报道的题目会不会就成了“35-54岁女性非拉美裔白人死亡率在上升”呢？&lt;/p&gt;
&lt;p&gt;其实我讲这个故事对这个论文事实兴趣不大，我很好奇的是为什么这样的评论是以博客的形式出现的。传统学术界的交流一般依赖期刊论文与会议，但是动辄几个月的审稿时间是不是对成果交流的一种阻碍呢？诚然学术界绝大多数是要依赖出版物来获取声望，但其实有时候很多博客评论的深度与广度可能并不比3-5个审稿人的审稿意见低。&lt;/p&gt;
&lt;p&gt;回到这个案例，原论文的作者在另一个科学博客里回应了&lt;a href=&#34;http://nymag.com/scienceofus/2015/11/gender-controversy-over-white-mortality.html&#34;&gt;质疑&lt;/a&gt;，她声称研究过程中确实也考察了性别影响，但没有使用相对死亡率，为了不让读者被一大堆图表覆盖就没放到文章里。同时针对Gelman教授的论点，她重新分析后认为吸烟与否对这个年龄段男性女性死亡率差异起了重要贡献。但是她又说了如下的话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We spent a year working on this paper, sweating out every number, sweating out over what we were doing, and then to see people blogging about it in real time — that’s not the way science really gets done. . . . And so it’s a little hard for us to respond to all of the blog posts that are coming out. . . . And if this is all people shooting from the hip, I don’t think that’s any way to move science forward, to move the research forward.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也就是说，你们博客评论太草根，懒得理你。但数据的产生者或科学问题的提出者不应该同时也要是问题的正确解决者，有时候提供一个视角就很好了。可了解Gelman教授的人应该清楚，其哥伦比亚大学资深话唠身份不是白拿的，他马上就在博客上&lt;a href=&#34;http://andrewgelman.com/2015/11/15/why-is-it-so-hard-for-them-to-acknowledge-a-correction/&#34;&gt;回应&lt;/a&gt;了这样一封应该来自作者的虚构的信来表明博客这种交流方式其实也应该被科研人员尊敬而不是故作清高姿态：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We spent a year working on this paper, sweating out every number, sweating out over what we were doing, and we’re happy to see see people blogging about it in real time.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We very much appreciate the effort put in by Laudan Aron, Lisa Dubay, Elaine Waxman, and Steven Martin, Philip Cohen, and Andrew Gelman to uncover the aggregation bias in our analysis, to correct for that bias, and to explore subtleties that we did not have a chance to get into in our paper. As Gelman noted, these corrections are in no way a debunking of our work—our comparisons of non-Hispanic American whites to groups in other countries and other ethnic groups still stand.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;We think it’s great that, after our paper was published in PNAS, it was possible to get rapid feedback. Had it not been for bloggers, we’d still be in the awkward situation of people trying to trying to explain an increase in death rates which isn’t actually happening. We join Paul Krugman and Ross Douthat in thanking these bloggers for their unpaid efforts on the behalf of everyone interested in this research. We count ourselves lucky to live in an era in which mistakes can be corrected rapidly, so that we and others do not have to wait months or even years for published corrections which themselves could contain further errors.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;As economists, we recognize that research work is always provisional, and that anyone studying the real world of human interactions has to accept that mistakes are part of the process. It is only through the efforts of our entire research community—publishing in journals, publishing in blogs, through informal conversations, whatever—that we move toward the truth. We always considered our PNAS paper to be just a single step in this process and we are glad that others have taken the trouble to correct some of our biases and omissions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Again, we thank the many researchers who have taken a careful look at our analyses. It’s good to know that our main findings are not affected by the corrections, we welcome further research in this area, and we hope that future discussion of our work, both in the scientific literature and in the popular press, make use of the corrected, age-adjusted trends.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;– Sincerely, Anne Case and Angus Deaton&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;P.S. We have heard some people criticize the researchers noted above because they published their work in blogs rather than in peer-reviewed journals. We would never make such a silly, uninformed criticism. Since appearing in print, our work has received a huge amount of publicity. And, to the extent that we made mistakes or did not happen to explain ourselves clearly enough, it is the responsibility of others to publish their corrections and explanations as rapidly as possible. Blogs are a great way to do this. Blogs, unlike newspaper interviews, allow unlimited space to develop arguments and to present graphs of data. And we are of course aware that peer-reviewed journals make mistakes too. We published our paper in the Proceedings of the National Academy of Sciences, a journal that last year published a notorious paper on himmicanes and hurricanes, another discredited paper claiming certain behavior by people whose ages end in 9, and another paper on demographics which neglected to apply a basic age adjustment. So, yes, publication in journals is fine, but we very much welcome researchers who are willing to stick out their necks and correct the record in real time on blogs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;当然，Gelman教授的火爆脾气自然也会招来一些&lt;a href=&#34;http://noahpinionblog.blogspot.ca/2015/11/gelman-vs-case-deaton-academics-vs.html&#34;&gt;不满&lt;/a&gt;，但是我认为有些观点是很有益处的。&lt;/p&gt;
&lt;p&gt;博客，作为一种快速的回应方式，理应被尊重，因为科学发展就是要依赖这样的过程才能快速进步。说白了，现代科学研究不再是躲在黑暗小实验室里的勤勉钻研，更应该是一个交流碰撞的过程。最近几年，预印本服务器已经在物理、计算机跟生命科学领域大力发展，很多科研报道的记者跟前沿课题组都盯着。同时，基于博客还有微博（当然不是你熟悉的那个娱乐版）对科研成果的讨论也逐渐成为一种风气。数据共享、媒体传播、在线学术档案也逐渐成为青年科学家累积学术声誉、寻找业界合作的方法。严肃的学术讨论可以发生在任何地方，态度而不是场景产生严肃感。我们可以逐渐看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;大量高质量的问答、博文及报告幻灯片共享其实正在自发地形成一本本最新的网络教材&lt;/li&gt;
&lt;li&gt;计算机领域里最新的算法很快就会有博文告诉你如何去用并出现一个对应的github repo&lt;/li&gt;
&lt;li&gt;这边刚上传了一个物种基因组数据，那边某课题组集群上的自动化脚本就能生成一份报告email到课题组成员的邮箱里&lt;/li&gt;
&lt;li&gt;微博上传阅的最新研究成果很快就被reddit上的匿名专家进行了通俗化解读与评论并发现了新现象&lt;/li&gt;
&lt;li&gt;某公司苦苦追寻的最新技术操作过程竟然在直播平台被前沿科研人员作为论文发表的一部分所展示&lt;/li&gt;
&lt;li&gt;某个博士生意外收到某大牛课题组长的报告邀请，只因为他读了这个学生的博客，感觉他对某个领域的理解很有特色&lt;/li&gt;
&lt;li&gt;……&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以躲在象牙塔里不知道，但这一切都在发生，或许它目前不“正式”，但解决科学问题更应该依赖快速的良性公开交流而不是论文被发表，那终归只是个起点，现代化的科研方式正在兴起。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>清洁空气法案的故事</title>
      <link>https://yufree.cn/cn/2014/10/17/history-of-clean-air-act/</link>
      <pubDate>Fri, 17 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2014/10/17/history-of-clean-air-act/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;看图，这是加拿大科学家 Aaron van Donkelaar 与 Randall Martin用&lt;a href=&#34;http://www.nasa.gov/topics/earth/features/health-sapping.html&#34;&gt;NASA&lt;/a&gt;卫星遥感数据做出的图，相关文章发表在&lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2898863/&#34;&gt;《环境健康与展望》&lt;/a&gt;上。该研究首次把全世界的PM2.5状况来了个大曝光，抛开遥感数据在预测PM2.5上的技术细节不谈，相信大家都看到那个红得发紫的地方了吧。别紧张，打开随意一个预报空气质量的网站查下数据，80在我国不算严重污染的，超过75不到115那叫轻度污染（新标准，老标准里只有PM10的）。另外这是2001到2006年的数据，那年头各位可能还没听说过PM2.5是个啥，没关系，现在我们已经知道了，这是中国人民的老朋友。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://class.coursera.org/chemhealth-001&#34;&gt;Coursera&lt;/a&gt;上开了一门讲化学品与健康的课，这周讲到了米帝的清洁空气法案，这里以史为鉴的聊聊。环境口科班出身不知道八大污染事件的应该比较少，那八个在我印象中带着译制片翻译腔的事件中有五个是大气污染相关的，两个是重金属，一个隶属持久性有机污染范畴。所以，翻旧账的话我们今天的空气不过老牌资本主义国家几十年前的重演，在那个电话跟电报是主流通讯手段的时代，没有那么多的数据让你早上起来一看就心情变坏。所不同的是，我们大概已经清楚自己处在一个几十年后被认为严重环境污染事件之中，用老掉牙的话说就是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;生活中只有一种英雄主义，那就是在认清生活真相之后依然热爱生活。——罗曼•罗兰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其实不管装不装英雄，热不热爱生活，反正真相已经满朋友圈都是了，躲都躲不开。那就看看危害吧：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这是10年导致疾病外在风险的前20及其对寿命的影响的图示，该研究发表于&lt;a href=&#34;http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(14)60844-8/fulltext&#34;&gt;《柳叶刀》&lt;/a&gt;，顺带一提，有晚上睡不着的同学可以数数这篇文章的作者。睡得着的我们看看那两个箭头，一个是室内固体燃料燃烧造成的空气污染（做个烧煤的厨子也是要折寿的），另一个是室外颗粒物污染，这哥俩都进了前十。所以基于数据我们可以说空气污染不是好东西。&lt;/p&gt;
&lt;p&gt;但一开始我们只能看到污染问题或事件，对其研究又是如何进行的呢？我们看看米帝走的路：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这也是环境科学的研究历史概述，一开始大家都是做调查看现象去确认究竟某种污染物是否产生了危害。有人会说都死人了还说这没用的，但科学研究要求严谨，要控制变量去从现象数据中提炼主要因素去控制，去进行实验室随机试验，这样的结果大概是科研人员认为靠谱的。第二阶段是相关毒理学研究与暴露评价，确定污染组分的效应与环境暴露水平，基于此进行风险评价。这里要说清楚，确定某种污染物的环境暴露水平与危害是科学问题，但风险评价不是自然科学问题，属于决策与管理问题。第三阶段就着手控制了，这一阶段要解决来源问题，另一个需要解决的问题就是复合毒性问题，也就是说你搞清了其中一种或几种组分的危害，他们实际是否能产生危害是需要另外考察的，可能有增强，也可能有拮抗。&lt;/p&gt;
&lt;p&gt;米帝在这个过程中就通过了《清洁空气法案》，制定了一系列的标准来阻止空气污染，这个法案算的上科技导向的典范，法案中明确规定各州政府与联邦环保署（EPA）要参照最新的科研成果，现在你去&lt;a href=&#34;http://www.epa.gov&#34;&gt;EPA网站&lt;/a&gt;转转，你关心的环境问题或污染物大都有专题介绍，下面会有一列参考文献与数据图表都印证了科技导向的原则。你可以自行对比下环保部的&lt;a href=&#34;http://www.zhb.gov.cn&#34;&gt;网站&lt;/a&gt;，你大概可以找到不少验收报告列表，但单纯把项目报告没有整合的放到一个分类下很形式化，专业程度也很差。我们的科学家在政府资助下明明发表了很多高水平文章，却没有把这些发现很好的展示出来，结论都让别的国家拿去借鉴了。法案是不断修订的，也就是具备反馈作用，方法有效果就坚持，与时俱进也很重要，毕竟技术进步每天都在发生。&lt;/p&gt;
&lt;p&gt;那么这个《清洁空气法案》究竟管不管用？要知道有标准就有牺牲，实用观点上看不能做亏本的买卖。结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，米帝的GDP，人口，能源消费，机动车都增长了，但氮氧化物，硫氧化物，一氧化碳及挥发性有机物的排放都下降了。其实不止米帝，你有兴趣可以查下我国的这20年的数据，也是下降的，除了PM2.5跟PM10。因为国内控硫控硝其实开展的也不晚，技术上也有保障，但这PM10与PM2.5的控制技术其实技术也应该是成熟的，但估计经济上不合算或现行产业能源结构有问题，但从前景看，只要法规严格，还是很不错的。&lt;/p&gt;
&lt;p&gt;但标准都是有假设的，浓度越低影响越小，但这个正相关是不是线性还是需要研究的，这又回到了风险评价，现行清洁空气法案修正的难点也在这里：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;降低同样浓度降低的风险在不同浓度尺度下是不一样的，这笔账一般是决策者自己去算，里面的文章比较多。&lt;/p&gt;
&lt;p&gt;最后来点直观的数据：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/caa6.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;这是米帝，三三，天朝2010年因颗粒物污染致死的数据，123万，且不论数据真实性，我们确乎已经在一个严重的污染的历史事件之中了。&lt;/p&gt;
&lt;p&gt;现在北京空气污染指数195，窗外朦胧，这个无风无雨无奥运的周末又出不去了。&lt;/p&gt;
&lt;p&gt;（图片主要来自课程讲义与相关论文）&lt;/p&gt;
&lt;p&gt;===&lt;/p&gt;
&lt;p&gt;10月26日凌晨补充&lt;/p&gt;
&lt;p&gt;这篇吐槽写于上周五，一个周没动静，到了这周五突然收到关注，里面确实有不严谨的地方，恕不一一回复，前面有一篇雾霾问答可供参考，以下重点回复几个疑问：&lt;/p&gt;
&lt;p&gt;1 关于致死人数&lt;/p&gt;
&lt;p&gt;该图下方有数据出处，我也有怀疑，因为没有看到同行评议的论文支持也不能多说什么。个人观点，即使不看另外两国数据，这个数字也不算小了。&lt;/p&gt;
&lt;p&gt;2 关于法案的作用&lt;/p&gt;
&lt;p&gt;欧美这些年污染物降下来不见得是技术多好，监管多严，一个重要因素是产业结构变了，污染大户都转到别的国家了，所以清洁空气法案的作用要放到大环境下看，我主要是很欣赏EPA科技导向的原则。&lt;/p&gt;
&lt;p&gt;3 哪种污染更严重&lt;/p&gt;
&lt;p&gt;我之前回答过关于地下水砷污染的问题，老实说，科研人员想拿钱做研究都会把自己的研究领域说的危害巨大才能引起重视拿到经费，这点国内国外都一样，把其中危害摘一段给媒体渲染下就可能失真。水，气，土壤都是环境介质，产生危害的是其中某些污染物的单独或联合作用，所以老生常谈的话就是剂量决定效应。这里的剂量是指污染物的暴露剂量而不是含量，有些污染物毒性很高但一进入环境就降解了，还有些本身毒性不高但一降解毒性就高了，还有些浓度高但生物有效性低，所以问题很复杂，得具体去看。&lt;/p&gt;
&lt;p&gt;4 氮氧化物一氧化氮的控制&lt;/p&gt;
&lt;p&gt;燃煤脱硫脱硝与汽车尾气脱硝等技术确实在国内是推行的，相信很多人是有体会的，这些指标都是单一成分，技术专一性强，相对容易。PM2.5它就不是一个成分固定的东西，更麻烦的是它属于二次污染物，也就是很多一次污染物在外界环境相对应的气象条件下转化生成的，所以控制这玩意机理复杂，目前搞不清。至于说PM2.5源控制技术是否成熟，我没做过深入调查，结论可能有问题。&lt;/p&gt;
&lt;p&gt;5 PM2.5的纬度问题&lt;/p&gt;
&lt;p&gt;观察很仔细，你有兴趣可以去看下原文。个人观点，由于PM2.5生成需要外部气象条件允许，有些地方如热带地区可能自然清除可能比较快，还有些地方例如撒哈拉那里的PM2.5基本来自沙漠扬尘，跟工业国家产生的PM2.5成分不一样，排除掉同一纬度有沙漠的地方剩下的基本都在工业区了。&lt;/p&gt;
&lt;p&gt;6 关于环境伦理&lt;/p&gt;
&lt;p&gt;这个我了解不多，但如果没有技术进步，自然环境是无法负担太多的人类需求的。技术受限下，你不太可能同时享受高能耗的现代生活与优良的环境质量。如果能耗意味着环境质量的下降，那么这是一个零和博弈，你享受了就有人享受不到。现在基本是发达国家在享受，而技术进步的话，是有可能都享受得到的。但仅仅技术进步也不够，还得考虑经济什么的，也是个说不清的问题。&lt;/p&gt;
&lt;p&gt;本人水平有限，各位如从事相关研究还请赐教，谢谢！&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>动态报告与可复算性研究简介</title>
      <link>https://yufree.cn/cn/2014/07/23/reproducible-research-0/</link>
      <pubDate>Wed, 23 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2014/07/23/reproducible-research-0/</guid>
      <description>&lt;p&gt;科学研究的一个基本要求就是可重复（Replication），但很现实的一个问题就是不是每个实验都可以被重复。有很多研究是一锤子买卖的，例如测试某种污染物毒性的动物暴露实验，一个实验周期3到6个月，独立研究人员重复三次加上写文章发表的过程要2年，这时候如果另外有独立课题组也想重复这个实验，时间成本与资源成本是很不合算的，而且重复别人工作的项目你很难拿到基金去支持，后续发表也可能因新意不足被拒稿。实际点说，脑子不进水的研究组是不会轻易去重复一个理论上可重复，耗用时间人力经济成本高而实际意义又不那么明朗的实验的。很多大项目或者研究人员想知道的问题很有可能全世界独一份，例如探月，探火星，当前技术条件下除了研究人员自己的重复也很难找到另一份可参考的报告来评价这个工作，这就是可复算性研究（reproducible research）出现的第一个背景。&lt;/p&gt;
&lt;p&gt;第二个背景就是当今实验数据处理本身已经也存在重复性问题，例如原来搞测序跑胶，几个月才能搞明白一个蛋白序列，现在有组学技术，你搞个二代测序，分分钟（夸张，实际也得几天）搞定单体基因组。但与几十年前不同的是，原来你是带着问题找答案去设计实验，现在技术进步了，一下出来一堆数据，而这一堆数据里面你的问题可能解答了，但也可以去解答另一些问题，甚至面对同一批数据，不同研究组可能得到不同的结论。这个问题的核心就是数据处理步骤也需要可重复性。杜克大学有过一个很有名的&lt;a href=&#34;http://blog.revolutionanalytics.com/2011/09/why-you-should-care-about-reproducible-research.html&#34;&gt;案例&lt;/a&gt;，一个进入到临床阶段的抗癌药物被发现在离体实验阶段被标错了号，也就是后面三年的工作都是无用功，这个损失是很大的，而且问题并非出现在实验阶段，而是数据处理过程的失误。据此，约翰霍普金斯大学的Roger D. Peng副教授就在science上&lt;a href=&#34;http://www.sciencemag.org/content/334/6060/1226&#34;&gt;撰文&lt;/a&gt;提出，不妨假定实验操作是正确的，让研究人员提供公开的原始数据，这样一方面我们可以对数据处理过程进行验证，另一方面也说不准能从原始数据中发现新的问题或现象。这样当论文作者提供了原始数据与处理代码后，其他独立研究人员可以直接去评价代码质量。在实验流程越来越标准而数据量越来越大的今天，数据处理的解释与可重复其实对于整体可重复性来说就成了关键一环。这是可复算性研究（reproducible research）的时代背景。&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;并非所有结果都可以重复&lt;/li&gt;
&lt;li&gt;当前数据维度增高可被整合入更大的数据集进行重复检验与挖掘&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;可复算性研究（其实有时也被翻译为可重复性研究）关注的重心在得到数据后的阶段，也就是从得到数据到文章发表的阶段。平时我们能看到的是图，表及文中的数据描述，这些算是数据可视化的部分，产生这些数据描述需要对原始测量数据进行预处理，分析与计算，每一步的处理代码脚本都应该随文章与原始数据一同发表或提交给审稿人进行评估，这样可以最小化数据产生后的问题。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://yufree.github.io/blogcn/figure/researchpipeline.png&#34; alt=&#34;处理流程&#34;&gt;&lt;/p&gt;
&lt;p&gt;前面谈的是可复算性研究的起源与概念，而真正意义上的实现需要依赖动态报告系统。动态报告是文学编程（Literate programming）的产品，而文学编程思想是Tex语言的开发者高纳德提出的。现在我们把这些概念一个一个串起来。&lt;/p&gt;
&lt;p&gt;文学编程不同于结构化编程，简单说就是像写故事那样解释程序以便清晰的描述程序逻辑，具体点就是类似伪代码，但包含真正代码的文本报告，其中的代码可通过编译执行并返回结果。典型代表&lt;a href=&#34;http://cos.name/2010/11/reproducible-research-in-statistics/&#34;&gt;Sweave&lt;/a&gt;，你可以在用Tex写文本的同时混杂R代码段，用特定的符号注明，然后用Sweave处理文本生成PDF报告时你的R代码会同时被执行并可在正文中调用这个结果。&lt;/p&gt;
&lt;p&gt;这样的报告也是动态的，例如，我在R代码里用数据A生成一个模型并返回了一个参数，我就可以在正文中调用这个参数名，这样，当我把数据A换成数据B时，我只需修改R代码就可以了，这样一份数据A的报告瞬间就变成数据B的报告了。在谢益辉的&lt;a href=&#34;yihui.name/knitr&#34;&gt;Knitr包&lt;/a&gt;问世后，这个动态多了另一重含义，那就是真正基于html5的动态交互图形，这个后面会专门有文章去讲。&lt;/p&gt;
&lt;p&gt;那么，动态报告与可复算性研究的联系是什么呢？利用动态报告系统，特别是knitr，我可以同时将研究论文与数据处理整合到一个文本里去。什么样的文本呢？越简单越好，不是每个人都喜欢Tex，但5分钟内上手Markdown我认为还是不难的。混合什么样的代码呢？个人觉得R在数据分析上应是不二之选。将这两者结合生成的文本能不能有程序处理呢？有，就是R中的knitr包，它完美支持R与markdown的混合。这样，你只需写一个混合R与Markdown的文本并将R代码标记出来，knit一下就可以处理得到或PDF或word或html的论文，甚至你可以配合&lt;a href=&#34;http://johnmacfarlane.net/pandoc/&#34;&gt;pandoc&lt;/a&gt;将Rmarkdown文本转化为任意你熟悉的格式。由于Rmd文本中清晰的描述了你的数据处理过程与图片表格的生成过程，作为读者可以很轻松的评价你的工作，进而避免大量对数据处理过程的质疑，如果你投过稿，对这种质疑应该不陌生。这样可复算性研究就可以说利用动态报告实现了，当然，动态报告的功能要远比可复算性研究的要求强大的多。&lt;/p&gt;
&lt;h2 id=&#34;动态报告&#34;&gt;动态报告&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可重复性研究的实现系统&lt;/li&gt;
&lt;li&gt;动态报告的生成需要原始文本（混合数据处理代码的文本如Rmarkdown）与处理引擎（knitr）&lt;/li&gt;
&lt;li&gt;knitr的出现极大程度方便了动态报告的生成&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OK，介绍完动态报告再推荐一个IDE：RStudio，目前&lt;a href=&#34;http://rmarkdown.rstudio.com/&#34;&gt;RStudio&lt;/a&gt;对动态报告系统（knitr与pandoc）的支持应该是最好的没有之一。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PLOS ONE 别叠被子了</title>
      <link>https://yufree.cn/cn/2014/03/16/plos-one-quilt/</link>
      <pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2014/03/16/plos-one-quilt/</guid>
      <description>&lt;p&gt;传说有一种机制叫做同行评议，经过了这关发表的文章都有一定学术价值。又传说有一种同行评议的开放获取的期刊，只要你给钱就能发表（夸张，真的是夸张）。不不，不是影射plos one，相反，我个人非常看好plos one或scientific reports这类开放获取的同行评议期刊，拿国家的钱做科研，结果不涉密当然应该让公众看到，不然总是自家圈子捧丑脚也没什么意思。但不能因为受众更广泛就降低标准，今年1月，plos one上这篇文章实在让人大跌眼镜，这就是多少土鳖魂牵梦绕的s(tupid)-c(hinese)-i(ndex)。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0085047#pone-0085047-t001&#34;&gt;PLOS ONE: Quilt Plots: A Simple Tool for the Visualisation of Large Epidemiological Data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;简单说，作者说我发现一种不错的数据可视化方法，原来我们搞流行病学，都是列联表，太不直观，应该用颜色深浅来表示列联表的频率数据，还为此起了个很形象的名字：被子图。为了高大上，还写了个R包，里面就一个函数quilt().这个包连r-core都没搭理，却过了plos one审稿人跟编辑的审核。&lt;/p&gt;
&lt;p&gt;但想法还是很好的，不过怎么如此眼熟？心中弱弱的问下：这货跟heatmap有区别吗？好，来看下discussion：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Quilt plots” can be considered as a simple formulation of “heat maps”. They produce a similar graphical display to “heat maps” when the “clustering” and “dendrogram” options are turned off. In addition, “quilt plots” have several advantages over “heat maps”. Firstly, unlike “heat maps”, “quilt plots” come with easily understood R-functions (i.e. plot, legend and color). In addition, R is freely available software and supported by leading statistical experts around the world, and it is important to promote the use of this software among epidemiological researchers. In addition it is difficult to learn to use R compared to other statistical packages. For example, “heat maps” require the specification of 21 arguments including hierarchical clustering, weights for re-ordering the row and columns dendrogram, which are not always easily understood unless one has an extensive programming knowledge and skills. One of the aims of our paper is to present “quilt plots” as a useful tool with simply formulated R-functions that can be easily understood by researchers from different scientific backgrounds without high-level programming skills.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不翻译了，太直白了。作者说的很清楚：绝对不是heatmap，是heatmap的简化版。等等，有点不对劲，heatmap也是R写的，被子图也是R写的，哪里简化了？前面说被子图适合科研人员使用不反对，怎么后面又说R很难学？被子图不就是R写的吗？运行也要在R里敲代码的！这篇文章的逻辑实在太强大了，重新发明阉割版轮子不说，还说完整版轮子不好用，作为开车的，有那学阉割版的工夫，完整版早搞明白了。&lt;/p&gt;
&lt;p&gt;问：如何把一个期刊搞臭？&lt;/p&gt;
&lt;p&gt;答：拿被子捂捂就可以了。&lt;/p&gt;
&lt;p&gt;参考文献&lt;/p&gt;
&lt;p&gt;A mathematical model for the determination of total area under glucose tolerance and other metabolic curves. M.M. Tai. Diabetes Care, Vol 17, Issue 2 152-154&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ELEMENTARY RULES OF USAGE脱水版</title>
      <link>https://yufree.cn/cn/2014/02/19/teos/</link>
      <pubDate>Wed, 19 Feb 2014 00:00:00 +0000</pubDate>
      
      <guid>https://yufree.cn/cn/2014/02/19/teos/</guid>
      <description>&lt;p&gt;如有侵权，请&lt;a href=&#34;mailto:yufreecas@gmail.com&#34;&gt;转告&lt;/a&gt;，得到通知后24小时内删除。&lt;/p&gt;
&lt;h2 id=&#34;名词所有格&#34;&gt;名词所有格&lt;/h2&gt;
&lt;p&gt;一般加&amp;rsquo;s，以下为例外&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于以-es与-is结尾的名词用of
&lt;ul&gt;
&lt;li&gt;the heel of Achilles&lt;/li&gt;
&lt;li&gt;the laws of Moses&lt;/li&gt;
&lt;li&gt;the temple of Isis&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Jesus’&lt;/li&gt;
&lt;li&gt;for conscience’ sake&lt;/li&gt;
&lt;li&gt;for righteousness’ sake&lt;/li&gt;
&lt;li&gt;hers, its, theirs, yours与oneself无所有格&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;列举三个或更多名词除最后一个外用逗号分割&#34;&gt;列举三个或更多名词除最后一个外用逗号分割&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;商店名最后一个逗号用and替代&lt;/li&gt;
&lt;li&gt;etc.前面要有逗号，哪怕只有一个词&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;插入语用逗号分割&#34;&gt;插入语用逗号分割&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;只要使用，必须成双配对&lt;/li&gt;
&lt;li&gt;非限制定语从句（一般指which， when， where从句）要用逗号分割&lt;/li&gt;
&lt;li&gt;限制性定语从句不用分割&lt;/li&gt;
&lt;li&gt;etc. jr.前面要有逗号，但前面一个词用在句末可以不用&lt;/li&gt;
&lt;li&gt;两个用连词连接句子中间的插入语前面的逗号要放到连词之前
He saw us coming, and unaware that we had learned of his treachery, greeted us with a smile.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;在and或but之前用逗号来引导子句&#34;&gt;在and或but之前用逗号来引导子句&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可避免使用连词用介词或不定式表示较强的关系&lt;/li&gt;
&lt;li&gt;两段式句子更容易懂，用在非正式问题减轻读者阅读压力&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;不要用逗号连接独立子句&#34;&gt;不要用逗号连接独立子句&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;独立子句用分号连接&lt;/li&gt;
&lt;li&gt;可以直接用句号分拆也可以&lt;/li&gt;
&lt;li&gt;accordingly, besides,so, then, therefore或thus等副词引导从句，用分号分割
I had never been in the place before; so I had difficulty in finding my way about.&lt;/li&gt;
&lt;li&gt;避免使用so，会导致滥用，不如改用as提到前面去
As I had never been in the place before, I had difficulty in finding my way about.&lt;/li&gt;
&lt;li&gt;如果句子很短，可考虑用逗号
The gate swung apart, the bridge fell, the portcullis was drawn up.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;不要把一体的句子用句号打断&#34;&gt;不要把一体的句子用句号打断&lt;/h2&gt;
&lt;h2 id=&#34;分词的主语要确定&#34;&gt;分词的主语要确定&lt;/h2&gt;
&lt;h2 id=&#34;句尾断词要按照词的组成或发音来切割&#34;&gt;句尾断词要按照词的组成或发音来切割&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;词组成
know-ledge (not knowl-edge)
Shake-speare (not Shakes-peare)
de-scribe (not des-cribe)
atmo-sphere (not atmos-phere)&lt;/li&gt;
&lt;li&gt;元音分割
edi-ble (not ed-ible) propo-sition
ordi-nary espe-cial
reli-gious oppo-nents
regu-lar classi-fi-ca-tion
deco-rative presi-dent&lt;/li&gt;
&lt;li&gt;双字母分割 除非简单词的分词
Apen-nines Cincin-nati
refer-ring tell-ing&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;elementary-principles-of-composition&#34;&gt;ELEMENTARY PRINCIPLES OF COMPOSITION&lt;/h1&gt;
&lt;h2 id=&#34;段落为创作单元一个主题一段&#34;&gt;段落为创作单元，一个主题一段&lt;/h2&gt;
&lt;h2 id=&#34;段落开头点明主题结尾呼应开头&#34;&gt;段落开头点明主题，结尾呼应开头&lt;/h2&gt;
&lt;h2 id=&#34;使用主动语态&#34;&gt;使用主动语态&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;刷存在感&lt;/li&gt;
&lt;li&gt;被动语态不能取消掉主要动词的表述&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;主张用主动语态&#34;&gt;主张用主动语态&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;避免无意义、表意不清及含糊的表述&lt;/li&gt;
&lt;li&gt;避免not，阅读不悦
not honest &amp;lt;-  dishonest
not important &amp;lt;- trifling
did not remember &amp;lt;- forgot
did not pay any attention to &amp;lt;- ignored
did not have much confidence in &amp;lt;- distrusted&lt;/li&gt;
&lt;li&gt;非not的否定词表意强烈&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;避免无意义的词&#34;&gt;避免无意义的词&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;the question as to whether  &amp;lt;- whether (the question whether)
there is no doubt but that  &amp;lt;- no doubt (doubtless)
used for fuel purposes  &amp;lt;- used for fuel
he is a man who  &amp;lt;- he 
in a hasty manner  &amp;lt;- hastily
this is a subject which  &amp;lt;- this subject
His story is a strange one.  &amp;lt;- His story is strange.
owing to the fact that since (because)
in spite of the fact that  &amp;lt;- though (although)
call your attention to the fact that  &amp;lt;- remind you (notify you)
I was unaware of the fact that  &amp;lt;- I was unaware that (did not know)
the fact that he had not succeeded  &amp;lt;- his failure
the fact that I had arrived  &amp;lt;- my arrival
His brother, who is a member of the same firm His brother,  &amp;lt;- a member of the same firm
Trafalgar, which was Nelson’s last battle Trafalgar,  &amp;lt;- Nelson’s last battle
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;避免连续的大长句&#34;&gt;避免连续的大长句&lt;/h2&gt;
&lt;h2 id=&#34;相近的想法用相近的句式&#34;&gt;相近的想法用相近的句式&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;表意相近，句式统一&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;相关词放到一起&#34;&gt;相关词放到一起&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;从句不要放在主要动词之前&lt;/li&gt;
&lt;li&gt;主谓宾结合方便阅读&lt;/li&gt;
&lt;li&gt;代词紧贴主语&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结中时态要统一&#34;&gt;总结中时态要统一&lt;/h2&gt;
&lt;h2 id=&#34;强调的词放在句尾&#34;&gt;强调的词放在句尾&lt;/h2&gt;
&lt;h1 id=&#34;a-few-matters-of-form&#34;&gt;A FEW MATTERS OF FORM&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;题目或标题下留空行&lt;/li&gt;
&lt;li&gt;数字用阿拉伯数字或罗马数字表示&lt;/li&gt;
&lt;li&gt;括号末除了句号与感叹号不留标点&lt;/li&gt;
&lt;li&gt;引用要有冒号与引号&lt;/li&gt;
&lt;li&gt;逗号后引用都在引号里
Aristotle says, “Art is an imitation of nature.”&lt;/li&gt;
&lt;li&gt;引用整行或诗要另起一行居中&lt;/li&gt;
&lt;li&gt;that表非正式引用，不用引号
Keats declares that beauty is truth, truth beauty.&lt;/li&gt;
&lt;li&gt;谚语与常用句式不用引号&lt;/li&gt;
&lt;li&gt;参考文献按期刊要求，文中注明引用地点，文末注明文献列表&lt;/li&gt;
&lt;li&gt;文学作品题目采用首字母大写的斜体&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;words-and-expressions-commonly-misused&#34;&gt;WORDS AND EXPRESSIONS COMMONLY MISUSED&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;All right. 避免使用冷淡词&lt;/li&gt;
&lt;li&gt;As good or better than.
My opinion is as good or better than his.
My opinion is as good as his, or better (if not better).&lt;/li&gt;
&lt;li&gt;As to whether. Whether足够哦&lt;/li&gt;
&lt;li&gt;Bid. 不定式没有to，过去式bade&lt;/li&gt;
&lt;li&gt;Case. 可省略词&lt;/li&gt;
&lt;li&gt;Certainly. 避免使用&lt;/li&gt;
&lt;li&gt;Character. 可省略词&lt;/li&gt;
&lt;li&gt;Claim, vb. 及物动词，表对某某要求的声明，不可与charge等混淆&lt;/li&gt;
&lt;li&gt;Compare. compare to 表相似性，可不同级别；compare with 表同级别比较
Paris has been compared to ancient Athens; it may be compared with modern London.&lt;/li&gt;
&lt;li&gt;Clever. 滥用，应用范围小&lt;/li&gt;
&lt;li&gt;Consider. 表意为beileve to be 时不用as，为examined或discuss时用&lt;/li&gt;
&lt;li&gt;Dependable. reliable, trustworthy的无意义替代&lt;/li&gt;
&lt;li&gt;Due to. 名词修饰语，不用做副词从句作为because of 等的替代&lt;/li&gt;
&lt;li&gt;Effect. 名词结果，效果，affect为动词影响&lt;/li&gt;
&lt;li&gt;Etc. 不用于人名，等同and the rest, and so forth&lt;/li&gt;
&lt;li&gt;Fact. 用于直接确认而不用于判断&lt;/li&gt;
&lt;li&gt;Factor. 无意义，考虑删除&lt;/li&gt;
&lt;li&gt;Feature. 无意义，考虑删除&lt;/li&gt;
&lt;li&gt;Fix. 书面语不表示修理表加固&lt;/li&gt;
&lt;li&gt;He is a man who. 改为He is&lt;/li&gt;
&lt;li&gt;However. 表然而，不放在句首，放句首表无论如何&lt;/li&gt;
&lt;li&gt;Kind of. 非rather或something of替代，理解为书面意思，sort of等同&lt;/li&gt;
&lt;li&gt;Less. less表量少，few表数字少&lt;/li&gt;
&lt;li&gt;Line, along these lines. 少用&lt;/li&gt;
&lt;li&gt;Literal, literally. 可省略&lt;/li&gt;
&lt;li&gt;Lose out. 比loss语气更强&lt;/li&gt;
&lt;li&gt;Most. 不要与almost抢饭碗&lt;/li&gt;
&lt;li&gt;Nature. 考虑删除&lt;/li&gt;
&lt;li&gt;Near by. 副词短语，尽量不用或用neighboring替代&lt;/li&gt;
&lt;li&gt;Oftentimes, ofttimes. 古英语，现在用often&lt;/li&gt;
&lt;li&gt;One hundred and one. 保留and&lt;/li&gt;
&lt;li&gt;One of the most. 不要用在开头&lt;/li&gt;
&lt;li&gt;People. 政治术语，与public区分，有数量用person&lt;/li&gt;
&lt;li&gt;Phase. 转变与发展的阶段，不用做aspect 或 topic的替代&lt;/li&gt;
&lt;li&gt;Possess. 不要与have或own混用&lt;/li&gt;
&lt;li&gt;Respective, respectively. 避免使用&lt;/li&gt;
&lt;li&gt;So. 避免使用&lt;/li&gt;
&lt;li&gt;State. 不要与say或remark混用，表声明&lt;/li&gt;
&lt;li&gt;Student body. 用students代替&lt;/li&gt;
&lt;li&gt;System. 无意义，去掉&lt;/li&gt;
&lt;li&gt;Thanking you in advance. 直接说thaking you&lt;/li&gt;
&lt;li&gt;They. each, each one, everybody, every one, many a man用单数而非复数代词&lt;/li&gt;
&lt;li&gt;Very. 珍惜使用&lt;/li&gt;
&lt;li&gt;Viewpoint. 写为point of view&lt;/li&gt;
&lt;li&gt;While. 少用，考虑用分号或者although代替&lt;/li&gt;
&lt;li&gt;Whom. 宾格&lt;/li&gt;
&lt;li&gt;Worth while. 表意模糊，尽量不用&lt;/li&gt;
&lt;li&gt;Would. 不用或者别跟shall或should抢生意&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;words-often-misspelled&#34;&gt;WORDS OFTEN MISSPELLED&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;accidentally&lt;/li&gt;
&lt;li&gt;advice&lt;/li&gt;
&lt;li&gt;affect&lt;/li&gt;
&lt;li&gt;beginning&lt;/li&gt;
&lt;li&gt;believe&lt;/li&gt;
&lt;li&gt;benefit&lt;/li&gt;
&lt;li&gt;challenge&lt;/li&gt;
&lt;li&gt;criticize&lt;/li&gt;
&lt;li&gt;deceive&lt;/li&gt;
&lt;li&gt;definite&lt;/li&gt;
&lt;li&gt;describe&lt;/li&gt;
&lt;li&gt;despise&lt;/li&gt;
&lt;li&gt;develop&lt;/li&gt;
&lt;li&gt;disappoint&lt;/li&gt;
&lt;li&gt;duel&lt;/li&gt;
&lt;li&gt;ecstasy&lt;/li&gt;
&lt;li&gt;effect&lt;/li&gt;
&lt;li&gt;existence&lt;/li&gt;
&lt;li&gt;fiery&lt;/li&gt;
&lt;li&gt;formerly&lt;/li&gt;
&lt;li&gt;humorous&lt;/li&gt;
&lt;li&gt;hypocrisy&lt;/li&gt;
&lt;li&gt;immediately&lt;/li&gt;
&lt;li&gt;incidentally&lt;/li&gt;
&lt;li&gt;latter&lt;/li&gt;
&lt;li&gt;led&lt;/li&gt;
&lt;li&gt;lose&lt;/li&gt;
&lt;li&gt;marriage&lt;/li&gt;
&lt;li&gt;mischief&lt;/li&gt;
&lt;li&gt;murmur&lt;/li&gt;
&lt;li&gt;necessary&lt;/li&gt;
&lt;li&gt;occurred&lt;/li&gt;
&lt;li&gt;parallel&lt;/li&gt;
&lt;li&gt;Philip&lt;/li&gt;
&lt;li&gt;playwright&lt;/li&gt;
&lt;li&gt;preceding&lt;/li&gt;
&lt;li&gt;prejudice&lt;/li&gt;
&lt;li&gt;principal&lt;/li&gt;
&lt;li&gt;privilege&lt;/li&gt;
&lt;li&gt;pursue&lt;/li&gt;
&lt;li&gt;repetition&lt;/li&gt;
&lt;li&gt;rhyme&lt;/li&gt;
&lt;li&gt;rhythm&lt;/li&gt;
&lt;li&gt;ridiculous&lt;/li&gt;
&lt;li&gt;sacrilegious&lt;/li&gt;
&lt;li&gt;seize&lt;/li&gt;
&lt;li&gt;separate&lt;/li&gt;
&lt;li&gt;shepherd&lt;/li&gt;
&lt;li&gt;siege&lt;/li&gt;
&lt;li&gt;similar&lt;/li&gt;
&lt;li&gt;simile&lt;/li&gt;
&lt;li&gt;too&lt;/li&gt;
&lt;li&gt;tragedy&lt;/li&gt;
&lt;li&gt;tries&lt;/li&gt;
&lt;li&gt;undoubtedly&lt;/li&gt;
&lt;li&gt;until&lt;/li&gt;
&lt;li&gt;to-day, to-night, to-morrow有连字符&lt;/li&gt;
&lt;li&gt;any one, every one, some one, some time 两个词&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
